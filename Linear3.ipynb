{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "\n",
    "cuda_status = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 64\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, out, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "def test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(76, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 4)\n",
    ")\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e93dd29da454e43b3786b72f4a12682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3218.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35adce5686c8497dbc59576e7fe763c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3875164985656747\n",
      "1.7350105047225952\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "agent_id = 0\n",
    "epoch = 3\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out, scene_ids, track_ids, agent_ids = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])\n",
    "        \n",
    "# Use the nn package to define our loss function\n",
    "loss_fn=torch.nn.MSELoss()\n",
    "\n",
    "# Use the optim package to define an Optimizer\n",
    "\n",
    "learning_rate =1e-3\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=0.001)\n",
    "#optimizer = torch.optim.Adagrad(model.parameters(), lr=learning_rate, lr_decay=0.01)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "iterator = tqdm(val_loader)\n",
    "\n",
    "for i in trange(epoch):\n",
    "    \n",
    "    for i_batch, sample_batch in enumerate(iterator):\n",
    "        inp, out, scene_ids, track_ids, agent_ids = sample_batch\n",
    "        \"\"\"TODO:\n",
    "          Deep learning model\n",
    "          training routine\n",
    "        \"\"\"\n",
    "        if i_batch >= 3216:\n",
    "            #show_sample_batch(sample_batch, agent_id)\n",
    "            #show_sample_batch([inp, y_pred.cpu().detach(), scene_ids, track_ids, agent_ids], agent_id)\n",
    "            continue\n",
    "\n",
    "        x = inp.float()\n",
    "        y = out.float()\n",
    "\n",
    "        if cuda_status:\n",
    "            #model = model.cuda()\n",
    "            #x = inp.cuda()\n",
    "            #y = out.cuda()\n",
    "            x.to(device)\n",
    "            y.to(device)\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        y_pred = torch.zeros(30,64,60,4, device=device).cuda()\n",
    "\n",
    "        # Forward pass: predict y by passing x to the model.   \n",
    "        for j in range(30):\n",
    "            #if j < 19:\n",
    "            #    diff = 19 - j\n",
    "            #    next_x = torch.cat((x[:,:,j:19,:], y[:,:,0:19 - diff,:]), 2)\n",
    "            #    next_x = torch.flatten(next_x, start_dim=2)\n",
    "                # 64 x 60 x 19 x 4\n",
    "            #    curr_y = model(next_x)\n",
    "            #else:\n",
    "            #    next_x = y[:,:,j - 19:j,:]\n",
    "            #    next_x = torch.flatten(next_x, start_dim=2)\n",
    "                # 64 x 60 x 19 x 4\n",
    "            #    curr_y = model(next_x)\n",
    "            # 64 x 60 x 4\n",
    "            #y_pred[j] = curr_y\n",
    "            if j < 19:\n",
    "                diff = 19 - j\n",
    "\n",
    "                next_x = torch.cat((x[:,:,j:19,:], y_pred.permute(1,2,0,3)[:,:,0:19 - diff,:]), 2)\n",
    "                next_x = torch.flatten(next_x, start_dim=2)\n",
    "                # 64 x 60 x 19 x 4\n",
    "                curr_y = model(next_x)\n",
    "            else:\n",
    "                next_x = y_pred.permute(1,2,0,3)[:,:,j - 19:j,:]\n",
    "                next_x = torch.flatten(next_x, start_dim=2)\n",
    "                # 64 x 60 x 19 x 4\n",
    "                curr_y = model(next_x)\n",
    "                # 64 x 60 x 4\n",
    "            y_pred[j] = curr_y\n",
    "            \n",
    "        #y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 2]))\n",
    "        y_pred = y_pred.permute(1,2,0,3)\n",
    "\n",
    "        # Compute the loss.\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        # Before backward pass, zero outgradients to clear buffers  \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient w.r.t modelparameters\n",
    "        loss.backward()\n",
    "\n",
    "        # makes an gradient descent step to update its parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(torch.sqrt(loss).item(), end='\\r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './models/3epochlinearincrementalnoteachingadamextralayer.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/6epochmodel.pt')\n",
    "model.eval()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebafca15af8843388cee76037a8b5338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         ID                  v1                  v2                  v3  \\\n",
      "0     10002  1644.1842041015625  458.61651611328125     1643.9541015625   \n",
      "1     10015   712.4559936523438    1234.95654296875         716.8359375   \n",
      "2     10019   572.0779418945312   1245.367431640625     572.10595703125   \n",
      "3     10028   1615.775146484375   445.6374206542969  1614.7332763671875   \n",
      "4      1003      2111.544921875   691.9639892578125    2108.16259765625   \n",
      "...     ...                 ...                 ...                 ...   \n",
      "3195   9897  253.69850158691406    807.767822265625  254.44679260253906   \n",
      "3196     99   582.8790283203125        1157.9140625     582.59130859375   \n",
      "3197   9905   1713.667724609375   515.9618530273438   1711.799072265625   \n",
      "3198   9910   574.7551879882812  1289.3184814453125       574.634765625   \n",
      "3199   9918      580.0478515625   1167.566650390625     580.77197265625   \n",
      "\n",
      "                      v4                  v5                  v6  \\\n",
      "0      459.5924987792969  1644.2701416015625   459.2315979003906   \n",
      "1     1234.1273193359375   716.8245849609375  1233.4876708984375   \n",
      "2        1245.5166015625   573.4449462890625       1245.09765625   \n",
      "3      446.2569885253906   1614.510009765625   444.9244079589844   \n",
      "4      690.4009399414062      2105.326171875   689.0641479492188   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   807.3572998046875   253.7097930908203   807.2030029296875   \n",
      "3196    1156.60693359375   583.0995483398438       1155.87890625   \n",
      "3197   515.7228393554688   1710.774169921875   514.7748413085938   \n",
      "3198   1289.629638671875   574.3865356445312      1288.994140625   \n",
      "3199  1164.3875732421875    579.818115234375         1164.796875   \n",
      "\n",
      "                      v7                  v8                  v9  ...  \\\n",
      "0       1649.84228515625   462.4878845214844  1650.3936767578125  ...   \n",
      "1       717.248291015625  1233.4652099609375   716.7093505859375  ...   \n",
      "2        573.44287109375   1245.221923828125   572.9845581054688  ...   \n",
      "3       1620.12353515625   448.5162658691406  1619.7659912109375  ...   \n",
      "4      2102.116943359375   688.0979614257812      2099.896484375  ...   \n",
      "...                  ...                 ...                 ...  ...   \n",
      "3195   254.3594970703125   806.7489013671875   255.2151336669922  ...   \n",
      "3196   583.0897216796875   1155.346923828125    582.805908203125  ...   \n",
      "3197  1713.1951904296875   517.4987182617188     1712.0654296875  ...   \n",
      "3198   574.2665405273438   1288.247802734375   574.2059936523438  ...   \n",
      "3199      580.1376953125     1161.9912109375   579.4165649414062  ...   \n",
      "\n",
      "                     v51                 v52                 v53  \\\n",
      "0     1618.1668701171875   514.5276489257812     1617.4794921875   \n",
      "1      701.8171997070312  1237.1407470703125      701.1572265625   \n",
      "2       575.457763671875  1243.6036376953125      575.4951171875   \n",
      "3     1581.5928955078125   500.9753112792969  1580.5902099609375   \n",
      "4          2082.62890625    685.630615234375          2082.09375   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   257.9651794433594     804.57275390625    258.152587890625   \n",
      "3196      579.0107421875   1151.362548828125   578.8782958984375   \n",
      "3197    1687.27392578125     545.56884765625  1686.6446533203125   \n",
      "3198   573.7698974609375  1285.6236572265625   573.7406005859375   \n",
      "3199       576.576171875  1155.2220458984375   576.5388793945312   \n",
      "\n",
      "                     v54                 v55                v56  \\\n",
      "0       515.203857421875   1616.593994140625  516.1323852539062   \n",
      "1     1236.9754638671875        700.33203125     1237.357421875   \n",
      "2      1243.574462890625     575.48779296875  1243.473876953125   \n",
      "3     501.49749755859375   1579.816162109375  502.5817565917969   \n",
      "4      685.5308227539062   2082.010498046875  685.6944580078125   \n",
      "...                  ...                 ...                ...   \n",
      "3195   804.3958740234375   258.1877136230469  804.3460693359375   \n",
      "3196   1151.055908203125   578.7660522460938   1151.02001953125   \n",
      "3197      545.8193359375  1686.1644287109375  546.3563232421875   \n",
      "3198     1285.5087890625   573.7538452148438  1285.476318359375   \n",
      "3199  1155.0084228515625   576.5216674804688  1155.343017578125   \n",
      "\n",
      "                     v57                 v58                v59  \\\n",
      "0       1615.77783203125   517.4020385742188  1614.424072265625   \n",
      "1      699.4595947265625   1237.563232421875   698.582763671875   \n",
      "2      575.5426635742188     1243.4052734375  575.5186767578125   \n",
      "3      1578.877197265625  503.76678466796875   1577.59912109375   \n",
      "4       2082.07568359375     685.90380859375   2082.37158203125   \n",
      "...                  ...                 ...                ...   \n",
      "3195  258.25335693359375    804.260498046875           258.1875   \n",
      "3196           578.65625     1151.1240234375  578.5242309570312   \n",
      "3197    1685.65966796875   547.0772705078125  1685.030517578125   \n",
      "3198      573.7861328125  1285.4732666015625  573.8103637695312   \n",
      "3199   576.4053344726562   1155.498779296875  576.1876831054688   \n",
      "\n",
      "                     v60  \n",
      "0      517.4932861328125  \n",
      "1     1237.8382568359375  \n",
      "2     1243.4117431640625  \n",
      "3      504.2443542480469  \n",
      "4      686.3704833984375  \n",
      "...                  ...  \n",
      "3195   804.3084716796875  \n",
      "3196   1151.101806640625  \n",
      "3197   547.3980712890625  \n",
      "3198    1285.57470703125  \n",
      "3199  1155.9158935546875  \n",
      "\n",
      "[3200 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Submission output\n",
    "writeCSV = True\n",
    "val_path = \"./new_val_in/new_val_in\"\n",
    "\n",
    "if writeCSV:\n",
    "    \n",
    "    dataset = ArgoverseDataset(data_path=val_path)\n",
    "    test_loader = DataLoader(dataset,batch_size=batch_sz, shuffle = False, collate_fn=test_collate, num_workers=0)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(tqdm(test_loader)):\n",
    "            inp, scene_ids, track_ids, agent_ids = sample_batch\n",
    "\n",
    "            if cuda_status:\n",
    "                model = model.cuda()\n",
    "                x = inp.float().to(device).cuda()\n",
    "            else:\n",
    "                x = inp.float()\n",
    "\n",
    "            y_pred = torch.zeros(30,64,60,4).to(device).cuda()\n",
    "            \n",
    "            # Forward pass: predict y by passing x to the model.   \n",
    "            for j in range(30):\n",
    "                if j < 19:\n",
    "                    diff = 19 - j\n",
    "\n",
    "                    next_x = torch.cat((x[:,:,j:19,:], y_pred.permute(1,2,0,3)[:,:,0:19 - diff,:]), 2)\n",
    "                    next_x = torch.flatten(next_x, start_dim=2)\n",
    "                    # 64 x 60 x 19 x 4\n",
    "                    curr_y = model(next_x)\n",
    "                else:\n",
    "                    next_x = y_pred.permute(1,2,0,3)[:,:,j - 19:j,:]\n",
    "                    next_x = torch.flatten(next_x, start_dim=2)\n",
    "                    # 64 x 60 x 19 x 4\n",
    "                    curr_y = model(next_x)\n",
    "                # 64 x 60 x 4\n",
    "                y_pred[j] = curr_y\n",
    "            #y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 2]))\n",
    "            y_pred = y_pred.permute(1,2,0,3)\n",
    "            \n",
    "            for i in range(batch_sz):\n",
    "                row = []\n",
    "                row.append(scene_ids[i].item())\n",
    "                curr = y_pred[i]\n",
    "                \n",
    "                agent_id = agent_ids[i]\n",
    "                \n",
    "                for j in range(30):\n",
    "                    vehicle_index = 0\n",
    "                    found = False\n",
    "                    while not found:\n",
    "                        if track_ids[i][vehicle_index][j][0] == agent_id:\n",
    "                            found = True\n",
    "                        else:\n",
    "                            vehicle_index += 1\n",
    "\n",
    "                    row.append(str(curr[vehicle_index][j][0].item()))\n",
    "                    row.append(str(curr[vehicle_index][j][1].item()))\n",
    "                    \n",
    "                data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, columns = ['ID','v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','v11','v12','v13','v14','v15','v16','v17','v18','v19','v20','v21','v22','v23','v24','v25','v26','v27','v28','v29','v30','v31','v32','v33','v34','v35','v36','v37','v38','v39','v40','v41','v42','v43','v44','v45','v46','v47','v48','v49','v50','v51','v52','v53','v54','v55','v56','v57','v58','v59','v60'])\n",
    "    print(df)\n",
    "    df.to_csv('submission.csv', index=False)\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
