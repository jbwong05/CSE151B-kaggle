{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy as np\n",
    "import pickle\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "\n",
    "cuda_status = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 128\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [np.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [np.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    car_mask = [scene['car_mask'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    car_mask = torch.LongTensor(car_mask)\n",
    "\n",
    "    num_cars = np.zeros((inp.shape[0]))\n",
    "    offsets = np.zeros((inp.shape[0], 2))\n",
    "    \n",
    "    for i in range(inp.shape[0]):\n",
    "        num_vehicles = 0\n",
    "        for j in range(60):\n",
    "            if car_mask[i][j][0] == 1:\n",
    "                num_vehicles += 1\n",
    "        num_cars[i] = num_vehicles\n",
    "        \n",
    "        agent_id = agent_ids[i]\n",
    "        vehicle_index = 0\n",
    "        found = False\n",
    "        while not found:\n",
    "            if track_ids[i][vehicle_index][0][0] == agent_id:\n",
    "                found = True\n",
    "            else:\n",
    "                vehicle_index += 1\n",
    "        start_x = inp[i][vehicle_index][18][0]\n",
    "        start_y = inp[i][vehicle_index][18][1]\n",
    "        \n",
    "        offsets[i][0] = start_x\n",
    "        offsets[i][1] = start_y\n",
    "        \n",
    "        inp[i,0:num_vehicles,:,0] -= start_x\n",
    "        inp[i,0:num_vehicles,:,1] -= start_y\n",
    "        #out[i,0:num_vehicles,:,0] -= start_x\n",
    "        #out[i,0:num_vehicles,:,1] -= start_y\n",
    "        \n",
    "    offsets = torch.LongTensor(offsets)\n",
    "    num_cars = torch.LongTensor(num_cars)\n",
    "\n",
    "    return [inp, out, scene_ids, track_ids, agent_ids, car_mask, num_cars, offsets]\n",
    "\n",
    "def test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [np.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    car_mask = [scene['car_mask'] for scene in batch]\n",
    "    \n",
    "    inp = torch.FloatTensor(inp)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    car_mask = torch.LongTensor(car_mask)\n",
    "    \n",
    "    num_cars = np.zeros((inp.shape[0]))\n",
    "    offsets = np.zeros((inp.shape[0], 2))\n",
    "    \n",
    "    for i in range(inp.shape[0]):\n",
    "        num_vehicles = 0\n",
    "        for j in range(60):\n",
    "            if car_mask[i][j][0] == 1:\n",
    "                num_vehicles += 1\n",
    "        num_cars[i] = num_vehicles\n",
    "        \n",
    "        agent_id = agent_ids[i]\n",
    "        vehicle_index = 0\n",
    "        found = False\n",
    "        while not found:\n",
    "            if track_ids[i][vehicle_index][0][0] == agent_id:\n",
    "                found = True\n",
    "            else:\n",
    "                vehicle_index += 1\n",
    "        start_x = inp[i][vehicle_index][0][0]\n",
    "        start_y = inp[i][vehicle_index][0][1]\n",
    "        \n",
    "        offsets[i][0] = start_x\n",
    "        offsets[i][1] = start_y\n",
    "        \n",
    "        inp[i,0:num_vehicles,:,0] -= start_x\n",
    "        inp[i,0:num_vehicles,:,1] -= start_y\n",
    "        \n",
    "    offsets = torch.LongTensor(offsets)\n",
    "    num_cars = torch.LongTensor(num_cars)\n",
    "    return [inp, scene_ids, track_ids, agent_ids, car_mask, num_cars, offsets]\n",
    "\n",
    "#temp_loader = DataLoader(val_dataset,batch_size=205942, shuffle = False, collate_fn=my_collate, num_workers=0, drop_last=True)\n",
    "#data = next(iter(temp_loader))\n",
    "#inp, out, scene_ids, track_ids, agent_ids, car_mask = data\n",
    "#print(inp.mean())\n",
    "#print(inp.std())\n",
    "#print(out.mean())\n",
    "#print(out.std())\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNEncoderDecoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.RNN(184, hidden_size=512, batch_first=True, nonlinearity='relu')\n",
    "        self.decoder = torch.nn.RNN(184, hidden_size=512, batch_first=True, nonlinearity='relu')\n",
    "        \n",
    "        self.align1 = torch.nn.Linear(10240, 19)\n",
    "        #self.attn = Attention(512,512)\n",
    "        \n",
    "        self.linear = torch.nn.Linear(512, 184)\n",
    "\n",
    "    def forward(self, x, y, teach = False, teaching_ratio = 0.5):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # batch_szx60x19x4\n",
    "        x = x.permute(0,2,1,3)\n",
    "        x = torch.flatten(x, start_dim=2)\n",
    "        # batch_szx19x240\n",
    "        output, hidden = self.encoder(x)\n",
    "        \n",
    "        if cuda_status:\n",
    "            outputs = torch.zeros(30,batch_size,46,4).to(device).cuda()\n",
    "            dec_out, dec_hidden = self.decoder(torch.full((batch_size,1,184), -1).to(device).cuda(), hidden)\n",
    "        else:\n",
    "            outputs = torch.zeros(30,batch_size,46,4).to(device)\n",
    "            dec_out, dec_hidden = self.decoder(torch.full((batch_size,1,184), -1).to(device).float(), hidden)\n",
    "        \n",
    "        # dec_out: batch_szx1x512\n",
    "        dec_out = dec_out.permute(1,0,2).squeeze(0)\n",
    "        # batch_szx512\n",
    "        dec_out = self.linear(dec_out)\n",
    "        # batch_sz x 240\n",
    "        outputs[0] = torch.reshape(dec_out, torch.Size([batch_size, 46, 4]))\n",
    "        \n",
    "        if teach:\n",
    "            next_in = torch.flatten(y[:,:,0,:].squeeze(2), start_dim=1).unsqueeze(1)\n",
    "            # batch_szx240\n",
    "        else:\n",
    "            next_in = dec_out.unsqueeze(1)\n",
    "        \n",
    "        # output: batch_szx19x512\n",
    "        # h_n: 1xbatch_szx512\n",
    "        prevState = hidden.permute(1,0,2)\n",
    "        inputStates = output\n",
    "        \n",
    "        for i in range(1,30):\n",
    "            alignment = self.align1(torch.flatten(torch.cat((inputStates, prevState), 1), start_dim=1))\n",
    "            #batch_szx19\n",
    "            \n",
    "            attention = torch.nn.functional.softmax(alignment, dim=1)\n",
    "            attention = attention.unsqueeze(1)\n",
    "            #batch_szx1x19\n",
    "            \n",
    "            new_hidden = torch.bmm(attention, inputStates)\n",
    "            new_hidden = new_hidden.permute(1,0,2)\n",
    "            #1xbatch_szx512\n",
    "             \n",
    "            dec_out, dec_hidden = self.decoder(next_in, new_hidden)\n",
    "            # dec_out: batch_szx1x512\n",
    "            dec_out = dec_out.permute(1,0,2).squeeze(0)\n",
    "            # batch_szx512\n",
    "            dec_out = self.linear(dec_out)\n",
    "            # batch_sz x 240\n",
    "            \n",
    "            teaching = random.random() < teaching_ratio\n",
    "            \n",
    "            if teach and teaching:\n",
    "                next_in = torch.flatten(y[:,:,i-1,:].squeeze(2), start_dim=1).unsqueeze(1)\n",
    "            else:\n",
    "                next_in = dec_out.unsqueeze(1)\n",
    "                \n",
    "            outputs[i] = torch.reshape(dec_out, torch.Size([batch_size, 46, 4]))\n",
    "            \n",
    "            prevState = dec_hidden.permute(1,0,2)\n",
    "        \n",
    "        return outputs.permute(1,2,0,3)\n",
    "\n",
    "model = RNNEncoderDecoder()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777678c247944f23b528ed686882c2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1824ce6975c647de8f9b973fea397d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1608.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609647ea4ebc469faf416708f8c9428c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1608.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751acf035f2b4810868ff4f05aebfc5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1608.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "119f512a82d444b89437dd309d0f9906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1608.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2544efcea81d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscene_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcar_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-4e7c3676307a>\u001b[0m in \u001b[0;36mmy_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcar_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'car_mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mscene\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mscene_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcar_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcar_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "agent_id = 0\n",
    "epoch = 4\n",
    "        \n",
    "# Use the nn package to define our loss function\n",
    "loss_fn=torch.nn.MSELoss()\n",
    "\n",
    "# Use the optim package to define an Optimizer\n",
    "\n",
    "learning_rate =1e-3\n",
    "#learning_rate =0.01\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for i in trange(epoch):\n",
    "    iterator = tqdm(val_loader)\n",
    "    total = 0\n",
    "    count = 0\n",
    "    \n",
    "    for i_batch, sample_batch in enumerate(iterator):\n",
    "        inp, out, scene_ids, track_ids, agent_ids, car_mask, num_cars, offsets = sample_batch\n",
    "        \n",
    "        x = inp.float()\n",
    "        y = out.float()\n",
    "\n",
    "        if cuda_status:\n",
    "            x.to(device)\n",
    "            y.to(device)\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        y_pred = None\n",
    "        # Forward pass: predict y by passing x to the model.    \n",
    "        y_pred = model(x[:,0:46,:,:], y[:,0:46,:,:], False)\n",
    "        #y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 4]))\n",
    "\n",
    "        for i in range(y_pred.shape[0]):\n",
    "            y_pred[i,0:num_cars[i],:,0] += offsets[i][0]\n",
    "            y_pred[i,0:num_cars[i],:,1] += offsets[i][1]\n",
    "\n",
    "        # Compute the loss.\n",
    "        loss = loss_fn(y_pred, y[:,0:46,:,:])\n",
    "        total += torch.sqrt(loss).item()\n",
    "\n",
    "        # Before backward pass, zero outgradients to clear buffers  \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient w.r.t modelparameters\n",
    "        loss.backward()\n",
    "\n",
    "        # makes an gradient descent step to update its parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        count += 1\n",
    "        \n",
    "        iterator.set_postfix(loss=total / count, curr=torch.sqrt(loss).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './models/16epoch-RNN-Encoder-Decoder-Attention-512-reoriented.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97c67c934d2740149cc0d4868a89c216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         ID                  v1                  v2                 v3  \\\n",
      "0     10002   1896.576416015625       240.767578125  1914.790283203125   \n",
      "1     10015   749.0038452148438  1290.2967529296875  744.3609619140625   \n",
      "2     10019   578.8092041015625  1284.3685302734375       578.37109375   \n",
      "3     10028     3440.1923828125   598.5861206054688  3337.244384765625   \n",
      "4      1003   2148.858154296875   684.3060302734375   2132.61376953125   \n",
      "...     ...                 ...                 ...                ...   \n",
      "3195   9897   257.7226867675781   793.0396118164062  260.6379699707031   \n",
      "3196     99    1255.28955078125   2314.205322265625  1200.934814453125   \n",
      "3197   9905  1783.4849853515625   426.6375732421875  1781.990478515625   \n",
      "3198   9910   580.1873168945312  1295.1317138671875  577.7432861328125   \n",
      "3199   9918   608.8973388671875      1155.216796875  610.3402709960938   \n",
      "\n",
      "                      v4                  v5                  v6  \\\n",
      "0     262.48065185546875   1907.428955078125  257.41595458984375   \n",
      "1      1289.473388671875   744.9356079101562  1288.4114990234375   \n",
      "2      1292.337158203125     577.41064453125    1290.70556640625   \n",
      "3      478.6102294921875   3326.849853515625      476.5068359375   \n",
      "4      677.8086547851562      2144.857421875   684.5596923828125   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   798.0052490234375  258.59381103515625   794.1080932617188   \n",
      "3196      2178.958984375    1183.50341796875        2173.0703125   \n",
      "3197   421.5085144042969    1780.70166015625   423.0644226074219   \n",
      "3198     1293.4658203125   578.3425903320312   1293.854248046875   \n",
      "3199   1162.883056640625   608.0821533203125  1162.9693603515625   \n",
      "\n",
      "                      v7                  v8                  v9  ...  \\\n",
      "0        1910.8349609375  258.41864013671875  1909.2469482421875  ...   \n",
      "1        745.35888671875   1288.808349609375   744.9199829101562  ...   \n",
      "2      577.7706298828125    1291.15771484375   577.6240844726562  ...   \n",
      "3       3352.74658203125  483.56451416015625     3339.0576171875  ...   \n",
      "4      2136.719970703125   679.7220458984375   2141.625732421875  ...   \n",
      "...                  ...                 ...                 ...  ...   \n",
      "3195   260.2552490234375   795.8270263671875   259.1697082519531  ...   \n",
      "3196   1191.251220703125   2179.785400390625     1189.4873046875  ...   \n",
      "3197  1781.9417724609375   422.5185852050781  1781.1983642578125  ...   \n",
      "3198   578.1959838867188  1293.7471923828125   578.2305908203125  ...   \n",
      "3199   609.1201782226562     1162.6806640625   608.5855102539062  ...   \n",
      "\n",
      "                     v51                 v52                 v53  \\\n",
      "0     1909.7386474609375   258.2058410644531  1909.7386474609375   \n",
      "1       745.095458984375  1288.7188720703125    745.095458984375   \n",
      "2       577.666259765625    1291.05322265625    577.666259765625   \n",
      "3      3343.648193359375   480.4564208984375    3343.64794921875   \n",
      "4      2139.818115234375   681.6658935546875   2139.818115234375   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   259.5919189453125   795.2640380859375   259.5919189453125   \n",
      "3196  1189.7413330078125   2178.466064453125  1189.7413330078125   \n",
      "3197   1781.452880859375  422.67449951171875   1781.452880859375   \n",
      "3198   578.2240600585938  1293.7691650390625   578.2240600585938   \n",
      "3199    608.771240234375     1162.7431640625    608.771240234375   \n",
      "\n",
      "                     v54                 v55                 v56  \\\n",
      "0      258.2058410644531  1909.7386474609375   258.2058410644531   \n",
      "1     1288.7188720703125    745.095458984375  1288.7188720703125   \n",
      "2       1291.05322265625    577.666259765625    1291.05322265625   \n",
      "3      480.4564208984375    3343.64794921875  480.45660400390625   \n",
      "4      681.6658935546875   2139.818115234375   681.6658935546875   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   795.2640380859375   259.5919189453125   795.2640380859375   \n",
      "3196   2178.466064453125  1189.7413330078125   2178.466064453125   \n",
      "3197  422.67449951171875   1781.452880859375  422.67449951171875   \n",
      "3198  1293.7691650390625   578.2240600585938  1293.7691650390625   \n",
      "3199     1162.7431640625    608.771240234375     1162.7431640625   \n",
      "\n",
      "                     v57                 v58                 v59  \\\n",
      "0     1909.7386474609375  258.20587158203125  1909.7386474609375   \n",
      "1       745.095458984375  1288.7188720703125    745.095458984375   \n",
      "2       577.666259765625    1291.05322265625    577.666259765625   \n",
      "3      3343.648193359375  480.45635986328125    3343.64794921875   \n",
      "4      2139.818115234375   681.6658935546875   2139.818115234375   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   259.5919189453125   795.2640380859375   259.5919189453125   \n",
      "3196  1189.7413330078125   2178.466064453125  1189.7413330078125   \n",
      "3197   1781.452880859375  422.67449951171875   1781.452880859375   \n",
      "3198   578.2240600585938  1293.7691650390625   578.2240600585938   \n",
      "3199    608.771240234375     1162.7431640625    608.771240234375   \n",
      "\n",
      "                     v60  \n",
      "0      258.2058410644531  \n",
      "1     1288.7188720703125  \n",
      "2       1291.05322265625  \n",
      "3     480.45635986328125  \n",
      "4      681.6658935546875  \n",
      "...                  ...  \n",
      "3195   795.2640380859375  \n",
      "3196   2178.466064453125  \n",
      "3197  422.67449951171875  \n",
      "3198  1293.7691650390625  \n",
      "3199     1162.7431640625  \n",
      "\n",
      "[3200 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Submission output\n",
    "writeCSV = True\n",
    "val_path = \"./new_val_in/new_val_in\"\n",
    "\n",
    "if writeCSV:\n",
    "    \n",
    "    dataset = ArgoverseDataset(data_path=val_path)\n",
    "    test_loader = DataLoader(dataset,batch_size=64, shuffle = False, collate_fn=test_collate, num_workers=0)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(tqdm(test_loader)):\n",
    "            inp, scene_ids, track_ids, agent_ids, car_mask, num_cars, offsets = sample_batch\n",
    "\n",
    "            if cuda_status:\n",
    "                model = model.cuda()\n",
    "                x = inp.float().cuda()\n",
    "            else:\n",
    "                x = inp.float()\n",
    "\n",
    "            y_pred = None\n",
    "\n",
    "            # Forward pass: predict y by passing x to the model.    \n",
    "            y_pred = model(x[:,0:46,:,:], None, False)\n",
    "            #y_pred = torch.reshape(y_pred, torch.Size([64, 60, 30, 4]))\n",
    "            \n",
    "            for i in range(y_pred.shape[0]):\n",
    "                y_pred[i,0:num_cars[i],:,0] += offsets[i][0]\n",
    "                y_pred[i,0:num_cars[i],:,1] += offsets[i][1]\n",
    "\n",
    "            \n",
    "            for i in range(64):\n",
    "                row = []\n",
    "                row.append(scene_ids[i].item())\n",
    "                curr = y_pred[i]\n",
    "                \n",
    "                agent_id = agent_ids[i]\n",
    "                \n",
    "                for j in range(30):\n",
    "                    vehicle_index = 0\n",
    "                    found = False\n",
    "                    while not found:\n",
    "                        if track_ids[i][vehicle_index][j][0] == agent_id:\n",
    "                            found = True\n",
    "                        else:\n",
    "                            vehicle_index += 1\n",
    "\n",
    "                    row.append(str(curr[vehicle_index][j][0].item()))\n",
    "                    row.append(str(curr[vehicle_index][j][1].item()))\n",
    "                    \n",
    "                data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, columns = ['ID','v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','v11','v12','v13','v14','v15','v16','v17','v18','v19','v20','v21','v22','v23','v24','v25','v26','v27','v28','v29','v30','v31','v32','v33','v34','v35','v36','v37','v38','v39','v40','v41','v42','v43','v44','v45','v46','v47','v48','v49','v50','v51','v52','v53','v54','v55','v56','v57','v58','v59','v60'])\n",
    "    print(df)\n",
    "    df.to_csv('submission.csv', index=False)\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
