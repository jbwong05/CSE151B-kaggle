{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy as np\n",
    "import pickle\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "\n",
    "cuda_status = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "batch_sz = 128\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [np.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [np.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    car_mask = [scene['car_mask'] for scene in batch]\n",
    "    \n",
    "    inp = torch.FloatTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    car_mask = torch.LongTensor(car_mask)\n",
    "    \n",
    "    num_cars = np.zeros((inp.shape[0]))\n",
    "    offsets = np.zeros((inp.shape[0], 2))\n",
    "    \n",
    "    real_input = np.zeros((inp.shape[0], 7, 19, 4))\n",
    "    real_output = np.zeros((inp.shape[0], 7, 30, 2))\n",
    "    \n",
    "    for i in range(inp.shape[0]):\n",
    "        \n",
    "        num_vehicles = 0\n",
    "        for j in range(60):\n",
    "            if car_mask[i][j][0] == 1:\n",
    "                num_vehicles += 1\n",
    "        num_cars[i] = num_vehicles\n",
    "        \n",
    "        agent_id = agent_ids[i]\n",
    "        vehicle_index = 0\n",
    "        found = False\n",
    "        while not found:\n",
    "            if track_ids[i][vehicle_index][0][0] == agent_id:\n",
    "                found = True\n",
    "            else:\n",
    "                vehicle_index += 1\n",
    "        start_x = inp[i][vehicle_index][0][0]\n",
    "        start_y = inp[i][vehicle_index][0][1]\n",
    "        \n",
    "        offsets[i][0] = start_x\n",
    "        offsets[i][1] = start_y\n",
    "        \n",
    "        inp[i,0:num_vehicles,:,0] -= start_x\n",
    "        inp[i,0:num_vehicles,:,1] -= start_y\n",
    "        #out[i,j,:,0] -= start_x\n",
    "        #out[i,j,:,1] -= start_y\n",
    "        \n",
    "        distances = [0] * num_vehicles\n",
    "        for j in range(num_vehicles):\n",
    "            if j == vehicle_index:\n",
    "                continue\n",
    "            distances[j] = math.sqrt(((inp[i,j,0,0] - inp[i,vehicle_index,0,0])**2) + ((inp[i,j,0,1] - inp[i,vehicle_index,0,1])**2))\n",
    "        \n",
    "        included = []\n",
    "        for j in range(6):\n",
    "            min_distance = -1\n",
    "            min_index = -1\n",
    "            \n",
    "            for k in range(len(distances)):\n",
    "                if k == vehicle_index:\n",
    "                    continue\n",
    "                \n",
    "                if min_index == -1 and k not in included:\n",
    "                    min_distance = distances[k]\n",
    "                    min_index = k\n",
    "                elif k not in included and distances[k] < min_distance:\n",
    "                    min_distance = distances[k]\n",
    "                    min_index = k\n",
    "            included.append(min_index)\n",
    "            real_input[i][j] = inp[i,min_index,:,:]\n",
    "            real_output[i][j] = out[i,min_index,:,0:2]\n",
    "        real_input[i][6] = inp[i,vehicle_index,:,:]\n",
    "        real_output[i] = out[i,vehicle_index,:,0:2]\n",
    "    \n",
    "    real_input = torch.LongTensor(real_input)\n",
    "    real_output = torch.LongTensor(real_output)\n",
    "    offsets = torch.LongTensor(offsets)\n",
    "    num_cars = torch.LongTensor(num_cars)\n",
    "    return [real_input, real_output, scene_ids, offsets]\n",
    "\n",
    "def test_collate(batch):\n",
    "    inp = [np.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    #out = [np.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    car_mask = [scene['car_mask'] for scene in batch]\n",
    "    \n",
    "    inp = torch.FloatTensor(inp)\n",
    "    #out = torch.LongTensor(out)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    car_mask = torch.LongTensor(car_mask)\n",
    "    \n",
    "    num_cars = np.zeros((inp.shape[0]))\n",
    "    offsets = np.zeros((inp.shape[0], 2))\n",
    "    \n",
    "    real_input = np.zeros((inp.shape[0], 7, 19, 4))\n",
    "    real_output = np.zeros((inp.shape[0], 7, 30, 2))\n",
    "    \n",
    "    for i in range(inp.shape[0]):\n",
    "        \n",
    "        num_vehicles = 0\n",
    "        for j in range(60):\n",
    "            if car_mask[i][j][0] == 1:\n",
    "                num_vehicles += 1\n",
    "        num_cars[i] = num_vehicles\n",
    "        \n",
    "        agent_id = agent_ids[i]\n",
    "        vehicle_index = 0\n",
    "        found = False\n",
    "        while not found:\n",
    "            if track_ids[i][vehicle_index][0][0] == agent_id:\n",
    "                found = True\n",
    "            else:\n",
    "                vehicle_index += 1\n",
    "        start_x = inp[i][vehicle_index][0][0]\n",
    "        start_y = inp[i][vehicle_index][0][1]\n",
    "        \n",
    "        offsets[i][0] = start_x\n",
    "        offsets[i][1] = start_y\n",
    "        \n",
    "        inp[i,0:num_vehicles,:,0] -= start_x\n",
    "        inp[i,0:num_vehicles,:,1] -= start_y\n",
    "        #out[i,j,:,0] -= start_x\n",
    "        #out[i,j,:,1] -= start_y\n",
    "        \n",
    "        distances = [0] * num_vehicles\n",
    "        for j in range(num_vehicles):\n",
    "            if j == vehicle_index:\n",
    "                continue\n",
    "            distances[j] = math.sqrt(((inp[i,j,0,0] - inp[i,vehicle_index,0,0])**2) + ((inp[i,j,0,1] - inp[i,vehicle_index,0,1])**2))\n",
    "        \n",
    "        included = []\n",
    "        for j in range(6):\n",
    "            min_distance = -1\n",
    "            min_index = -1\n",
    "            \n",
    "            for k in range(len(distances)):\n",
    "                if k == vehicle_index:\n",
    "                    continue\n",
    "                \n",
    "                if min_index == -1 and k not in included:\n",
    "                    min_distance = distances[k]\n",
    "                    min_index = k\n",
    "                elif k not in included and distances[k] < min_distance:\n",
    "                    min_distance = distances[k]\n",
    "                    min_index = k\n",
    "            included.append(min_index)\n",
    "            real_input[i][j] = inp[i,min_index,:,:]\n",
    "            #real_output[i][j] = out[i,min_index,:,0:2]\n",
    "        real_input[i][6] = inp[i,vehicle_index,:,:]\n",
    "        #real_output[i] = out[i,vehicle_index,:,0:2]\n",
    "    \n",
    "    real_input = torch.LongTensor(real_input)\n",
    "    #real_output = torch.LongTensor(real_output)\n",
    "    offsets = torch.LongTensor(offsets)\n",
    "    num_cars = torch.LongTensor(num_cars)\n",
    "    return [real_input, scene_ids, offsets]\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNEncoderDecoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.RNN(28, hidden_size=512, batch_first=True, nonlinearity='relu')\n",
    "        self.decoder = torch.nn.RNN(28, hidden_size=512, batch_first=True, nonlinearity='relu')\n",
    "        \n",
    "        self.align1 = torch.nn.Linear(10240, 19)\n",
    "        #self.attn = Attention(512,512)\n",
    "        \n",
    "        self.linear = torch.nn.Linear(512, 28)\n",
    "\n",
    "    def forward(self, x, y, teach = False, teaching_ratio = 0.5):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # batch_szx60x19x4\n",
    "        x = x.permute(0,2,1,3)\n",
    "        x = torch.flatten(x, start_dim=2)\n",
    "        # batch_szx19x240\n",
    "        output, hidden = self.encoder(x)\n",
    "        \n",
    "        if cuda_status:\n",
    "            outputs = torch.zeros(30,batch_size,7,4).to(device).cuda()\n",
    "            dec_out, dec_hidden = self.decoder(torch.full((batch_size,1,28), -1).to(device).cuda(), hidden)\n",
    "        else:\n",
    "            outputs = torch.zeros(30,batch_size,7,4).to(device)\n",
    "            dec_out, dec_hidden = self.decoder(torch.full((batch_size,1,28), -1).to(device).float(), hidden)\n",
    "        \n",
    "        # dec_out: batch_szx1x512\n",
    "        dec_out = dec_out.permute(1,0,2).squeeze(0)\n",
    "        # batch_szx512\n",
    "        dec_out = self.linear(dec_out)\n",
    "        # batch_sz x 240\n",
    "        outputs[0] = torch.reshape(dec_out, torch.Size([batch_size, 7, 4]))\n",
    "        \n",
    "        if teach:\n",
    "            next_in = torch.flatten(y[:,:,0,:].squeeze(2), start_dim=1).unsqueeze(1)\n",
    "            # batch_szx240\n",
    "        else:\n",
    "            next_in = dec_out.unsqueeze(1)\n",
    "        \n",
    "        # output: batch_szx19x512\n",
    "        # h_n: 1xbatch_szx512\n",
    "        prevState = hidden.permute(1,0,2)\n",
    "        inputStates = output\n",
    "        \n",
    "        for i in range(1,30):\n",
    "            alignment = self.align1(torch.flatten(torch.cat((inputStates, prevState), 1), start_dim=1))\n",
    "            #batch_szx19\n",
    "            \n",
    "            attention = torch.nn.functional.softmax(alignment, dim=1)\n",
    "            attention = attention.unsqueeze(1)\n",
    "            #batch_szx1x19\n",
    "            \n",
    "            new_hidden = torch.bmm(attention, inputStates)\n",
    "            new_hidden = new_hidden.permute(1,0,2)\n",
    "            #1xbatch_szx512\n",
    "             \n",
    "            dec_out, dec_hidden = self.decoder(next_in, new_hidden)\n",
    "            # dec_out: batch_szx1x512\n",
    "            dec_out = dec_out.permute(1,0,2).squeeze(0)\n",
    "            # batch_szx512\n",
    "            dec_out = self.linear(dec_out)\n",
    "            # batch_sz x 240\n",
    "            \n",
    "            teaching = random.random() < teaching_ratio\n",
    "            \n",
    "            if teach and teaching:\n",
    "                next_in = torch.flatten(y[:,:,i-1,:].squeeze(2), start_dim=1).unsqueeze(1)\n",
    "            else:\n",
    "                next_in = dec_out.unsqueeze(1)\n",
    "                \n",
    "            outputs[i] = torch.reshape(dec_out, torch.Size([batch_size, 7, 4]))\n",
    "            \n",
    "            prevState = dec_hidden.permute(1,0,2)\n",
    "        \n",
    "        return outputs.permute(1,2,0,3)\n",
    "\n",
    "model = RNNEncoderDecoder()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca6b2106e094ee5b7c79af08ce61e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a221a6b6dac14f6ea70ab44d23727a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1608.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type RNNEncoderDecoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0a1c57446c4e0d9dd67ac0a4d17cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1608.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4b4649587f4274aa3d5ff6ed30c35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1608.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d538d48c00845d1abd9315584a25175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1608.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27639de03f984197a6e2e057f65d9efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1608.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b08bf40bfe48a08b4e370ff87f1848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1608.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c4a76e23384c968efebf918108bb46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1608.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b200766ad97947079a3d23d2fe7842bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1608.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978991703ff64707880345bb882792e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1608.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bba088b4fe49528ba4706bccde7679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1608.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "agent_id = 0\n",
    "epoch = 10\n",
    "        \n",
    "# Use the nn package to define our loss function\n",
    "loss_fn=torch.nn.MSELoss()\n",
    "\n",
    "# Use the optim package to define an Optimizer\n",
    "\n",
    "learning_rate =1e-3\n",
    "#learning_rate =0.01\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "epoch_count = 0\n",
    "\n",
    "for i in trange(epoch):\n",
    "    iterator = tqdm(val_loader)\n",
    "    total = 0\n",
    "    count = 0\n",
    "    \n",
    "    for i_batch, sample_batch in enumerate(iterator):\n",
    "        inp, out, scene_ids, offsets = sample_batch\n",
    "        \n",
    "        x = inp.float()\n",
    "        y = out.float()\n",
    "\n",
    "        if cuda_status:\n",
    "            x.to(device)\n",
    "            y.to(device)\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        y_pred = None\n",
    "        # Forward pass: predict y by passing x to the model.    \n",
    "        y_pred = model(x, y, False)\n",
    "        #y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 4]))\n",
    "\n",
    "        for i in range(y_pred.shape[0]):\n",
    "            y_pred[i,:,:,0] += offsets[i][0]\n",
    "            y_pred[i,:,:,1] += offsets[i][1]\n",
    "\n",
    "        # Compute the loss.\n",
    "        loss = loss_fn(y_pred[:,6,:,0:2], y[:,6,:,:])\n",
    "        total += torch.sqrt(loss).item()\n",
    "\n",
    "        # Before backward pass, zero outgradients to clear buffers  \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient w.r.t modelparameters\n",
    "        loss.backward()\n",
    "\n",
    "        # makes an gradient descent step to update its parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        count += 1\n",
    "        \n",
    "        iterator.set_postfix(loss=total / count, curr=torch.sqrt(loss).item())\n",
    "    epoch_count += 1\n",
    "    torch.save(model, './models/new-rnn-ed' + str(epoch_count) + '.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './models/16epoch-RNN-Encoder-Decoder-Attention-512-reoriented.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e4f755528c42aea1f7ff6db6540549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         ID                  v1                  v2                  v3  \\\n",
      "0     10002  1713.8968505859375  335.67706298828125     1713.9501953125   \n",
      "1     10015   725.2689819335938  1231.5135498046875   724.6871948242188   \n",
      "2     10019     572.43310546875  1241.4617919921875    572.353759765625   \n",
      "3     10028   1689.933349609375   312.4473571777344  1690.6966552734375   \n",
      "4      1003       2123.41796875   673.6227416992188   2126.038330078125   \n",
      "...     ...                 ...                 ...                 ...   \n",
      "3195   9897  255.89727783203125   804.8311157226562   253.0451202392578   \n",
      "3196     99   587.8493041992188    1148.79736328125   586.0477294921875   \n",
      "3197   9905   1755.614501953125   442.7036437988281  1755.0113525390625   \n",
      "3198   9910     573.90478515625    1285.23095703125       574.810546875   \n",
      "3199   9918   584.6610717773438      1165.646484375    582.992431640625   \n",
      "\n",
      "                      v4                  v5                  v6  \\\n",
      "0     332.55267333984375   1716.572021484375   335.0657043457031   \n",
      "1      1227.224365234375   725.2910766601562  1227.9537353515625   \n",
      "2     1242.8302001953125   572.9207153320312    1243.50244140625   \n",
      "3      313.8175354003906  1691.0059814453125    313.655029296875   \n",
      "4      678.3712158203125   2126.457275390625   671.0507202148438   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   807.5621337890625  253.33384704589844        807.05859375   \n",
      "3196    1153.45751953125    586.310791015625   1152.198486328125   \n",
      "3197    442.190185546875  1756.0645751953125    442.061767578125   \n",
      "3198  1286.4898681640625    575.101806640625   1286.252685546875   \n",
      "3199      1165.119140625   582.8829956054688    1162.94970703125   \n",
      "\n",
      "                      v7                  v8                  v9  ...  \\\n",
      "0       1716.94580078125    335.110107421875  1719.2052001953125  ...   \n",
      "1          725.638671875  1227.7147216796875   725.2326049804688  ...   \n",
      "2      573.9059448242188  1241.8634033203125   573.2454223632812  ...   \n",
      "3     1692.4913330078125  315.98699951171875   1691.590087890625  ...   \n",
      "4      2117.145751953125    674.534912109375    2118.45654296875  ...   \n",
      "...                  ...                 ...                 ...  ...   \n",
      "3195   254.6445770263672   806.9906616210938  254.19146728515625  ...   \n",
      "3196   586.1373901367188  1151.8153076171875   586.3462524414062  ...   \n",
      "3197  1754.1907958984375   442.3643798828125  1755.0826416015625  ...   \n",
      "3198     575.17138671875  1284.4769287109375   574.8814697265625  ...   \n",
      "3199   583.2745361328125  1161.6812744140625   582.8421630859375  ...   \n",
      "\n",
      "                    v51                 v52                 v53  \\\n",
      "0     1737.012939453125  351.80963134765625   1737.011474609375   \n",
      "1     722.9961547851562    1219.26318359375    723.251220703125   \n",
      "2     576.3215942382812  1238.3975830078125   577.0117797851562   \n",
      "3     1711.054443359375   332.7413330078125   1711.624267578125   \n",
      "4      2096.57177734375    651.859619140625            2096.625   \n",
      "...                 ...                 ...                 ...   \n",
      "3195  257.6411437988281   805.5464477539062   257.9460144042969   \n",
      "3196  584.8490600585938  1135.1251220703125   584.4069213867188   \n",
      "3197  1755.927490234375   450.7309875488281  1756.6895751953125   \n",
      "3198  574.4069213867188  1278.4036865234375   574.5294799804688   \n",
      "3199     584.0830078125  1140.7579345703125   584.6975708007812   \n",
      "\n",
      "                     v54                 v55                 v56  \\\n",
      "0      351.8105163574219  1737.0101318359375  351.80853271484375   \n",
      "1      1218.488037109375    722.733642578125  1218.8111572265625   \n",
      "2     1237.8243408203125   576.6366577148438    1237.54443359375   \n",
      "3     333.94989013671875    1711.96435546875    333.619384765625   \n",
      "4      651.7230224609375        2096.6484375       651.849609375   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   805.6966552734375   258.0341491699219   805.8150024414062   \n",
      "3196  1134.4696044921875   584.4174194335938  1134.5345458984375   \n",
      "3197    451.123291015625  1756.4290771484375  451.88153076171875   \n",
      "3198           1277.9375      574.2919921875     1278.1748046875   \n",
      "3199  1139.8299560546875   584.2412719726562  1139.5638427734375   \n",
      "\n",
      "                     v57                 v58                v59  \\\n",
      "0      1737.010009765625  351.80743408203125   1737.01025390625   \n",
      "1      723.1167602539062    1218.15576171875  722.3880004882812   \n",
      "2      577.6300659179688   1237.372802734375     577.5712890625   \n",
      "3     1712.7374267578125   335.3539123535156  1712.731689453125   \n",
      "4      2096.679443359375   651.7839965820312  2096.688720703125   \n",
      "...                  ...                 ...                ...   \n",
      "3195   258.2048034667969   805.9437255859375    258.16259765625   \n",
      "3196   584.2120361328125   1134.258056640625  584.1925048828125   \n",
      "3197   1756.952880859375   452.2749938964844   1756.62353515625   \n",
      "3198   574.5995483398438   1278.118896484375     574.4013671875   \n",
      "3199     584.54052734375  1139.2945556640625  584.4308471679688   \n",
      "\n",
      "                     v60  \n",
      "0      351.8075256347656  \n",
      "1       1218.00146484375  \n",
      "2           1237.3515625  \n",
      "3      335.0822448730469  \n",
      "4      651.8530883789062  \n",
      "...                  ...  \n",
      "3195   806.1381225585938  \n",
      "3196  1134.3121337890625  \n",
      "3197   452.9065856933594  \n",
      "3198   1278.361572265625  \n",
      "3199   1139.144287109375  \n",
      "\n",
      "[3200 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Submission output\n",
    "writeCSV = True\n",
    "val_path = \"./new_val_in/new_val_in\"\n",
    "\n",
    "if writeCSV:\n",
    "    \n",
    "    dataset = ArgoverseDataset(data_path=val_path)\n",
    "    test_loader = DataLoader(dataset,batch_size=64, shuffle = False, collate_fn=test_collate, num_workers=0)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(tqdm(test_loader)):\n",
    "            inp, scene_ids, offsets = sample_batch\n",
    "\n",
    "            if cuda_status:\n",
    "                model = model.cuda()\n",
    "                x = inp.cuda()\n",
    "            else:\n",
    "                x = inp\n",
    "\n",
    "            y_pred = None\n",
    "\n",
    "            # Forward pass: predict y by passing x to the model.    \n",
    "            y_pred = model(x.float(), None, False)\n",
    "            y_pred = torch.reshape(y_pred, torch.Size([64, 7, 30, 4]))\n",
    "            \n",
    "            for i in range(y_pred.shape[0]):\n",
    "                y_pred[i,:,:,0] += offsets[i][0]\n",
    "                y_pred[i,:,:,1] += offsets[i][1]\n",
    "            \n",
    "            for i in range(64):\n",
    "                row = []\n",
    "                row.append(scene_ids[i].item())\n",
    "                \n",
    "                curr = y_pred[i]\n",
    "                \n",
    "                for j in range(30):\n",
    "                    row.append(str(curr[6][j][0].item()))\n",
    "                    row.append(str(curr[6][j][1].item()))\n",
    "                    \n",
    "                data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, columns = ['ID','v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','v11','v12','v13','v14','v15','v16','v17','v18','v19','v20','v21','v22','v23','v24','v25','v26','v27','v28','v29','v30','v31','v32','v33','v34','v35','v36','v37','v38','v39','v40','v41','v42','v43','v44','v45','v46','v47','v48','v49','v50','v51','v52','v53','v54','v55','v56','v57','v58','v59','v60'])\n",
    "    print(df)\n",
    "    df.to_csv('submission.csv', index=False)\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
