{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy as np\n",
    "import pickle\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "\n",
    "cuda_status = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "batch_sz = 128\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [np.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [np.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    car_mask = [scene['car_mask'] for scene in batch]\n",
    "    \n",
    "    inp = torch.FloatTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    car_mask = torch.LongTensor(car_mask)\n",
    "    \n",
    "    num_cars = np.zeros((inp.shape[0]))\n",
    "    offsets = np.zeros((inp.shape[0], 2))\n",
    "    \n",
    "    real_input = np.zeros((inp.shape[0], 7, 19, 4))\n",
    "    real_output = np.zeros((inp.shape[0], 7, 30, 2))\n",
    "    \n",
    "    for i in range(inp.shape[0]):\n",
    "        \n",
    "        num_vehicles = 0\n",
    "        for j in range(60):\n",
    "            if car_mask[i][j][0] == 1:\n",
    "                num_vehicles += 1\n",
    "        num_cars[i] = num_vehicles\n",
    "        \n",
    "        agent_id = agent_ids[i]\n",
    "        vehicle_index = 0\n",
    "        found = False\n",
    "        while not found:\n",
    "            if track_ids[i][vehicle_index][0][0] == agent_id:\n",
    "                found = True\n",
    "            else:\n",
    "                vehicle_index += 1\n",
    "        start_x = inp[i][vehicle_index][0][0]\n",
    "        start_y = inp[i][vehicle_index][0][1]\n",
    "        \n",
    "        offsets[i][0] = start_x\n",
    "        offsets[i][1] = start_y\n",
    "        \n",
    "        inp[i,0:num_vehicles,:,0] -= start_x\n",
    "        inp[i,0:num_vehicles,:,1] -= start_y\n",
    "        \n",
    "        distances = [0] * num_vehicles\n",
    "        for j in range(num_vehicles):\n",
    "            if j == vehicle_index:\n",
    "                continue\n",
    "            distances[j] = math.sqrt(((inp[i,j,0,0] - inp[i,vehicle_index,0,0])**2) + ((inp[i,j,0,1] - inp[i,vehicle_index,0,1])**2))\n",
    "        \n",
    "        included = []\n",
    "        for j in range(6):\n",
    "            min_distance = -1\n",
    "            min_index = -1\n",
    "            \n",
    "            for k in range(len(distances)):\n",
    "                if k == vehicle_index:\n",
    "                    continue\n",
    "                \n",
    "                if min_index == -1 and k not in included:\n",
    "                    min_distance = distances[k]\n",
    "                    min_index = k\n",
    "                elif k not in included and distances[k] < min_distance:\n",
    "                    min_distance = distances[k]\n",
    "                    min_index = k\n",
    "            if min_index == -1:\n",
    "                real_input[i][j] = np.zeros((19,4))\n",
    "                real_output[i][j] = np.zeros((30,2))\n",
    "            else:\n",
    "                included.append(min_index)\n",
    "                real_input[i][j] = inp[i,min_index,:,:]\n",
    "                real_output[i][j] = out[i,min_index,:,0:2]\n",
    "        real_input[i][6] = inp[i,vehicle_index,:,:]\n",
    "        real_output[i] = out[i,vehicle_index,:,0:2]\n",
    "    \n",
    "    real_input = torch.LongTensor(real_input)\n",
    "    real_output = torch.LongTensor(real_output)\n",
    "    offsets = torch.LongTensor(offsets)\n",
    "    num_cars = torch.LongTensor(num_cars)\n",
    "    return [real_input, real_output, scene_ids, offsets]\n",
    "\n",
    "def test_collate(batch):\n",
    "    inp = [np.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    car_mask = [scene['car_mask'] for scene in batch]\n",
    "    \n",
    "    inp = torch.FloatTensor(inp)\n",
    "    #out = torch.LongTensor(out)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    car_mask = torch.LongTensor(car_mask)\n",
    "    \n",
    "    num_cars = np.zeros((inp.shape[0]))\n",
    "    offsets = np.zeros((inp.shape[0], 2))\n",
    "    \n",
    "    real_input = np.zeros((inp.shape[0], 7, 19, 4))\n",
    "    real_output = np.zeros((inp.shape[0], 7, 30, 2))\n",
    "    \n",
    "    for i in range(inp.shape[0]):\n",
    "        \n",
    "        num_vehicles = 0\n",
    "        for j in range(60):\n",
    "            if car_mask[i][j][0] == 1:\n",
    "                num_vehicles += 1\n",
    "        num_cars[i] = num_vehicles\n",
    "        \n",
    "        agent_id = agent_ids[i]\n",
    "        vehicle_index = 0\n",
    "        found = False\n",
    "        while not found:\n",
    "            if track_ids[i][vehicle_index][0][0] == agent_id:\n",
    "                found = True\n",
    "            else:\n",
    "                vehicle_index += 1\n",
    "        start_x = inp[i][vehicle_index][0][0]\n",
    "        start_y = inp[i][vehicle_index][0][1]\n",
    "        \n",
    "        offsets[i][0] = start_x\n",
    "        offsets[i][1] = start_y\n",
    "        \n",
    "        inp[i,0:num_vehicles,:,0] -= start_x\n",
    "        inp[i,0:num_vehicles,:,1] -= start_y\n",
    "        \n",
    "        distances = [0] * num_vehicles\n",
    "        for j in range(num_vehicles):\n",
    "            if j == vehicle_index:\n",
    "                continue\n",
    "            distances[j] = math.sqrt(((inp[i,j,0,0] - inp[i,vehicle_index,0,0])**2) + ((inp[i,j,0,1] - inp[i,vehicle_index,0,1])**2))\n",
    "        \n",
    "        included = []\n",
    "        for j in range(6):\n",
    "            min_distance = -1\n",
    "            min_index = -1\n",
    "            \n",
    "            for k in range(len(distances)):\n",
    "                if k == vehicle_index:\n",
    "                    continue\n",
    "                \n",
    "                if min_index == -1 and k not in included:\n",
    "                    min_distance = distances[k]\n",
    "                    min_index = k\n",
    "                elif k not in included and distances[k] < min_distance:\n",
    "                    min_distance = distances[k]\n",
    "                    min_index = k\n",
    "            if min_index == -1:\n",
    "                real_input[i][j] = np.zeros((19,4))\n",
    "            else:\n",
    "                included.append(min_index)\n",
    "                real_input[i][j] = inp[i,min_index,:,:]\n",
    "            included.append(min_index)\n",
    "            real_input[i][j] = inp[i,min_index,:,:]\n",
    "        real_input[i][6] = inp[i,vehicle_index,:,:]\n",
    "    \n",
    "    real_input = torch.LongTensor(real_input)\n",
    "    offsets = torch.LongTensor(offsets)\n",
    "    num_cars = torch.LongTensor(num_cars)\n",
    "    return [real_input, scene_ids, offsets]\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class RNNEncoderDecoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.RNN(28, hidden_size=512, batch_first=True, nonlinearity='relu')\n",
    "        self.decoder = torch.nn.RNN(28, hidden_size=512, batch_first=True, nonlinearity='relu')\n",
    "        \n",
    "        self.align1 = torch.nn.Linear(10240, 19)\n",
    "        #self.attn = Attention(512,512)\n",
    "        \n",
    "        self.linear = torch.nn.Linear(512, 28)\n",
    "\n",
    "    def forward(self, x, y, teach = False, teaching_ratio = 0.5):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # batch_szx60x19x4\n",
    "        x = x.permute(0,2,1,3)\n",
    "        x = torch.flatten(x, start_dim=2)\n",
    "        # batch_szx19x240\n",
    "        output, hidden = self.encoder(x)\n",
    "        \n",
    "        if cuda_status:\n",
    "            outputs = torch.zeros(30,batch_size,7,4).to(device).cuda()\n",
    "            dec_out, dec_hidden = self.decoder(torch.full((batch_size,1,28), -1).to(device).cuda(), hidden)\n",
    "        else:\n",
    "            outputs = torch.zeros(30,batch_size,7,4).to(device)\n",
    "            dec_out, dec_hidden = self.decoder(torch.full((batch_size,1,28), -1).to(device).float(), hidden)\n",
    "        \n",
    "        # dec_out: batch_szx1x512\n",
    "        dec_out = dec_out.permute(1,0,2).squeeze(0)\n",
    "        # batch_szx512\n",
    "        dec_out = self.linear(dec_out)\n",
    "        # batch_sz x 240\n",
    "        outputs[0] = torch.reshape(dec_out, torch.Size([batch_size, 7, 4]))\n",
    "        \n",
    "        if teach:\n",
    "            next_in = torch.flatten(y[:,:,0,:].squeeze(2), start_dim=1).unsqueeze(1)\n",
    "            # batch_szx240\n",
    "        else:\n",
    "            next_in = dec_out.unsqueeze(1)\n",
    "        \n",
    "        # output: batch_szx19x512\n",
    "        # h_n: 1xbatch_szx512\n",
    "        prevState = hidden.permute(1,0,2)\n",
    "        inputStates = output\n",
    "        \n",
    "        for i in range(1,30):\n",
    "            alignment = self.align1(torch.flatten(torch.cat((inputStates, prevState), 1), start_dim=1))\n",
    "            #batch_szx19\n",
    "            \n",
    "            attention = torch.nn.functional.softmax(alignment, dim=1)\n",
    "            attention = attention.unsqueeze(1)\n",
    "            #batch_szx1x19\n",
    "            \n",
    "            new_hidden = torch.bmm(attention, inputStates)\n",
    "            new_hidden = new_hidden.permute(1,0,2)\n",
    "            #1xbatch_szx512\n",
    "             \n",
    "            dec_out, dec_hidden = self.decoder(next_in, new_hidden)\n",
    "            # dec_out: batch_szx1x512\n",
    "            dec_out = dec_out.permute(1,0,2).squeeze(0)\n",
    "            # batch_szx512\n",
    "            dec_out = self.linear(dec_out)\n",
    "            # batch_sz x 240\n",
    "            \n",
    "            teaching = random.random() < teaching_ratio\n",
    "            \n",
    "            if teach and teaching:\n",
    "                next_in = torch.flatten(y[:,:,i-1,:].squeeze(2), start_dim=1).unsqueeze(1)\n",
    "            else:\n",
    "                next_in = dec_out.unsqueeze(1)\n",
    "                \n",
    "            outputs[i] = torch.reshape(dec_out, torch.Size([batch_size, 7, 4]))\n",
    "            \n",
    "            prevState = dec_hidden.permute(1,0,2)\n",
    "        \n",
    "        return outputs.permute(1,2,0,3)\n",
    "\n",
    "model = RNNEncoderDecoder()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNEncoderDecoder(\n",
       "  (encoder): RNN(28, 512, batch_first=True)\n",
       "  (decoder): RNN(28, 512, batch_first=True)\n",
       "  (align1): Linear(in_features=10240, out_features=19, bias=True)\n",
       "  (linear): Linear(in_features=512, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('./models/new-rnn-ed39.pt')\n",
    "model.train()\n",
    "model.to(device)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff17339fb2f4cf694b19e683482df60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09cde837cab4e33bb9351f75f396579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1608.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type RNNEncoderDecoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc6c8c16e3142cfa6d8903486798e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1608.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31cd4a7b24914af2bdee978c490a88df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1608.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "agent_id = 0\n",
    "epoch = 3\n",
    "        \n",
    "# Use the nn package to define our loss function\n",
    "loss_fn=torch.nn.MSELoss()\n",
    "\n",
    "# Use the optim package to define an Optimizer\n",
    "\n",
    "learning_rate =1e-3\n",
    "#learning_rate =0.01\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "epoch_count = 0\n",
    "\n",
    "for i in trange(epoch):\n",
    "    iterator = tqdm(val_loader)\n",
    "    total = 0\n",
    "    count = 0\n",
    "    \n",
    "    for i_batch, sample_batch in enumerate(iterator):\n",
    "        inp, out, scene_ids, offsets = sample_batch\n",
    "        \n",
    "        x = inp.float()\n",
    "        y = out.float()\n",
    "\n",
    "        if cuda_status:\n",
    "            x.to(device)\n",
    "            y.to(device)\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        y_pred = None\n",
    "        # Forward pass: predict y by passing x to the model.    \n",
    "        y_pred = model(x, y, False)\n",
    "        #y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 4]))\n",
    "\n",
    "        for i in range(y_pred.shape[0]):\n",
    "            y_pred[i,:,:,0] += offsets[i][0]\n",
    "            y_pred[i,:,:,1] += offsets[i][1]\n",
    "\n",
    "        # Compute the loss.\n",
    "        loss = loss_fn(y_pred[:,6,:,0:2], y[:,6,:,:])\n",
    "        total += torch.sqrt(loss).item()\n",
    "\n",
    "        # Before backward pass, zero outgradients to clear buffers  \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient w.r.t modelparameters\n",
    "        loss.backward()\n",
    "\n",
    "        # makes an gradient descent step to update its parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        count += 1\n",
    "        \n",
    "        iterator.set_postfix(loss=total / count, curr=torch.sqrt(loss).item())\n",
    "    epoch_count += 1\n",
    "    torch.save(model, './models/new-rnn-ed4' + str(epoch_count) + '.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './models/16epoch-RNN-Encoder-Decoder-Attention-512-reoriented.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/new-rnn-ed5.pt')\n",
    "model.eval()\n",
    "model.to(device)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca28bd256bc4f95a2a4971f289ef5b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         ID                  v1                  v2                  v3  \\\n",
      "0     10002   1712.838623046875   339.1656494140625  1716.0286865234375   \n",
      "1     10015    724.650634765625      1231.646484375   720.4927978515625   \n",
      "2     10019   572.2623901367188  1243.7022705078125   571.4546508789062   \n",
      "3     10028  1687.5614013671875   315.5906066894531  1690.2152099609375   \n",
      "4      1003        2122.3046875     673.93017578125          2121.53125   \n",
      "...     ...                 ...                 ...                 ...   \n",
      "3195   9897  255.34808349609375   804.8645629882812  255.09701538085938   \n",
      "3196     99   585.4197998046875    1153.33447265625   584.4025268554688   \n",
      "3197   9905    1755.10107421875   442.7119445800781    1754.41357421875   \n",
      "3198   9910   571.9765014648438  1287.8658447265625   571.8234252929688   \n",
      "3199   9918   581.8795166015625  1164.8375244140625   585.0364990234375   \n",
      "\n",
      "                      v4                  v5                  v6  \\\n",
      "0     338.07733154296875    1715.82861328125   336.6117858886719   \n",
      "1     1231.2264404296875    721.619384765625   1232.158447265625   \n",
      "2     1244.6531982421875     571.05419921875   1243.601806640625   \n",
      "3     315.39678955078125  1690.5367431640625     313.33251953125   \n",
      "4      673.7347412109375   2117.644287109375       671.388671875   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   805.3817749023438  254.86090087890625    804.348876953125   \n",
      "3196  1153.6453857421875   583.4373779296875   1151.521240234375   \n",
      "3197     443.03466796875  1752.8314208984375  444.95660400390625   \n",
      "3198  1288.6500244140625   571.1260986328125      1287.837890625   \n",
      "3199  1162.8472900390625   585.6107177734375    1161.37646484375   \n",
      "\n",
      "                      v7                  v8                  v9  ...  \\\n",
      "0     1717.9334716796875  337.94195556640625    1718.80029296875  ...   \n",
      "1      719.6124267578125    1231.65478515625    720.253173828125  ...   \n",
      "2      572.0656127929688    1243.49658203125   571.9841918945312  ...   \n",
      "3         1691.873046875    315.058837890625  1691.8934326171875  ...   \n",
      "4         2116.779296875   670.5364990234375    2116.14111328125  ...   \n",
      "...                  ...                 ...                 ...  ...   \n",
      "3195  255.79527282714844   804.1331176757812  256.17706298828125  ...   \n",
      "3196   586.2713623046875  1149.7923583984375   586.0875244140625  ...   \n",
      "3197  1752.9312744140625  443.67840576171875   1753.911865234375  ...   \n",
      "3198   571.5181274414062   1287.746826171875   570.7252197265625  ...   \n",
      "3199   583.3387451171875  1160.7491455078125   584.1380615234375  ...   \n",
      "\n",
      "                     v51                 v52                 v53  \\\n",
      "0     1741.4388427734375   358.6151428222656   1742.692626953125   \n",
      "1      721.9429931640625   1228.479248046875     722.13818359375   \n",
      "2      576.6138305664062       1238.76171875   576.9484252929688   \n",
      "3     1708.0987548828125  329.33184814453125  1708.9407958984375   \n",
      "4      2089.629638671875   645.9292602539062    2088.02587890625   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   256.0555419921875   798.3749389648438   255.9117889404297   \n",
      "3196      586.6884765625  1135.0045166015625   586.5507202148438   \n",
      "3197  1747.9962158203125   452.4317626953125  1747.6649169921875   \n",
      "3198   565.9556884765625  1283.4830322265625    565.688720703125   \n",
      "3199   586.5932006835938  1136.3431396484375    586.623779296875   \n",
      "\n",
      "                     v54                 v55                 v56  \\\n",
      "0      359.6661071777344    1743.97509765625   360.7413024902344   \n",
      "1      1228.266845703125   722.3402709960938  1228.0489501953125   \n",
      "2      1238.510009765625   577.3262329101562    1238.11767578125   \n",
      "3     330.09356689453125  1709.8028564453125   330.8739013671875   \n",
      "4       644.369384765625    2086.55517578125   642.8959350585938   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   798.3256225585938   255.6377716064453   797.7876586914062   \n",
      "3196  1134.1116943359375   586.4662475585938  1133.0701904296875   \n",
      "3197   453.0129089355469  1747.3223876953125    453.612060546875   \n",
      "3198   1283.285888671875     565.43017578125   1283.083251953125   \n",
      "3199   1135.014892578125   586.7437133789062  1133.5765380859375   \n",
      "\n",
      "                     v57                v58                 v59  \\\n",
      "0     1745.2869873046875  361.8413391113281   1746.629150390625   \n",
      "1      722.5494995117188    1227.8251953125   722.7661743164062   \n",
      "2      577.7276000976562  1237.557861328125   578.1131591796875   \n",
      "3     1710.6856689453125  331.6734313964844       1711.58984375   \n",
      "4       2085.09912109375   641.357666015625   2083.661865234375   \n",
      "...                  ...                ...                 ...   \n",
      "3195  255.54205322265625  797.1868896484375  255.41433715820312   \n",
      "3196    586.415771484375   1132.04052734375   586.3881225585938   \n",
      "3197    1746.96826171875  454.2298583984375  1746.6346435546875   \n",
      "3198   565.1791381835938  1282.875244140625   564.9376220703125   \n",
      "3199      586.8720703125    1132.0634765625   587.0113525390625   \n",
      "\n",
      "                     v60  \n",
      "0     362.96685791015625  \n",
      "1     1227.5955810546875  \n",
      "2        1236.9287109375  \n",
      "3      332.4927062988281  \n",
      "4      639.7892456054688  \n",
      "...                  ...  \n",
      "3195   796.6046142578125  \n",
      "3196  1130.9913330078125  \n",
      "3197   454.8388366699219  \n",
      "3198  1282.6597900390625  \n",
      "3199    1130.51513671875  \n",
      "\n",
      "[3200 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Submission output\n",
    "writeCSV = True\n",
    "val_path = \"./new_val_in/new_val_in\"\n",
    "\n",
    "if writeCSV:\n",
    "    \n",
    "    dataset = ArgoverseDataset(data_path=val_path)\n",
    "    test_loader = DataLoader(dataset,batch_size=64, shuffle = False, collate_fn=test_collate, num_workers=0)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(tqdm(test_loader)):\n",
    "            inp, scene_ids, offsets = sample_batch\n",
    "\n",
    "            if cuda_status:\n",
    "                model = model.cuda()\n",
    "                x = inp.cuda()\n",
    "            else:\n",
    "                x = inp\n",
    "\n",
    "            y_pred = None\n",
    "\n",
    "            # Forward pass: predict y by passing x to the model.    \n",
    "            y_pred = model(x.float(), None, False)\n",
    "            y_pred = torch.reshape(y_pred, torch.Size([64, 7, 30, 4]))\n",
    "            \n",
    "            for i in range(y_pred.shape[0]):\n",
    "                y_pred[i,:,:,0] += offsets[i][0]\n",
    "                y_pred[i,:,:,1] += offsets[i][1]\n",
    "            \n",
    "            for i in range(64):\n",
    "                row = []\n",
    "                row.append(scene_ids[i].item())\n",
    "                \n",
    "                curr = y_pred[i]\n",
    "                \n",
    "                for j in range(30):\n",
    "                    row.append(str(curr[6][j][0].item()))\n",
    "                    row.append(str(curr[6][j][1].item()))\n",
    "                    \n",
    "                data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, columns = ['ID','v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','v11','v12','v13','v14','v15','v16','v17','v18','v19','v20','v21','v22','v23','v24','v25','v26','v27','v28','v29','v30','v31','v32','v33','v34','v35','v36','v37','v38','v39','v40','v41','v42','v43','v44','v45','v46','v47','v48','v49','v50','v51','v52','v53','v54','v55','v56','v57','v58','v59','v60'])\n",
    "    print(df)\n",
    "    df.to_csv('submission.csv', index=False)\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
