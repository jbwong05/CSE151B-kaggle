{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "\n",
    "cuda_status = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 64\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [scene['p_out'] for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, out, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "def test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMLinear(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = torch.nn.LSTM(240, 512, batch_first=True, num_layers=2)\n",
    "        self.linear1 = torch.nn.Linear(9728,3600)\n",
    "        self.linear2 = torch.nn.Linear(3600,3600)\n",
    "        self.linear3 = torch.nn.Linear(3600,3600)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0,2,1,3)\n",
    "        x = torch.flatten(x, start_dim=2)\n",
    "        x, (hidden, cell) = self.lstm(x)\n",
    "        # x: 64 x 19 x 512\n",
    "        x = self.relu(self.linear1(torch.flatten(x, start_dim=1)))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        x = torch.reshape(x, torch.Size([64, 60, 30, 2]))\n",
    "        return x\n",
    "\n",
    "model = LSTMLinear()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/1epochAdam.pt')\n",
    "model.train()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e8aea325a34cf8b8d8eb528414ae93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3218.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "485a2169a4ba4aaeb24c1733c6d9f3c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147.71859245395186\n",
      "142.06654473006324\r"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "agent_id = 0\n",
    "epoch = 5\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out, scene_ids, track_ids, agent_ids = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])\n",
    "        \n",
    "# Use the nn package to define our loss function\n",
    "loss_fn=torch.nn.MSELoss()\n",
    "\n",
    "# Use the optim package to define an Optimizer\n",
    "\n",
    "learning_rate =1e-3\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "iterator = tqdm(val_loader)\n",
    "\n",
    "for i in trange(epoch):\n",
    "    error = 0\n",
    "    count = 0\n",
    "    \n",
    "    for i_batch, sample_batch in enumerate(iterator):\n",
    "        inp, out, scene_ids, track_ids, agent_ids = sample_batch\n",
    "        \"\"\"TODO:\n",
    "          Deep learning model\n",
    "          training routine\n",
    "        \"\"\"\n",
    "        #x = torch.flatten(inp, start_dim=2)\n",
    "        \n",
    "        if i_batch >= 3216:\n",
    "            #show_sample_batch(sample_batch, agent_id)\n",
    "            #show_sample_batch([inp, y_pred.cpu().detach(), scene_ids, track_ids, agent_ids], agent_id)\n",
    "            continue\n",
    "\n",
    "        x = inp.float()\n",
    "        y = out.float()\n",
    "\n",
    "        if cuda_status:\n",
    "            #model = model.cuda()\n",
    "            #x = inp.cuda()\n",
    "            #y = out.cuda()\n",
    "            x.to(device)\n",
    "            y.to(device)\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        y_pred = None\n",
    "\n",
    "        # Forward pass: predict y by passing x to the model.    \n",
    "        y_pred = model(x)\n",
    "        #y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 4]))\n",
    "\n",
    "        # Compute the loss.\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        # Before backward pass, zero outgradients to clear buffers  \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient w.r.t modelparameters\n",
    "        loss.backward()\n",
    "\n",
    "        # makes an gradient descent step to update its parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        error += torch.sqrt(loss).item()\n",
    "        count += 1\n",
    "        \n",
    "        print(error / count, end='\\r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type LSTMLinear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, './models/5epoch2LSTMLinear.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/6epochmodel.pt')\n",
    "model.eval()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ac7254c98c4504b2e3832f4ba9efbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         ID                 v1                  v2                 v3  \\\n",
      "0     10002   2276.46826171875   677.6082763671875    2276.8564453125   \n",
      "1     10015  589.7469482421875      1986.361328125  588.9934692382812   \n",
      "2     10019  579.1820678710938   2005.784912109375  578.5496826171875   \n",
      "3     10028   2100.23388671875    714.942138671875    2098.7744140625   \n",
      "4      1003   2334.77783203125   867.2025146484375  2334.656494140625   \n",
      "...     ...                ...                 ...                ...   \n",
      "3195   9897  576.1163940429688     2165.9091796875  576.3636474609375   \n",
      "3196     99  575.6768798828125     2053.9052734375  575.4098510742188   \n",
      "3197   9905  2209.096923828125    761.178955078125      2208.30859375   \n",
      "3198   9910  683.2701416015625   2160.637939453125  682.6387329101562   \n",
      "3199   9918  702.4746704101562  1869.9754638671875  701.4088745117188   \n",
      "\n",
      "                      v4                 v5                 v6  \\\n",
      "0      677.9616088867188  2276.479248046875  680.3489379882812   \n",
      "1       1986.35107421875  589.7708740234375   1986.62939453125   \n",
      "2     2006.1939697265625  579.3704223632812  2005.289794921875   \n",
      "3      715.6804809570312    2099.8720703125  715.4869995117188   \n",
      "4      868.3413696289062  2333.113037109375  867.8526611328125   \n",
      "...                  ...                ...                ...   \n",
      "3195   2166.056396484375  575.3001708984375     2166.099609375   \n",
      "3196   2053.053466796875  574.4356079101562  2054.706787109375   \n",
      "3197   762.1798095703125       2209.6953125  763.3829345703125   \n",
      "3198    2161.67626953125  683.9429931640625  2162.129638671875   \n",
      "3199     1871.8935546875  701.9652099609375  1872.575439453125   \n",
      "\n",
      "                     v7                 v8                 v9  ...  \\\n",
      "0       2278.1591796875   680.949462890625  2277.545166015625  ...   \n",
      "1     590.1372680664062   1986.87646484375  589.2544555664062  ...   \n",
      "2     578.1056518554688   2004.66162109375      577.822265625  ...   \n",
      "3     2100.724853515625  716.2129516601562   2099.29345703125  ...   \n",
      "4         2336.20703125   868.696533203125  2334.414794921875  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "3195  576.7085571289062  2165.258056640625   575.815185546875  ...   \n",
      "3196  574.8468017578125    2054.2666015625  575.6780395507812  ...   \n",
      "3197  2209.205322265625  761.9054565429688  2208.254638671875  ...   \n",
      "3198    683.76220703125    2161.5458984375  684.4357299804688  ...   \n",
      "3199  703.3803100585938  1871.161376953125  702.1867065429688  ...   \n",
      "\n",
      "                    v51                 v52                v53  \\\n",
      "0         2282.12890625   682.5051879882812  2282.356201171875   \n",
      "1       589.21533203125    1984.75048828125  588.6607055664062   \n",
      "2     578.7672729492188   2004.026611328125  578.9286499023438   \n",
      "3     2105.346923828125   716.5173950195312   2105.38037109375   \n",
      "4       2337.9091796875      869.5771484375   2337.63818359375   \n",
      "...                 ...                 ...                ...   \n",
      "3195  575.9699096679688   2163.217529296875   575.967041015625   \n",
      "3196  575.6471557617188   2052.248291015625   573.532470703125   \n",
      "3197   2212.61376953125   765.3941040039062  2212.935791015625   \n",
      "3198    684.50244140625   2159.552001953125   685.887451171875   \n",
      "3199  702.9066162109375  1870.7037353515625  702.3609619140625   \n",
      "\n",
      "                     v54                v55                v56  \\\n",
      "0       681.154541015625    2281.7158203125  681.3912353515625   \n",
      "1     1985.6285400390625  589.4397583007812  1986.119873046875   \n",
      "2      2004.084716796875  578.0360717773438   2004.49853515625   \n",
      "3      717.4899291992188  2104.265380859375  717.8052978515625   \n",
      "4      868.3456420898438    2337.9462890625  870.3079833984375   \n",
      "...                  ...                ...                ...   \n",
      "3195     2162.8955078125  575.0167846679688  2162.027099609375   \n",
      "3196   2051.816650390625   573.987060546875  2053.200927734375   \n",
      "3197   764.9148559570312   2212.42724609375   765.008056640625   \n",
      "3198         2160.640625  684.2007446289062       2159.7265625   \n",
      "3199    1871.40478515625  702.4673461914062   1871.76025390625   \n",
      "\n",
      "                    v57                 v58                v59  \\\n",
      "0     2281.093505859375   681.0894165039062   2281.52099609375   \n",
      "1     589.3077392578125    1984.53369140625  588.7806396484375   \n",
      "2     579.1561279296875  2004.6868896484375  579.2181396484375   \n",
      "3     2103.584716796875   719.6752319335938   2103.22412109375   \n",
      "4         2336.95703125   869.9389038085938   2337.06201171875   \n",
      "...                 ...                 ...                ...   \n",
      "3195  574.7603759765625    2162.77978515625    575.44189453125   \n",
      "3196  574.0179443359375    2051.98193359375  574.5928955078125   \n",
      "3197  2213.384521484375   767.0863647460938   2214.06982421875   \n",
      "3198  683.3853149414062    2159.61865234375  684.7914428710938   \n",
      "3199  702.1219482421875   1871.435302734375  702.4413452148438   \n",
      "\n",
      "                     v60  \n",
      "0       683.196044921875  \n",
      "1      1985.248779296875  \n",
      "2     2004.0172119140625  \n",
      "3        718.64501953125  \n",
      "4      870.2196044921875  \n",
      "...                  ...  \n",
      "3195    2162.88818359375  \n",
      "3196      2050.876953125  \n",
      "3197   765.9503173828125  \n",
      "3198    2159.17919921875  \n",
      "3199  1869.9210205078125  \n",
      "\n",
      "[3200 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Submission output\n",
    "writeCSV = True\n",
    "val_path = \"./new_val_in/new_val_in\"\n",
    "\n",
    "if writeCSV:\n",
    "    \n",
    "    dataset = ArgoverseDataset(data_path=val_path)\n",
    "    test_loader = DataLoader(dataset,batch_size=batch_sz, shuffle = False, collate_fn=test_collate, num_workers=0)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(tqdm(test_loader)):\n",
    "            inp, scene_ids, track_ids, agent_ids = sample_batch\n",
    "\n",
    "            if cuda_status:\n",
    "                model = model.cuda()\n",
    "                x = inp.cuda()\n",
    "            else:\n",
    "                x = inp\n",
    "\n",
    "            y_pred = None\n",
    "\n",
    "            # Forward pass: predict y by passing x to the model.    \n",
    "            y_pred = model(x.float())\n",
    "            \n",
    "            for i in range(batch_sz):\n",
    "                row = []\n",
    "                row.append(scene_ids[i].item())\n",
    "                curr = y_pred[i]\n",
    "                \n",
    "                agent_id = agent_ids[i]\n",
    "                \n",
    "                for j in range(30):\n",
    "                    vehicle_index = 0\n",
    "                    found = False\n",
    "                    while not found:\n",
    "                        if track_ids[i][vehicle_index][j][0] == agent_id:\n",
    "                            found = True\n",
    "                        else:\n",
    "                            vehicle_index += 1\n",
    "\n",
    "                    row.append(str(curr[vehicle_index][j][0].item()))\n",
    "                    row.append(str(curr[vehicle_index][j][1].item()))\n",
    "                    \n",
    "                data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, columns = ['ID','v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','v11','v12','v13','v14','v15','v16','v17','v18','v19','v20','v21','v22','v23','v24','v25','v26','v27','v28','v29','v30','v31','v32','v33','v34','v35','v36','v37','v38','v39','v40','v41','v42','v43','v44','v45','v46','v47','v48','v49','v50','v51','v52','v53','v54','v55','v56','v57','v58','v59','v60'])\n",
    "    print(df)\n",
    "    df.to_csv('submission.csv', index=False)\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
