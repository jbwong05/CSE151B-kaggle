{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "\n",
    "cuda_status = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 64\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, out, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "def test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(38, 50),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(50, 50),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(50, 50),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(50, 60)\n",
    ")\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/1epochAdam.pt')\n",
    "model.train()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45637a10598e47a78bd67563ca7f0c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3218.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "agent_id = 0\n",
    "epoch = 3\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out, scene_ids, track_ids, agent_ids = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])\n",
    "        \n",
    "# Use the nn package to define our loss function\n",
    "loss_fn=torch.nn.MSELoss()\n",
    "\n",
    "# Use the optim package to define an Optimizer\n",
    "\n",
    "learning_rate =1e-3\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "iterator = tqdm(val_loader)\n",
    "\n",
    "for i in range(epoch):\n",
    "    \n",
    "    for i_batch, sample_batch in enumerate(iterator):\n",
    "        inp, out, scene_ids, track_ids, agent_ids = sample_batch\n",
    "        \"\"\"TODO:\n",
    "          Deep learning model\n",
    "          training routine\n",
    "        \"\"\"\n",
    "        \n",
    "        if i_batch >= 3216:\n",
    "            continue\n",
    "        \n",
    "        x = torch.flatten(inp, start_dim=2)\n",
    "\n",
    "        x = x.float()\n",
    "        y = out.float()\n",
    "\n",
    "        if cuda_status:\n",
    "            #model = model.cuda()\n",
    "            #x = inp.cuda()\n",
    "            #y = out.cuda()\n",
    "            x.to(device)\n",
    "            y.to(device)\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        y_pred = None\n",
    "\n",
    "        # Forward pass: predict y by passing x to the model.    \n",
    "        y_pred = model(x)\n",
    "        y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 2]))\n",
    "\n",
    "        # Compute the loss.\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        # Before backward pass, zero outgradients to clear buffers  \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient w.r.t modelparameters\n",
    "        loss.backward()\n",
    "\n",
    "        # makes an gradient descent step to update its parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iterator.set_postfix(loss=(torch.sqrt(loss)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './models/3epoch4layerlinearnovelocity.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/6epochmodel.pt')\n",
    "model.eval()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddc4cf3f08a4a40bf95366603d6020d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         ID                  v1                 v2                  v3  \\\n",
      "0     10002  1647.5677490234375  507.1723327636719  1650.9595947265625   \n",
      "1     10015   720.4800415039062  1231.090576171875    714.343994140625   \n",
      "2     10019    568.710205078125  1243.345458984375     564.02685546875   \n",
      "3     10028  1624.8817138671875  497.0760192871094  1628.9515380859375   \n",
      "4      1003   2119.873779296875  718.3843383789062       2096.80078125   \n",
      "...     ...                 ...                ...                 ...   \n",
      "3195   9897   252.6645050048828  806.5007934570312  252.45596313476562   \n",
      "3196     99   583.1381225585938    1158.0361328125   578.8228149414062   \n",
      "3197   9905   1717.566650390625  551.6574096679688  1714.1063232421875   \n",
      "3198   9910   572.2960205078125  1288.699951171875     567.47998046875   \n",
      "3199   9918   579.5357666015625   1172.76708984375   575.4274291992188   \n",
      "\n",
      "                      v4                  v5                  v6  \\\n",
      "0      553.5352783203125   1691.632568359375   534.4525146484375   \n",
      "1     1226.6468505859375   719.9945068359375  1223.5953369140625   \n",
      "2     1244.4190673828125   567.3427124023438    1238.48193359375   \n",
      "3      544.7019653320312  1670.1268310546875   524.4596557617188   \n",
      "4      730.1431884765625    2133.58544921875   735.2081298828125   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   806.0093383789062   253.1771240234375   806.4229736328125   \n",
      "3196     1158.8818359375     582.84033203125   1151.824951171875   \n",
      "3197   584.7800903320312  1749.7269287109375   575.2803955078125   \n",
      "3198  1289.6280517578125    570.606201171875    1284.24267578125   \n",
      "3199  1174.1475830078125   579.1888427734375   1166.647705078125   \n",
      "\n",
      "                      v7                  v8                  v9  ...  \\\n",
      "0     1689.3753662109375  482.77630615234375   1688.864990234375  ...   \n",
      "1      708.9796752929688   1249.848388671875     716.31982421875  ...   \n",
      "2      565.5098266601562  1250.6829833984375   567.7175903320312  ...   \n",
      "3      1667.772216796875   471.4537658691406   1667.102783203125  ...   \n",
      "4       2132.64111328125   704.7869262695312   2128.660400390625  ...   \n",
      "...                  ...                 ...                 ...  ...   \n",
      "3195     252.58740234375   805.7511596679688  251.84536743164062  ...   \n",
      "3196    575.376708984375  1171.1959228515625   578.8136596679688  ...   \n",
      "3197  1748.3870849609375   535.3533325195312  1747.8270263671875  ...   \n",
      "3198   570.8311157226562   1294.009521484375   572.8630981445312  ...   \n",
      "3199   572.2239990234375  1185.5823974609375   575.1934814453125  ...   \n",
      "\n",
      "                     v51                 v52                 v53  \\\n",
      "0     1661.9923095703125   524.8956298828125   1692.175048828125   \n",
      "1      719.0877685546875    1216.01123046875      701.9892578125   \n",
      "2      566.7520141601562    1239.04931640625   562.2061157226562   \n",
      "3     1640.2340087890625   515.8644409179688  1670.5914306640625   \n",
      "4       2107.65087890625   719.7191162109375   2126.605712890625   \n",
      "...                  ...                 ...                 ...   \n",
      "3195  252.26065063476562   805.3590698242188  253.98379516601562   \n",
      "3196   580.6312255859375   1151.487060546875   573.3411254882812   \n",
      "3197  1723.3370361328125   561.3507690429688  1749.3536376953125   \n",
      "3198   570.6961059570312  1284.8001708984375   566.8143310546875   \n",
      "3199   576.7693481445312   1167.137939453125   570.4275512695312   \n",
      "\n",
      "                    v54                 v55                 v56  \\\n",
      "0     538.9476318359375  1666.4027099609375       491.478515625   \n",
      "1      1224.75048828125   726.9290771484375  1223.8895263671875   \n",
      "2     1240.587646484375   568.4287719726562  1240.5570068359375   \n",
      "3     529.7621459960938  1644.8719482421875   480.7882385253906   \n",
      "4     731.1882934570312    2115.62158203125   710.9635009765625   \n",
      "...                 ...                 ...                 ...   \n",
      "3195     806.6474609375       253.041015625   805.7658081054688   \n",
      "3196    1156.7587890625   586.2090454101562     1153.4599609375   \n",
      "3197  574.8711547851562  1727.2618408203125   540.5051879882812   \n",
      "3198  1285.170654296875   570.8424682617188    1286.55810546875   \n",
      "3199  1171.905029296875   582.2008056640625  1168.5135498046875   \n",
      "\n",
      "                     v57                 v58                 v59  \\\n",
      "0     1685.7738037109375   531.6148681640625  1715.5682373046875   \n",
      "1      720.9963989257812     1227.5498046875   709.3116455078125   \n",
      "2      568.3267822265625   1244.415771484375    567.180419921875   \n",
      "3     1664.4295654296875   522.4635009765625  1694.7564697265625   \n",
      "4      2128.029052734375    715.149658203125   2134.777099609375   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   252.9270782470703    805.167724609375   251.7132568359375   \n",
      "3196   585.0687255859375    1156.34033203125   578.7638549804688   \n",
      "3197  1743.5733642578125   566.4473266601562  1765.9757080078125   \n",
      "3198   570.9368286132812  1290.9761962890625   571.6326293945312   \n",
      "3199   581.6598510742188       1171.09765625   575.9309692382812   \n",
      "\n",
      "                     v60  \n",
      "0      534.7606811523438  \n",
      "1     1212.0006103515625  \n",
      "2     1234.3089599609375  \n",
      "3      525.8182983398438  \n",
      "4          726.732421875  \n",
      "...                  ...  \n",
      "3195    806.218505859375  \n",
      "3196    1144.24658203125  \n",
      "3197   569.8941650390625  \n",
      "3198  1281.4168701171875  \n",
      "3199  1159.4124755859375  \n",
      "\n",
      "[3200 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Submission output\n",
    "writeCSV = True\n",
    "val_path = \"./new_val_in/new_val_in\"\n",
    "\n",
    "if writeCSV:\n",
    "    \n",
    "    dataset = ArgoverseDataset(data_path=val_path)\n",
    "    test_loader = DataLoader(dataset,batch_size=batch_sz, shuffle = False, collate_fn=test_collate, num_workers=0)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(tqdm(test_loader)):\n",
    "            inp, scene_ids, track_ids, agent_ids = sample_batch\n",
    "            inp = torch.flatten(inp, start_dim=2)\n",
    "\n",
    "            if cuda_status:\n",
    "                model = model.cuda()\n",
    "                x = inp.cuda()\n",
    "            else:\n",
    "                x = inp\n",
    "\n",
    "            y_pred = None\n",
    "\n",
    "            # Forward pass: predict y by passing x to the model.    \n",
    "            y_pred = model(x.float())\n",
    "            y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 2]))\n",
    "            \n",
    "            for i in range(batch_sz):\n",
    "                row = []\n",
    "                row.append(scene_ids[i].item())\n",
    "                curr = y_pred[i]\n",
    "                \n",
    "                agent_id = agent_ids[i]\n",
    "                \n",
    "                for j in range(30):\n",
    "                    vehicle_index = 0\n",
    "                    found = False\n",
    "                    while not found:\n",
    "                        if track_ids[i][vehicle_index][j][0] == agent_id:\n",
    "                            found = True\n",
    "                        else:\n",
    "                            vehicle_index += 1\n",
    "\n",
    "                    row.append(str(curr[vehicle_index][j][0].item()))\n",
    "                    row.append(str(curr[vehicle_index][j][1].item()))\n",
    "                    \n",
    "                data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, columns = ['ID','v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','v11','v12','v13','v14','v15','v16','v17','v18','v19','v20','v21','v22','v23','v24','v25','v26','v27','v28','v29','v30','v31','v32','v33','v34','v35','v36','v37','v38','v39','v40','v41','v42','v43','v44','v45','v46','v47','v48','v49','v50','v51','v52','v53','v54','v55','v56','v57','v58','v59','v60'])\n",
    "    print(df)\n",
    "    df.to_csv('submission.csv', index=False)\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
