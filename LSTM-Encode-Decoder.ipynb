{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy as np\n",
    "import pickle\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "\n",
    "cuda_status = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 512\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [np.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [np.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    car_mask = [scene['car_mask'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    car_mask = torch.LongTensor(car_mask)\n",
    "\n",
    "    num_cars = np.zeros((inp.shape[0]))\n",
    "    offsets = np.zeros((inp.shape[0], 2))\n",
    "    \n",
    "    for i in range(inp.shape[0]):\n",
    "        num_vehicles = 0\n",
    "        for j in range(60):\n",
    "            if car_mask[i][j][0] == 1:\n",
    "                num_vehicles += 1\n",
    "        num_cars[i] = num_vehicles\n",
    "        \n",
    "        agent_id = agent_ids[i]\n",
    "        vehicle_index = 0\n",
    "        found = False\n",
    "        while not found:\n",
    "            if track_ids[i][vehicle_index][0][0] == agent_id:\n",
    "                found = True\n",
    "            else:\n",
    "                vehicle_index += 1\n",
    "        start_x = inp[i][vehicle_index][0][0]\n",
    "        start_y = inp[i][vehicle_index][0][1]\n",
    "        \n",
    "        offsets[i][0] = start_x\n",
    "        offsets[i][1] = start_y\n",
    "        \n",
    "        inp[i,0:num_vehicles,:,0] -= start_x\n",
    "        inp[i,0:num_vehicles,:,1] -= start_y\n",
    "        #out[i,0:num_vehicles,:,0] -= start_x\n",
    "        #out[i,0:num_vehicles,:,1] -= start_y\n",
    "        \n",
    "    offsets = torch.LongTensor(offsets)\n",
    "    num_cars = torch.LongTensor(num_cars)\n",
    "\n",
    "    return [inp, out, scene_ids, track_ids, agent_ids, car_mask, num_cars, offsets]\n",
    "\n",
    "def test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [np.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    car_mask = [scene['car_mask'] for scene in batch]\n",
    "    \n",
    "    inp = torch.FloatTensor(inp)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    car_mask = torch.LongTensor(car_mask)\n",
    "    \n",
    "    num_cars = np.zeros((inp.shape[0]))\n",
    "    offsets = np.zeros((inp.shape[0], 2))\n",
    "    \n",
    "    for i in range(inp.shape[0]):\n",
    "        num_vehicles = 0\n",
    "        for j in range(60):\n",
    "            if car_mask[i][j][0] == 1:\n",
    "                num_vehicles += 1\n",
    "        num_cars[i] = num_vehicles\n",
    "        \n",
    "        agent_id = agent_ids[i]\n",
    "        vehicle_index = 0\n",
    "        found = False\n",
    "        while not found:\n",
    "            if track_ids[i][vehicle_index][0][0] == agent_id:\n",
    "                found = True\n",
    "            else:\n",
    "                vehicle_index += 1\n",
    "        start_x = inp[i][vehicle_index][0][0]\n",
    "        start_y = inp[i][vehicle_index][0][1]\n",
    "        \n",
    "        offsets[i][0] = start_x\n",
    "        offsets[i][1] = start_y\n",
    "        \n",
    "        inp[i,0:num_vehicles,:,0] -= start_x\n",
    "        inp[i,0:num_vehicles,:,1] -= start_y\n",
    "        \n",
    "    offsets = torch.LongTensor(offsets)\n",
    "    num_cars = torch.LongTensor(num_cars)\n",
    "    return [inp, scene_ids, track_ids, agent_ids, car_mask, num_cars, offsets]\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMEncoderDecoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.LSTM(240, hidden_size=512, batch_first=True)\n",
    "        self.decoder = torch.nn.LSTM(240, hidden_size=512, batch_first=True)\n",
    "        \n",
    "        self.align1 = torch.nn.Linear(10240, 19)\n",
    "        self.align2 = torch.nn.Linear(10240, 19)\n",
    "        #self.attn = Attention(512,512)\n",
    "        \n",
    "        self.linear = torch.nn.Linear(512, 240)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # batch_szx60x19x4\n",
    "        x = x.permute(0,2,1,3)\n",
    "        x = torch.flatten(x, start_dim=2)\n",
    "        # batch_szx19x240\n",
    "        output, (hidden, cell) = self.encoder(x)\n",
    "        \n",
    "        outputs = torch.zeros(30,batch_sz,60,4).to(device).cuda()\n",
    "        dec_out, (dec_hidden, dec_cell) = self.decoder(torch.full((batch_sz,1,240), -1).to(device).cuda(), (hidden, cell))\n",
    "        # dec_out: batch_szx1x512\n",
    "        dec_out = dec_out.permute(1,0,2).squeeze(0)\n",
    "        # batch_szx512\n",
    "        dec_out = self.linear(dec_out)\n",
    "        # batch_sz x 240\n",
    "        next_in = dec_out.unsqueeze(1)\n",
    "        outputs[0] = torch.reshape(dec_out, torch.Size([batch_sz, 60, 4]))\n",
    "        \n",
    "        # output: batch_szx19x512\n",
    "        # h_n: 1xbatch_szx512\n",
    "        prevHidState = hidden.permute(1,0,2)\n",
    "        prevCellState = cell.permute(1,0,2)\n",
    "        inputStates = output\n",
    "        \n",
    "        for i in range(1,30):\n",
    "            hidAlignment = self.align1(torch.flatten(torch.cat((inputStates, prevHidState), 1), start_dim=1))\n",
    "            cellAlignment = self.align2(torch.flatten(torch.cat((inputStates, prevCellState), 1), start_dim=1))\n",
    "            #batch_szx19\n",
    "            \n",
    "            hidAttention = torch.nn.functional.softmax(hidAlignment, dim=1)\n",
    "            hidAttention = hidAttention.unsqueeze(1)\n",
    "            cellAttention = torch.nn.functional.softmax(cellAlignment, dim=1)\n",
    "            cellAttention = cellAttention.unsqueeze(1)\n",
    "            #batch_szx1x19\n",
    "            \n",
    "            new_hidden = torch.bmm(hidAttention, inputStates)\n",
    "            new_hidden = new_hidden.permute(1,0,2)\n",
    "            new_cell = torch.bmm(cellAttention, inputStates)\n",
    "            new_cell = new_cell.permute(1,0,2)\n",
    "            #1xbatch_szx512\n",
    "             \n",
    "            dec_out, (dec_hidden, dec_cell) = self.decoder(next_in, (new_hidden, new_cell))\n",
    "            # dec_out: batch_szx1x512\n",
    "            dec_out = dec_out.permute(1,0,2).squeeze(0)\n",
    "            # batch_szx512\n",
    "            dec_out = self.linear(dec_out)\n",
    "            # batch_sz x 240\n",
    "            next_in = dec_out.unsqueeze(1)\n",
    "            outputs[i] = torch.reshape(dec_out, torch.Size([batch_sz, 60, 4]))\n",
    "            \n",
    "            prevHidState = dec_hidden.permute(1,0,2)\n",
    "            prevCellState = dec_cell.permute(1,0,2)\n",
    "        \n",
    "        return outputs.permute(1,2,0,3)\n",
    "\n",
    "model = LSTMEncoderDecoder()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd18d829e4340c090a1e050dfa51b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896f77443bbf40488bb41a974377b397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=402.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02fdb230f92464fb261eb5de0bf466d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=402.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e487e35dc042a0bb1371fdd19d002f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=402.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "agent_id = 0\n",
    "epoch = 3\n",
    "        \n",
    "# Use the nn package to define our loss function\n",
    "loss_fn=torch.nn.MSELoss()\n",
    "\n",
    "# Use the optim package to define an Optimizer\n",
    "\n",
    "learning_rate =1e-3\n",
    "#learning_rate =0.01\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for i in trange(epoch):\n",
    "    iterator = tqdm(val_loader)\n",
    "    total = 0\n",
    "    count = 0\n",
    "    \n",
    "    for i_batch, sample_batch in enumerate(iterator):\n",
    "        inp, out, scene_ids, track_ids, agent_ids, car_mask, num_cars, offsets = sample_batch\n",
    "        \n",
    "        x = inp.float()\n",
    "        y = out.float()\n",
    "\n",
    "        if cuda_status:\n",
    "            x.to(device)\n",
    "            y.to(device)\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        y_pred = None\n",
    "        # Forward pass: predict y by passing x to the model.    \n",
    "        y_pred = model(x)\n",
    "        #y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 4]))\n",
    "        \n",
    "        for i in range(y_pred.shape[0]):\n",
    "            y_pred[i,0:num_cars[i],:,0] += offsets[i][0]\n",
    "            y_pred[i,0:num_cars[i],:,1] += offsets[i][1]\n",
    "\n",
    "\n",
    "        # Compute the loss.\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        total += torch.sqrt(loss).item()\n",
    "\n",
    "        # Before backward pass, zero outgradients to clear buffers  \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient w.r.t modelparameters\n",
    "        loss.backward()\n",
    "\n",
    "        # makes an gradient descent step to update its parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        iterator.set_postfix(loss=total / count, curr=torch.sqrt(loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './models/23epoch-LSTM-Encode-Decode.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/6epochmodel.pt')\n",
    "model.eval()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Submission output\n",
    "writeCSV = True\n",
    "val_path = \"./new_val_in/new_val_in\"\n",
    "\n",
    "if writeCSV:\n",
    "    \n",
    "    dataset = ArgoverseDataset(data_path=val_path)\n",
    "    test_loader = DataLoader(dataset,batch_size=batch_sz, shuffle = False, collate_fn=test_collate, num_workers=0)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(tqdm(test_loader)):\n",
    "            inp, scene_ids, track_ids, agent_ids = sample_batch\n",
    "\n",
    "            x = inp.float().cuda()\n",
    "            y_pred = None\n",
    "\n",
    "            # Forward pass: predict y by passing x to the model.    \n",
    "            y_pred = model(x, x, False)\n",
    "            y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 4]))\n",
    "            \n",
    "            for i in range(batch_sz):\n",
    "                row = []\n",
    "                row.append(scene_ids[i].item())\n",
    "                curr = y_pred[i]\n",
    "                \n",
    "                agent_id = agent_ids[i]\n",
    "                \n",
    "                for j in range(30):\n",
    "                    vehicle_index = 0\n",
    "                    found = False\n",
    "                    while not found:\n",
    "                        if track_ids[i][vehicle_index][j][0] == agent_id:\n",
    "                            found = True\n",
    "                        else:\n",
    "                            vehicle_index += 1\n",
    "\n",
    "                    row.append(str(curr[vehicle_index][j][0].item()))\n",
    "                    row.append(str(curr[vehicle_index][j][1].item()))\n",
    "                    \n",
    "                data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, columns = ['ID','v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','v11','v12','v13','v14','v15','v16','v17','v18','v19','v20','v21','v22','v23','v24','v25','v26','v27','v28','v29','v30','v31','v32','v33','v34','v35','v36','v37','v38','v39','v40','v41','v42','v43','v44','v45','v46','v47','v48','v49','v50','v51','v52','v53','v54','v55','v56','v57','v58','v59','v60'])\n",
    "    print(df)\n",
    "    df.to_csv('submission.csv', index=False)\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
