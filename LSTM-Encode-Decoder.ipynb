{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "\n",
    "cuda_status = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 64\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, out, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "def test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMEncoderDecoder(torch.nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.encoder = torch.nn.LSTM(240, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
    "        self.decoder = torch.nn.LSTM(240, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
    "        self.linear = torch.nn.Linear(512, 240)\n",
    "\n",
    "    def forward(self, x, y, train = False):\n",
    "        # x: 64 x 60 x 19 x 4\n",
    "        # y: 64 x 60 x 30 x 4\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        x = torch.flatten(x, start_dim=2)\n",
    "        # 64 x 19 x 240\n",
    "        y = y.permute(0, 2, 1, 3)\n",
    "        y = torch.flatten(y, start_dim=2)\n",
    "        # 64 x 30 x 240\n",
    "        \n",
    "        inp = None\n",
    "        if train:\n",
    "            inp = y[:,0,:]\n",
    "        else:\n",
    "            inp = x[:,18,:]\n",
    "        \n",
    "        outputs = torch.zeros(30, 64, 60, 4).to(self.device)\n",
    "        \n",
    "        # encoder\n",
    "        output, (hidden, cell) = self.encoder(x)\n",
    "        # 64 x 19 x 512\n",
    "        \n",
    "        # decoder\n",
    "        \n",
    "        for i in range(30):\n",
    "            # 64 x 1 x 240\n",
    "            inp = torch.reshape(inp, torch.Size([batch_sz, 1, inp.shape[1]]))\n",
    "            output, (hidden, cell) = self.decoder(inp, (hidden, cell))\n",
    "            # 64 x 1 x 512\n",
    "            output = torch.flatten(output, start_dim=1)\n",
    "            output = self.linear(output)\n",
    "            # 64 x 240\n",
    "            \n",
    "            if train:\n",
    "                inp = y[:,i,:]\n",
    "            else:\n",
    "                inp = output\n",
    "            \n",
    "            output = torch.reshape(output, torch.Size([batch_sz, 60, 4]))\n",
    "            # 64 x 60 x 4\n",
    "            outputs[i] = output\n",
    "        \n",
    "        # 30 x 64 x 60 x 4\n",
    "        outputs = outputs.permute(1, 2, 0, 3)\n",
    "        # 64 x 60 x 30 x 4\n",
    "        return outputs\n",
    "\n",
    "model = LSTMEncoderDecoder(device)\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/1epochAdam.pt')\n",
    "model.train()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661126122de0452faa5d10a310e85791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3218.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d473ca80994ee5920a07153c45a727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171.16249344004922\n",
      "77.754941219121067\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "agent_id = 0\n",
    "epoch = 16\n",
    "        \n",
    "# Use the nn package to define our loss function\n",
    "loss_fn=torch.nn.MSELoss()\n",
    "\n",
    "# Use the optim package to define an Optimizer\n",
    "\n",
    "learning_rate =1e-3\n",
    "#learning_rate =0.01\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "iterator = tqdm(val_loader)\n",
    "\n",
    "for i in trange(epoch):\n",
    "    error = 0\n",
    "    count = 0\n",
    "    \n",
    "    for i_batch, sample_batch in enumerate(iterator):\n",
    "        inp, out, scene_ids, track_ids, agent_ids = sample_batch\n",
    "        \"\"\"TODO:\n",
    "          Deep learning model\n",
    "          training routine\n",
    "        \"\"\"\n",
    "        if i_batch >= 3216:\n",
    "            continue\n",
    "        \n",
    "        x = inp.float()\n",
    "        y = out.float()\n",
    "\n",
    "        if cuda_status:\n",
    "            x.to(device)\n",
    "            y.to(device)\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        y_pred = None\n",
    "        # Forward pass: predict y by passing x to the model.    \n",
    "        y_pred = model(x, y, True)\n",
    "        #y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 4]))\n",
    "\n",
    "        # Compute the loss.\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        # Before backward pass, zero outgradients to clear buffers  \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient w.r.t modelparameters\n",
    "        loss.backward()\n",
    "\n",
    "        # makes an gradient descent step to update its parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        error += torch.sqrt(loss).item()\n",
    "        count += 1\n",
    "        \n",
    "        print(error / count, end='\\r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type LSTMEncoderDecoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, './models/23epoch-LSTM-Encode-Decode.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/6epochmodel.pt')\n",
    "model.eval()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561d7f4b9a1049318dd8851515d3aff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         ID                  v1                  v2                 v3  \\\n",
      "0     10002       1676.03515625       620.259765625    1676.9052734375   \n",
      "1     10015    584.951416015625  1701.2432861328125     698.5341796875   \n",
      "2     10019   609.7313232421875   2181.768310546875  621.0794067382812   \n",
      "3     10028     2417.8994140625   779.8427124023438  2368.146728515625   \n",
      "4      1003  1511.8406982421875   635.0143432617188  1526.433349609375   \n",
      "...     ...                 ...                 ...                ...   \n",
      "3195   9897   623.3502197265625    2391.37744140625  640.6844482421875   \n",
      "3196     99   617.7164916992188   2015.798583984375  689.4088745117188   \n",
      "3197   9905   2421.564697265625   977.5608520507812  2449.082763671875   \n",
      "3198   9910   525.3984985351562   2119.778076171875  691.9625854492188   \n",
      "3199   9918   690.8410034179688   2159.264892578125  740.9632568359375   \n",
      "\n",
      "                     v4                  v5                  v6  \\\n",
      "0     617.7557983398438  1659.8822021484375   635.2033081054688   \n",
      "1       1635.7607421875   707.2855224609375   1673.086181640625   \n",
      "2     2075.125244140625        623.68359375   2006.826904296875   \n",
      "3     745.2670288085938    2360.10205078125   755.4635009765625   \n",
      "4      659.947021484375   1506.859130859375   653.4964599609375   \n",
      "...                 ...                 ...                 ...   \n",
      "3195  2203.164306640625   666.0848999023438   2171.022705078125   \n",
      "3196   1905.29052734375   764.1654052734375  1923.0728759765625   \n",
      "3197  924.0285034179688     2463.4287109375   959.2402954101562   \n",
      "3198   2010.16162109375        691.99609375  1977.0057373046875   \n",
      "3199  2202.318603515625   726.6200561523438   2267.527587890625   \n",
      "\n",
      "                      v7                  v8                  v9  ...  \\\n",
      "0     1678.0650634765625   660.1771240234375  1698.9610595703125  ...   \n",
      "1      708.9229125976562  1698.5279541015625   665.7401123046875  ...   \n",
      "2      617.4041137695312  1984.9945068359375   618.6511840820312  ...   \n",
      "3         2351.763671875   741.0127563476562   2348.234130859375  ...   \n",
      "4      1493.331298828125   652.4644165039062    1485.12744140625  ...   \n",
      "...                  ...                 ...                 ...  ...   \n",
      "3195       680.384765625    2225.99267578125   687.9830932617188  ...   \n",
      "3196     782.77197265625   1980.935791015625   788.2501220703125  ...   \n",
      "3197           2466.4375   990.7767944335938      2450.888671875  ...   \n",
      "3198   682.8448486328125  1976.1900634765625    685.867919921875  ...   \n",
      "3199   701.1047973632812   2297.925537109375   696.9837036132812  ...   \n",
      "\n",
      "                     v51                 v52                 v53  \\\n",
      "0     1602.2479248046875   584.5236206054688  1598.8927001953125   \n",
      "1      692.6285400390625    1679.11767578125    710.881103515625   \n",
      "2      640.3463745117188   1966.163818359375   636.1832885742188   \n",
      "3      2373.096923828125     756.80322265625   2370.959716796875   \n",
      "4     1580.0247802734375   709.9229125976562   1546.682373046875   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   687.7869873046875   1978.372802734375   688.7465209960938   \n",
      "3196   794.2755737304688  2021.4356689453125    794.778076171875   \n",
      "3197     2462.9560546875   931.6130981445312    2474.55517578125   \n",
      "3198   748.2922973632812  1957.9764404296875   760.0020751953125   \n",
      "3199   665.3284912109375   2301.146240234375     655.12744140625   \n",
      "\n",
      "                    v54                 v55                 v56  \\\n",
      "0      574.987548828125   1608.400634765625   585.2817993164062   \n",
      "1     1633.681884765625   695.7601318359375   1662.178955078125   \n",
      "2     1958.847412109375   636.1668701171875     1978.8798828125   \n",
      "3      759.502197265625    2374.61669921875   759.4596557617188   \n",
      "4     695.7758178710938  1560.1644287109375   709.1249389648438   \n",
      "...                 ...                 ...                 ...   \n",
      "3195  1952.013916015625   708.1415405273438    1994.54150390625   \n",
      "3196    2046.0654296875   756.0382080078125    2000.82275390625   \n",
      "3197  913.7468872070312      2470.697265625   913.8484497070312   \n",
      "3198  1970.082275390625    751.525634765625  1977.7698974609375   \n",
      "3199  2328.325439453125   650.5457763671875   2333.308837890625   \n",
      "\n",
      "                     v57                 v58                 v59  \\\n",
      "0     1621.9735107421875      611.5673828125  1643.7730712890625   \n",
      "1      682.2838134765625   1669.741455078125      681.9052734375   \n",
      "2      633.6001586914062  1987.9967041015625   637.1255493164062   \n",
      "3        2371.3720703125   755.4175415039062   2366.554931640625   \n",
      "4        1572.1728515625   702.3074340820312      1519.509765625   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   711.2059326171875  2002.1077880859375   708.5655517578125   \n",
      "3196   773.4730834960938      1978.220703125   762.0941772460938   \n",
      "3197    2467.45458984375   941.2299194335938     2481.1767578125   \n",
      "3198   715.0465698242188  1950.1602783203125   729.1115112304688   \n",
      "3199    668.382568359375     2348.4736328125   697.9627685546875   \n",
      "\n",
      "                    v60  \n",
      "0     621.9159545898438  \n",
      "1      1665.95751953125  \n",
      "2      1973.54931640625  \n",
      "3      775.929443359375  \n",
      "4     646.8722534179688  \n",
      "...                 ...  \n",
      "3195          2046.0625  \n",
      "3196   1971.73095703125  \n",
      "3197  960.9661254882812  \n",
      "3198   1966.98974609375  \n",
      "3199  2257.919189453125  \n",
      "\n",
      "[3200 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Submission output\n",
    "writeCSV = True\n",
    "val_path = \"./new_val_in/new_val_in\"\n",
    "\n",
    "if writeCSV:\n",
    "    \n",
    "    dataset = ArgoverseDataset(data_path=val_path)\n",
    "    test_loader = DataLoader(dataset,batch_size=batch_sz, shuffle = False, collate_fn=test_collate, num_workers=0)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(tqdm(test_loader)):\n",
    "            inp, scene_ids, track_ids, agent_ids = sample_batch\n",
    "\n",
    "            x = inp.float().cuda()\n",
    "            y_pred = None\n",
    "\n",
    "            # Forward pass: predict y by passing x to the model.    \n",
    "            y_pred = model(x, x, False)\n",
    "            y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 4]))\n",
    "            \n",
    "            for i in range(batch_sz):\n",
    "                row = []\n",
    "                row.append(scene_ids[i].item())\n",
    "                curr = y_pred[i]\n",
    "                \n",
    "                agent_id = agent_ids[i]\n",
    "                \n",
    "                for j in range(30):\n",
    "                    vehicle_index = 0\n",
    "                    found = False\n",
    "                    while not found:\n",
    "                        if track_ids[i][vehicle_index][j][0] == agent_id:\n",
    "                            found = True\n",
    "                        else:\n",
    "                            vehicle_index += 1\n",
    "\n",
    "                    row.append(str(curr[vehicle_index][j][0].item()))\n",
    "                    row.append(str(curr[vehicle_index][j][1].item()))\n",
    "                    \n",
    "                data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, columns = ['ID','v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','v11','v12','v13','v14','v15','v16','v17','v18','v19','v20','v21','v22','v23','v24','v25','v26','v27','v28','v29','v30','v31','v32','v33','v34','v35','v36','v37','v38','v39','v40','v41','v42','v43','v44','v45','v46','v47','v48','v49','v50','v51','v52','v53','v54','v55','v56','v57','v58','v59','v60'])\n",
    "    print(df)\n",
    "    df.to_csv('submission.csv', index=False)\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
