{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "\n",
    "cuda_status = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 64\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, out, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "def test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(76, 98),\n",
    "    torch.nn.Dropout(p=0.4),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(98, 98),\n",
    "    torch.nn.Dropout(p=0.4),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(98, 120)\n",
    ")\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/1epochAdam.pt')\n",
    "model.train()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257807d18ad147d4bedf42dfb9fa2ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3218.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77572588bbb4455e9b4cf56ea61043ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.793251037597666\n",
      "75.184745788574222\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "agent_id = 0\n",
    "epoch = 3\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out, scene_ids, track_ids, agent_ids = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])\n",
    "        \n",
    "# Use the nn package to define our loss function\n",
    "loss_fn=torch.nn.MSELoss()\n",
    "\n",
    "# Use the optim package to define an Optimizer\n",
    "\n",
    "learning_rate =1e-3\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "iterator = tqdm(val_loader)\n",
    "\n",
    "for i in trange(epoch):\n",
    "    \n",
    "    for i_batch, sample_batch in enumerate(iterator):\n",
    "        inp, out, scene_ids, track_ids, agent_ids = sample_batch\n",
    "        \"\"\"TODO:\n",
    "          Deep learning model\n",
    "          training routine\n",
    "        \"\"\"\n",
    "        if i_batch >= 3216:\n",
    "            #show_sample_batch(sample_batch, agent_id)\n",
    "            #show_sample_batch([inp, y_pred.cpu().detach(), scene_ids, track_ids, agent_ids], agent_id)\n",
    "            continue\n",
    "        \n",
    "        x = torch.flatten(inp, start_dim=2)\n",
    "\n",
    "        x = x.float()\n",
    "        y = out.float()\n",
    "\n",
    "        if cuda_status:\n",
    "            #model = model.cuda()\n",
    "            #x = inp.cuda()\n",
    "            #y = out.cuda()\n",
    "            x.to(device)\n",
    "            y.to(device)\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        y_pred = None\n",
    "\n",
    "        # Forward pass: predict y by passing x to the model.    \n",
    "        y_pred = model(x)\n",
    "        y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 4]))\n",
    "\n",
    "        # Compute the loss.\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        # Before backward pass, zero outgradients to clear buffers  \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient w.r.t modelparameters\n",
    "        loss.backward()\n",
    "\n",
    "        # makes an gradient descent step to update its parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(torch.sqrt(loss).item(), end='\\r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './models/3epochlinear14rsm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/6epochmodel.pt')\n",
    "model.eval()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91e996a09a04137b5d9bcda1fd1fca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         ID                  v1                  v2                  v3  \\\n",
      "0     10002    1700.74853515625   468.5499572753906  1760.0201416015625   \n",
      "1     10015   734.8445434570312  1222.9210205078125   738.3655395507812   \n",
      "2     10019   581.3577270507812  1242.6278076171875   583.8421020507812   \n",
      "3     10028  1680.9898681640625   459.0301818847656  1739.6243896484375   \n",
      "4      1003    2111.05224609375     705.78955078125    2118.93994140625   \n",
      "...     ...                 ...                 ...                 ...   \n",
      "3195   9897  258.55511474609375    804.961669921875   258.2571105957031   \n",
      "3196     99   594.2051391601562  1143.0643310546875   597.2813110351562   \n",
      "3197   9905   1743.445068359375      541.6376953125  1768.0816650390625   \n",
      "3198   9910    579.650634765625  1284.7750244140625   581.1560668945312   \n",
      "3199   9918   591.4434204101562     1148.4873046875   594.4744262695312   \n",
      "\n",
      "                     v4                  v5                  v6  \\\n",
      "0     497.4622497558594   1712.611083984375   461.0358581542969   \n",
      "1       1214.4853515625   742.0555419921875   1216.141357421875   \n",
      "2      1237.91162109375   586.6870727539062       1238.95703125   \n",
      "3       485.78857421875    1686.44970703125   446.4631652832031   \n",
      "4         716.072265625          2113.15625     701.21826171875   \n",
      "...                 ...                 ...                 ...   \n",
      "3195  804.4992065429688   259.6022644042969   804.8406982421875   \n",
      "3196  1137.338623046875    599.939697265625  1138.1712646484375   \n",
      "3197   554.949951171875  1748.5174560546875   529.4028930664062   \n",
      "3198  1280.476806640625   584.0692749023438  1281.4613037109375   \n",
      "3199    1142.7060546875   596.9940795898438  1143.2843017578125   \n",
      "\n",
      "                      v7                  v8                 v9  ...  \\\n",
      "0       1750.60107421875   471.6243896484375   1736.12158203125  ...   \n",
      "1      734.7611083984375    1212.85595703125  734.6617431640625  ...   \n",
      "2       581.446044921875   1235.972900390625  582.1195678710938  ...   \n",
      "3      1729.008056640625   461.1617736816406   1711.72998046875  ...   \n",
      "4          2127.27734375   695.8866577148438   2117.39208984375  ...   \n",
      "...                  ...                 ...                ...  ...   \n",
      "3195  258.22711181640625   803.5599365234375    259.17041015625  ...   \n",
      "3196     594.36083984375    1135.66259765625  594.9632568359375  ...   \n",
      "3197  1777.4088134765625   533.9298095703125   1762.14990234375  ...   \n",
      "3198   579.3362426757812   1278.760009765625  579.9043579101562  ...   \n",
      "3199   591.5015869140625  1141.1510009765625  592.5764770507812  ...   \n",
      "\n",
      "                     v51                 v52                 v53  \\\n",
      "0     1768.0067138671875   506.1151428222656  1769.2725830078125   \n",
      "1       737.133544921875  1217.2369384765625   733.1480102539062   \n",
      "2      583.9781494140625       1238.91796875    580.939208984375   \n",
      "3     1738.1373291015625   485.1606140136719     1738.0322265625   \n",
      "4       2095.66162109375   677.0951538085938    2094.45751953125   \n",
      "...                  ...                 ...                 ...   \n",
      "3195  259.79473876953125   804.1235961914062  258.61224365234375   \n",
      "3196    596.188720703125  1138.5855712890625    593.238525390625   \n",
      "3197  1760.7613525390625   531.5647583007812   1761.752197265625   \n",
      "3198   581.3431396484375    1281.24560546875   578.5438232421875   \n",
      "3199    593.428955078125  1143.9027099609375   590.7078857421875   \n",
      "\n",
      "                     v54                 v55                 v56  \\\n",
      "0       511.150634765625  1776.7215576171875  492.28704833984375   \n",
      "1      1215.205322265625   736.9203491210938         1215.578125   \n",
      "2     1237.9471435546875   583.1890869140625   1237.937255859375   \n",
      "3      492.7845458984375    1747.09716796875   468.4444274902344   \n",
      "4         681.7744140625   2086.020263671875   679.8877563476562   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   804.3353881835938  258.90936279296875   803.9461669921875   \n",
      "3196   1137.584716796875   596.2603759765625   1137.487060546875   \n",
      "3197   544.1353149414062  1763.4476318359375   529.6891479492188   \n",
      "3198      1280.376953125   580.9613037109375  1280.2196044921875   \n",
      "3199    1143.25537109375   593.5533447265625     1142.9189453125   \n",
      "\n",
      "                     v57                 v58                 v59  \\\n",
      "0     1730.5098876953125       576.701171875  1765.4093017578125   \n",
      "1      738.6305541992188   1213.525634765625    738.103271484375   \n",
      "2       584.283935546875   1236.259521484375   583.8878173828125   \n",
      "3     1694.6927490234375    558.009521484375  1730.2427978515625   \n",
      "4       2076.23876953125    694.294189453125   2088.042236328125   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   259.1824951171875   803.0823364257812   259.0874938964844   \n",
      "3196     597.37744140625  1135.5428466796875    596.856201171875   \n",
      "3197  1734.7784423828125   579.8497314453125  1756.9769287109375   \n",
      "3198   581.6155395507812  1279.0211181640625         581.5234375   \n",
      "3199   595.0902099609375     1140.2568359375   594.2203369140625   \n",
      "\n",
      "                     v60  \n",
      "0      526.5159301757812  \n",
      "1       1217.71630859375  \n",
      "2      1238.510498046875  \n",
      "3     505.95989990234375  \n",
      "4       676.531005859375  \n",
      "...                  ...  \n",
      "3195   802.9638061523438  \n",
      "3196   1139.097412109375  \n",
      "3197   544.4459838867188  \n",
      "3198    1280.97802734375  \n",
      "3199   1144.234619140625  \n",
      "\n",
      "[3200 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Submission output\n",
    "writeCSV = True\n",
    "val_path = \"./new_val_in/new_val_in\"\n",
    "\n",
    "if writeCSV:\n",
    "    \n",
    "    dataset = ArgoverseDataset(data_path=val_path)\n",
    "    test_loader = DataLoader(dataset,batch_size=batch_sz, shuffle = False, collate_fn=test_collate, num_workers=0)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(tqdm(test_loader)):\n",
    "            inp, scene_ids, track_ids, agent_ids = sample_batch\n",
    "            inp = torch.flatten(inp, start_dim=2)\n",
    "\n",
    "            if cuda_status:\n",
    "                model = model.cuda()\n",
    "                x = inp.cuda()\n",
    "            else:\n",
    "                x = inp\n",
    "\n",
    "            y_pred = None\n",
    "\n",
    "            # Forward pass: predict y by passing x to the model.    \n",
    "            y_pred = model(x.float())\n",
    "            y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 4]))\n",
    "            \n",
    "            for i in range(batch_sz):\n",
    "                row = []\n",
    "                row.append(scene_ids[i].item())\n",
    "                curr = y_pred[i]\n",
    "                \n",
    "                agent_id = agent_ids[i]\n",
    "                \n",
    "                for j in range(30):\n",
    "                    vehicle_index = 0\n",
    "                    found = False\n",
    "                    while not found:\n",
    "                        if track_ids[i][vehicle_index][j][0] == agent_id:\n",
    "                            found = True\n",
    "                        else:\n",
    "                            vehicle_index += 1\n",
    "\n",
    "                    row.append(str(curr[vehicle_index][j][0].item()))\n",
    "                    row.append(str(curr[vehicle_index][j][1].item()))\n",
    "                    \n",
    "                data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, columns = ['ID','v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','v11','v12','v13','v14','v15','v16','v17','v18','v19','v20','v21','v22','v23','v24','v25','v26','v27','v28','v29','v30','v31','v32','v33','v34','v35','v36','v37','v38','v39','v40','v41','v42','v43','v44','v45','v46','v47','v48','v49','v50','v51','v52','v53','v54','v55','v56','v57','v58','v59','v60'])\n",
    "    print(df)\n",
    "    df.to_csv('submission.csv', index=False)\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
