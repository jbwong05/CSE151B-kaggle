{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "\n",
    "cuda_status = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 64\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    car_mask = [scene['car_mask'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    car_mask = torch.LongTensor(car_mask)\n",
    "    return [inp, out, scene_ids, track_ids, agent_ids, car_mask]\n",
    "\n",
    "def test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337f566e4af54648836e2de01794c578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3218.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "iterator = tqdm(val_loader)\n",
    "max_tracked = 0\n",
    "\n",
    "for i_batch, sample_batch in enumerate(iterator):\n",
    "    inp, out, scene_ids, track_ids, agent_ids, car_mask = sample_batch\n",
    "    \n",
    "    for i in range(car_mask.shape[0]):\n",
    "        curr_tracked = 0\n",
    "        for j in range(car_mask.shape[1]):\n",
    "            if car_mask[i][j][0].item() == 1:\n",
    "                curr_tracked += 1\n",
    "            else:\n",
    "                break\n",
    "        if curr_tracked > max_tracked:\n",
    "            max_tracked = curr_tracked\n",
    "            iterator.set_postfix(max_tracked=max_tracked)\n",
    "    \n",
    "print(max_tracked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(76, 98),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(98, 98),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(98, 120)\n",
    ")\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ae4bfb8bc147abb3712b6eac2e82db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be49ddd4f430446c91252074eec6a1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3217.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e911699b00af4631ae5d6fc36e4f5da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3217.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a7d7c489bb4706ada1c54d6c3c47b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3217.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "agent_id = 0\n",
    "epoch = 3\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out, scene_ids, track_ids, agent_ids = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])\n",
    "        \n",
    "# Use the nn package to define our loss function\n",
    "loss_fn=torch.nn.MSELoss()\n",
    "\n",
    "# Use the optim package to define an Optimizer\n",
    "\n",
    "learning_rate =1e-3\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for i in trange(epoch):\n",
    "    iterator = tqdm(val_loader)\n",
    "    total = 0\n",
    "    count = 0\n",
    "    \n",
    "    for i_batch, sample_batch in enumerate(iterator):\n",
    "        inp, out, scene_ids, track_ids, agent_ids, car_mask = sample_batch\n",
    "        \"\"\"TODO:\n",
    "          Deep learning model\n",
    "          training routine\n",
    "        \"\"\"\n",
    "        \n",
    "        x = torch.flatten(inp[:,0:46,:,:], start_dim=2)\n",
    "        #x = torch.flatten(inp, start_dim=2)\n",
    "\n",
    "        x = x.float()\n",
    "        y = out[:,0:46,:,:].float()\n",
    "        #y = out.float()\n",
    "\n",
    "        if cuda_status:\n",
    "            #model = model.cuda()\n",
    "            #x = inp.cuda()\n",
    "            #y = out.cuda()\n",
    "            x.to(device)\n",
    "            y.to(device)\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        y_pred = None\n",
    "\n",
    "        # Forward pass: predict y by passing x to the model.    \n",
    "        y_pred = model(x)\n",
    "        y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 46, 30, 4]))\n",
    "\n",
    "        # Compute the loss.\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        total += torch.sqrt(loss).item()\n",
    "\n",
    "        # Before backward pass, zero outgradients to clear buffers  \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient w.r.t modelparameters\n",
    "        loss.backward()\n",
    "\n",
    "        # makes an gradient descent step to update its parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        #print(torch.sqrt(loss).item(), end='\\r')\n",
    "        iterator.set_postfix(loss=total / count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './models/6epochlinearrsm46.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/6epochmodel.pt')\n",
    "model.eval()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378ec431d1854097964c56c144375d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         ID                  v1                  v2                  v3  \\\n",
      "0     10002  1650.0030517578125   564.5743408203125   1660.242919921875   \n",
      "1     10015   728.2482299804688  1222.3990478515625   733.8153686523438   \n",
      "2     10019    573.374755859375  1243.9908447265625   577.2925415039062   \n",
      "3     10028      1621.673828125    557.015869140625  1629.9810791015625   \n",
      "4      1003          2107.09375       725.349609375   2106.910888671875   \n",
      "...     ...                 ...                 ...                 ...   \n",
      "3195   9897  255.30213928222656     804.39599609375   256.4273681640625   \n",
      "3196     99   587.6168212890625   1144.658935546875       592.052734375   \n",
      "3197   9905   1725.016845703125   576.1810302734375       1725.88671875   \n",
      "3198   9910   572.1321411132812    1287.06298828125   575.7203979492188   \n",
      "3199   9918   585.7659912109375  1149.2213134765625   590.2617797851562   \n",
      "\n",
      "                     v4                  v5                  v6  \\\n",
      "0     542.7818603515625  1836.7142333984375   530.2835693359375   \n",
      "1     1215.969970703125    723.307861328125  1205.9722900390625   \n",
      "2     1238.742919921875   570.4006958007812    1231.74560546875   \n",
      "3     530.5297241210938  1822.6048583984375   516.3074340820312   \n",
      "4     720.6670532226562        2135.5390625   716.2677001953125   \n",
      "...                 ...                 ...                 ...   \n",
      "3195  802.9474487304688   256.7893981933594   805.2075805664062   \n",
      "3196      1142.12109375   582.9223022460938  1130.4127197265625   \n",
      "3197  574.7766723632812  1809.0911865234375   567.2426147460938   \n",
      "3198  1283.516845703125   569.1469116210938   1276.521240234375   \n",
      "3199    1148.7236328125    581.230712890625    1136.16552734375   \n",
      "\n",
      "                      v7                  v8                  v9  ...  \\\n",
      "0     1666.7943115234375   402.9858093261719    1740.07177734375  ...   \n",
      "1      733.6057739257812  1211.5311279296875   724.4064331054688  ...   \n",
      "2         577.8251953125  1234.8856201171875   571.1588134765625  ...   \n",
      "3        1635.9052734375       380.212890625   1719.448974609375  ...   \n",
      "4       2109.41845703125   689.4801025390625    2120.22900390625  ...   \n",
      "...                  ...                 ...                 ...  ...   \n",
      "3195     256.85888671875   804.8455810546875  255.74551391601562  ...   \n",
      "3196    591.290283203125   1135.216552734375    583.782958984375  ...   \n",
      "3197   1735.019775390625   503.4463806152344     1765.7099609375  ...   \n",
      "3198     575.78662109375           1279.6875   570.0053100585938  ...   \n",
      "3199   588.8121948242188   1141.301513671875   581.3460693359375  ...   \n",
      "\n",
      "                     v51                 v52                 v53  \\\n",
      "0       1759.52880859375  493.21319580078125   1712.663818359375   \n",
      "1              726.09375   1207.561767578125   737.3363037109375   \n",
      "2      573.3980102539062    1233.32568359375   579.9415893554688   \n",
      "3     1726.8787841796875  471.53033447265625  1683.3333740234375   \n",
      "4      2098.517822265625   688.6988525390625     2086.7744140625   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   257.7507019042969   804.5252685546875   256.2397766113281   \n",
      "3196   583.6461791992188   1131.121826171875   593.7875366210938   \n",
      "3197    1773.46728515625     552.44482421875  1748.1307373046875   \n",
      "3198   570.9579467773438   1277.375244140625   577.2604370117188   \n",
      "3199   580.5144653320312  1135.7156982421875   591.1687622070312   \n",
      "\n",
      "                     v54                 v55                 v56  \\\n",
      "0     507.13946533203125  1683.1219482421875      419.9990234375   \n",
      "1      1210.684326171875   727.0422973632812   1213.253662109375   \n",
      "2      1236.037841796875   573.9301147460938     1237.6923828125   \n",
      "3     486.53875732421875   1644.434326171875   388.6131286621094   \n",
      "4       684.180419921875   2083.516357421875   670.4759521484375   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   804.8997192382812   257.5368957519531   803.9952392578125   \n",
      "3196     1132.3115234375   584.7581787109375   1138.136474609375   \n",
      "3197   544.0863037109375   1737.348388671875   516.5518798828125   \n",
      "3198  1278.9678955078125   571.5475463867188   1281.860107421875   \n",
      "3199    1135.64697265625    581.735107421875  1143.3704833984375   \n",
      "\n",
      "                     v57                 v58                 v59  \\\n",
      "0      1736.340087890625   544.0960693359375  1815.3612060546875   \n",
      "1      734.1503295898438  1213.4473876953125   730.4867553710938   \n",
      "2      578.9512939453125   1239.538818359375    577.025146484375   \n",
      "3         1707.306640625   520.8204345703125    1784.93310546875   \n",
      "4        2086.4384765625   693.3980712890625        2100.5234375   \n",
      "...                  ...                 ...                 ...   \n",
      "3195    256.218017578125    803.857666015625   256.4770202636719   \n",
      "3196   590.1138305664062  1136.4034423828125   588.3495483398438   \n",
      "3197  1752.5692138671875   575.2686157226562   1798.367431640625   \n",
      "3198   575.5263061523438   1281.940185546875   573.9735107421875   \n",
      "3199   585.9191284179688  1139.0711669921875    584.631591796875   \n",
      "\n",
      "                     v60  \n",
      "0      526.2034912109375  \n",
      "1     1208.0079345703125  \n",
      "2          1234.87890625  \n",
      "3       499.832275390625  \n",
      "4      685.1598510742188  \n",
      "...                  ...  \n",
      "3195   805.5230712890625  \n",
      "3196  1128.3145751953125  \n",
      "3197   556.7619018554688  \n",
      "3198   1276.808349609375  \n",
      "3199  1130.6160888671875  \n",
      "\n",
      "[3200 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Submission output\n",
    "writeCSV = True\n",
    "val_path = \"./new_val_in/new_val_in\"\n",
    "\n",
    "if writeCSV:\n",
    "    \n",
    "    dataset = ArgoverseDataset(data_path=val_path)\n",
    "    test_loader = DataLoader(dataset,batch_size=batch_sz, shuffle = False, collate_fn=test_collate, num_workers=0)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(tqdm(test_loader)):\n",
    "            inp, scene_ids, track_ids, agent_ids = sample_batch\n",
    "            inp = torch.flatten(inp, start_dim=2)\n",
    "\n",
    "            if cuda_status:\n",
    "                model = model.cuda()\n",
    "                x = inp[:,0:46,:].cuda()\n",
    "            else:\n",
    "                x = inp[:,0:46,:]\n",
    "\n",
    "            y_pred = None\n",
    "\n",
    "            # Forward pass: predict y by passing x to the model.    \n",
    "            y_pred = model(x.float())\n",
    "            y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 46, 30, 4]))\n",
    "            \n",
    "            for i in range(batch_sz):\n",
    "                row = []\n",
    "                row.append(scene_ids[i].item())\n",
    "                curr = y_pred[i]\n",
    "                \n",
    "                agent_id = agent_ids[i]\n",
    "                \n",
    "                for j in range(30):\n",
    "                    vehicle_index = 0\n",
    "                    found = False\n",
    "                    while not found:\n",
    "                        if track_ids[i][vehicle_index][j][0] == agent_id:\n",
    "                            found = True\n",
    "                        else:\n",
    "                            vehicle_index += 1\n",
    "\n",
    "                    row.append(str(curr[vehicle_index][j][0].item()))\n",
    "                    row.append(str(curr[vehicle_index][j][1].item()))\n",
    "                    \n",
    "                data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, columns = ['ID','v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','v11','v12','v13','v14','v15','v16','v17','v18','v19','v20','v21','v22','v23','v24','v25','v26','v27','v28','v29','v30','v31','v32','v33','v34','v35','v36','v37','v38','v39','v40','v41','v42','v43','v44','v45','v46','v47','v48','v49','v50','v51','v52','v53','v54','v55','v56','v57','v58','v59','v60'])\n",
    "    print(df)\n",
    "    df.to_csv('submission.csv', index=False)\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
