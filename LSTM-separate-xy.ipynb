{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "\n",
    "cuda_status = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 64\n",
    "\n",
    "def my_collate_x(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    #inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    inp = [numpy.dstack([scene['p_in'][:,:,0]]) for scene in batch]\n",
    "    #out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'][:,:,0]]) for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    return [inp, out]\n",
    "\n",
    "def my_collate_y(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    #inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    inp = [numpy.dstack([scene['p_in'][:,:,1]]) for scene in batch]\n",
    "    #out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'][:,:,1]]) for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    return [inp, out]\n",
    "\n",
    "def test_collate_x(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'][:,:,0]]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "def test_collate_y(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'][:,:,1]]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "train_loader_x = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate_x, num_workers=0)\n",
    "train_loader_y = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate_y, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMEncoderDecoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = torch.nn.LSTM(60, hidden_size=100, batch_first=True)\n",
    "        self.lstm2 = torch.nn.LSTM(100, hidden_size=100, batch_first=True, num_layers=2)\n",
    "        self.linear = torch.nn.Linear(1900, 1800)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.relu(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.relu(self.linear(x))\n",
    "        x = torch.reshape(x, torch.Size([64, 60, 30]))\n",
    "        return x\n",
    "\n",
    "x_model = LSTMEncoderDecoder()\n",
    "x_model.to(device)\n",
    "if cuda_status:\n",
    "    x_model = x_model.cuda()\n",
    "y_model = LSTMEncoderDecoder()\n",
    "y_model.to(device)\n",
    "if cuda_status:\n",
    "    y_model = y_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/1epochAdam.pt')\n",
    "model.train()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c774a2bab71441c8fdfa4e5b9bf066c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6dd9dbe002947ec8ae584a891b7079a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3216.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(799.2502, device='cuda:0', grad_fn=<SqrtBackward>) tensor(879.0607, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(781.5557, device='cuda:0', grad_fn=<SqrtBackward>) tensor(877.2045, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(965.4304, device='cuda:0', grad_fn=<SqrtBackward>) tensor(796.4229, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(721.6404, device='cuda:0', grad_fn=<SqrtBackward>) tensor(948.8709, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(695.2684, device='cuda:0', grad_fn=<SqrtBackward>) tensor(926.2650, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(752.9189, device='cuda:0', grad_fn=<SqrtBackward>) tensor(942.9468, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(582.8083, device='cuda:0', grad_fn=<SqrtBackward>) tensor(876.5192, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(734.6807, device='cuda:0', grad_fn=<SqrtBackward>) tensor(863.1770, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(747.9660, device='cuda:0', grad_fn=<SqrtBackward>) tensor(1009.4683, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(726.0078, device='cuda:0', grad_fn=<SqrtBackward>) tensor(850.6801, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(799.5770, device='cuda:0', grad_fn=<SqrtBackward>) tensor(928.7675, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(696.8804, device='cuda:0', grad_fn=<SqrtBackward>) tensor(876.9255, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(696.9519, device='cuda:0', grad_fn=<SqrtBackward>) tensor(990.4677, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(763.3658, device='cuda:0', grad_fn=<SqrtBackward>) tensor(875.9543, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(779.4221, device='cuda:0', grad_fn=<SqrtBackward>) tensor(999.7075, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(793.7103, device='cuda:0', grad_fn=<SqrtBackward>) tensor(836.4646, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(815.3784, device='cuda:0', grad_fn=<SqrtBackward>) tensor(757.6697, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(726.6051, device='cuda:0', grad_fn=<SqrtBackward>) tensor(941.1320, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(682.0362, device='cuda:0', grad_fn=<SqrtBackward>) tensor(906.8220, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(729.1053, device='cuda:0', grad_fn=<SqrtBackward>) tensor(910.9910, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(637.4422, device='cuda:0', grad_fn=<SqrtBackward>) tensor(910.7216, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(679.4999, device='cuda:0', grad_fn=<SqrtBackward>) tensor(1004.3826, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(686.7318, device='cuda:0', grad_fn=<SqrtBackward>) tensor(990.5763, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(753.7662, device='cuda:0', grad_fn=<SqrtBackward>) tensor(889.1962, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(741.1152, device='cuda:0', grad_fn=<SqrtBackward>) tensor(771.9944, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(738.5482, device='cuda:0', grad_fn=<SqrtBackward>) tensor(795.8911, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(804.5977, device='cuda:0', grad_fn=<SqrtBackward>) tensor(835.9661, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(677.1507, device='cuda:0', grad_fn=<SqrtBackward>) tensor(830.0990, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(605.6398, device='cuda:0', grad_fn=<SqrtBackward>) tensor(1006.5627, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(798.4847, device='cuda:0', grad_fn=<SqrtBackward>) tensor(804.0454, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(675.3368, device='cuda:0', grad_fn=<SqrtBackward>) tensor(969.0815, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(740.4869, device='cuda:0', grad_fn=<SqrtBackward>) tensor(932.2205, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(723.2348, device='cuda:0', grad_fn=<SqrtBackward>) tensor(891.1363, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(700.8972, device='cuda:0', grad_fn=<SqrtBackward>) tensor(720.0388, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(734.4855, device='cuda:0', grad_fn=<SqrtBackward>) tensor(834.2040, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(698.6044, device='cuda:0', grad_fn=<SqrtBackward>) tensor(878.6060, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(614.8307, device='cuda:0', grad_fn=<SqrtBackward>) tensor(909.4002, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(799.3186, device='cuda:0', grad_fn=<SqrtBackward>) tensor(881.3929, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(613.7690, device='cuda:0', grad_fn=<SqrtBackward>) tensor(776.1067, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(761.5860, device='cuda:0', grad_fn=<SqrtBackward>) tensor(873.2061, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(770.8625, device='cuda:0', grad_fn=<SqrtBackward>) tensor(927.5514, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(656.4598, device='cuda:0', grad_fn=<SqrtBackward>) tensor(921.1533, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(698.4651, device='cuda:0', grad_fn=<SqrtBackward>) tensor(922.3514, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(793.1150, device='cuda:0', grad_fn=<SqrtBackward>) tensor(827.4645, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(694.2439, device='cuda:0', grad_fn=<SqrtBackward>) tensor(892.4538, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(732.7198, device='cuda:0', grad_fn=<SqrtBackward>) tensor(940.1339, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(671.1752, device='cuda:0', grad_fn=<SqrtBackward>) tensor(930.2321, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(714.2744, device='cuda:0', grad_fn=<SqrtBackward>) tensor(750.5442, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(744.5443, device='cuda:0', grad_fn=<SqrtBackward>) tensor(888.1418, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(838.4342, device='cuda:0', grad_fn=<SqrtBackward>) tensor(839.1528, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(735.6219, device='cuda:0', grad_fn=<SqrtBackward>) tensor(905.8775, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(838.2495, device='cuda:0', grad_fn=<SqrtBackward>) tensor(870.6503, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(688.9785, device='cuda:0', grad_fn=<SqrtBackward>) tensor(856.4770, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(748.7628, device='cuda:0', grad_fn=<SqrtBackward>) tensor(917.6633, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(786.9256, device='cuda:0', grad_fn=<SqrtBackward>) tensor(935.8886, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(718.1581, device='cuda:0', grad_fn=<SqrtBackward>) tensor(970.3834, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(722.9677, device='cuda:0', grad_fn=<SqrtBackward>) tensor(874.2747, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(712.1658, device='cuda:0', grad_fn=<SqrtBackward>) tensor(850.6547, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(760.2032, device='cuda:0', grad_fn=<SqrtBackward>) tensor(881.5344, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(652.0413, device='cuda:0', grad_fn=<SqrtBackward>) tensor(925.9655, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(767.0638, device='cuda:0', grad_fn=<SqrtBackward>) tensor(864.9965, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(762.7087, device='cuda:0', grad_fn=<SqrtBackward>) tensor(831.3188, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(621.6075, device='cuda:0', grad_fn=<SqrtBackward>) tensor(853.9656, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(838.5794, device='cuda:0', grad_fn=<SqrtBackward>) tensor(853.4086, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(714.2520, device='cuda:0', grad_fn=<SqrtBackward>) tensor(864.4265, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(611.1059, device='cuda:0', grad_fn=<SqrtBackward>) tensor(917.5929, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(689.3123, device='cuda:0', grad_fn=<SqrtBackward>) tensor(871.9448, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(808.0745, device='cuda:0', grad_fn=<SqrtBackward>) tensor(888.7107, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(706.7336, device='cuda:0', grad_fn=<SqrtBackward>) tensor(721.5490, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(759.8073, device='cuda:0', grad_fn=<SqrtBackward>) tensor(842.0720, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(630.7950, device='cuda:0', grad_fn=<SqrtBackward>) tensor(930.3260, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(824.5688, device='cuda:0', grad_fn=<SqrtBackward>) tensor(806.2856, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(730.3732, device='cuda:0', grad_fn=<SqrtBackward>) tensor(924.0704, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(649.9883, device='cuda:0', grad_fn=<SqrtBackward>) tensor(933.8777, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(671.6512, device='cuda:0', grad_fn=<SqrtBackward>) tensor(778.2968, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(643.1281, device='cuda:0', grad_fn=<SqrtBackward>) tensor(893.8199, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(675.8730, device='cuda:0', grad_fn=<SqrtBackward>) tensor(861.2225, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(853.3851, device='cuda:0', grad_fn=<SqrtBackward>) tensor(757.0832, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(645.4004, device='cuda:0', grad_fn=<SqrtBackward>) tensor(914.8071, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(739.9238, device='cuda:0', grad_fn=<SqrtBackward>) tensor(877.8397, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(773.9321, device='cuda:0', grad_fn=<SqrtBackward>) tensor(752.5701, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(742.7738, device='cuda:0', grad_fn=<SqrtBackward>) tensor(784.9878, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(800.6559, device='cuda:0', grad_fn=<SqrtBackward>) tensor(1021.5319, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(757.9330, device='cuda:0', grad_fn=<SqrtBackward>) tensor(777.0524, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(758.3162, device='cuda:0', grad_fn=<SqrtBackward>) tensor(920.5146, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(610.0356, device='cuda:0', grad_fn=<SqrtBackward>) tensor(786.2545, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(679.5919, device='cuda:0', grad_fn=<SqrtBackward>) tensor(901.6094, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(746.8351, device='cuda:0', grad_fn=<SqrtBackward>) tensor(807.4999, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(768.8555, device='cuda:0', grad_fn=<SqrtBackward>) tensor(740.7330, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(676.1887, device='cuda:0', grad_fn=<SqrtBackward>) tensor(832.5488, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(829.4512, device='cuda:0', grad_fn=<SqrtBackward>) tensor(843.3854, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(785.8137, device='cuda:0', grad_fn=<SqrtBackward>) tensor(884.5687, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(720.1578, device='cuda:0', grad_fn=<SqrtBackward>) tensor(752.7509, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(761.8355, device='cuda:0', grad_fn=<SqrtBackward>) tensor(869.8798, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(699.5445, device='cuda:0', grad_fn=<SqrtBackward>) tensor(864.0181, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(810.7363, device='cuda:0', grad_fn=<SqrtBackward>) tensor(750.2883, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(826.1094, device='cuda:0', grad_fn=<SqrtBackward>) tensor(835.6808, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(760.5583, device='cuda:0', grad_fn=<SqrtBackward>) tensor(863.0946, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(597.4941, device='cuda:0', grad_fn=<SqrtBackward>) tensor(766.6146, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(670.5316, device='cuda:0', grad_fn=<SqrtBackward>) tensor(840.9185, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(621.6054, device='cuda:0', grad_fn=<SqrtBackward>) tensor(868.0764, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(679.7841, device='cuda:0', grad_fn=<SqrtBackward>) tensor(778.8785, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(717.5551, device='cuda:0', grad_fn=<SqrtBackward>) tensor(850.1812, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(655.3701, device='cuda:0', grad_fn=<SqrtBackward>) tensor(861.1658, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(817.2755, device='cuda:0', grad_fn=<SqrtBackward>) tensor(846.5265, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(666.3096, device='cuda:0', grad_fn=<SqrtBackward>) tensor(887.7590, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(799.2823, device='cuda:0', grad_fn=<SqrtBackward>) tensor(787.7795, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(671.5604, device='cuda:0', grad_fn=<SqrtBackward>) tensor(936.4559, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(614.7076, device='cuda:0', grad_fn=<SqrtBackward>) tensor(852.9218, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(661.1776, device='cuda:0', grad_fn=<SqrtBackward>) tensor(898.1588, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(596.6357, device='cuda:0', grad_fn=<SqrtBackward>) tensor(776.3286, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(722.0560, device='cuda:0', grad_fn=<SqrtBackward>) tensor(805.4460, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(792.7150, device='cuda:0', grad_fn=<SqrtBackward>) tensor(891.2985, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(712.7972, device='cuda:0', grad_fn=<SqrtBackward>) tensor(890.6282, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(671.8867, device='cuda:0', grad_fn=<SqrtBackward>) tensor(832.3878, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(786.5767, device='cuda:0', grad_fn=<SqrtBackward>) tensor(877.1376, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(728.7727, device='cuda:0', grad_fn=<SqrtBackward>) tensor(891.7253, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(682.6360, device='cuda:0', grad_fn=<SqrtBackward>) tensor(906.8339, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(725.1500, device='cuda:0', grad_fn=<SqrtBackward>) tensor(863.4420, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(600.2045, device='cuda:0', grad_fn=<SqrtBackward>) tensor(827.4225, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(715.3025, device='cuda:0', grad_fn=<SqrtBackward>) tensor(913.3922, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(687.4669, device='cuda:0', grad_fn=<SqrtBackward>) tensor(779.0784, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(553.1541, device='cuda:0', grad_fn=<SqrtBackward>) tensor(907.4003, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(684.8172, device='cuda:0', grad_fn=<SqrtBackward>) tensor(813.9098, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(694.0502, device='cuda:0', grad_fn=<SqrtBackward>) tensor(796.3845, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(749.9822, device='cuda:0', grad_fn=<SqrtBackward>) tensor(786.4653, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(586.0756, device='cuda:0', grad_fn=<SqrtBackward>) tensor(763.1576, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(579.8939, device='cuda:0', grad_fn=<SqrtBackward>) tensor(966.5642, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(687.3192, device='cuda:0', grad_fn=<SqrtBackward>) tensor(885.4039, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(681.0084, device='cuda:0', grad_fn=<SqrtBackward>) tensor(715.0336, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(628.6653, device='cuda:0', grad_fn=<SqrtBackward>) tensor(876.9586, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(728.9087, device='cuda:0', grad_fn=<SqrtBackward>) tensor(862.3836, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(696.0089, device='cuda:0', grad_fn=<SqrtBackward>) tensor(746.1840, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(599.4902, device='cuda:0', grad_fn=<SqrtBackward>) tensor(974.9656, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(697.1840, device='cuda:0', grad_fn=<SqrtBackward>) tensor(886.5269, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(749.3755, device='cuda:0', grad_fn=<SqrtBackward>) tensor(853.9676, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(723.8583, device='cuda:0', grad_fn=<SqrtBackward>) tensor(1019.0660, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(579.4755, device='cuda:0', grad_fn=<SqrtBackward>) tensor(912.7299, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(675.5126, device='cuda:0', grad_fn=<SqrtBackward>) tensor(746.1165, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(774.3082, device='cuda:0', grad_fn=<SqrtBackward>) tensor(799.9012, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(834.9218, device='cuda:0', grad_fn=<SqrtBackward>) tensor(793.0664, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(689.0173, device='cuda:0', grad_fn=<SqrtBackward>) tensor(793.0576, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(695.2014, device='cuda:0', grad_fn=<SqrtBackward>) tensor(803.7007, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(764.1124, device='cuda:0', grad_fn=<SqrtBackward>) tensor(761.4576, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(805.8029, device='cuda:0', grad_fn=<SqrtBackward>) tensor(817.6094, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(744.6180, device='cuda:0', grad_fn=<SqrtBackward>) tensor(786.5547, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(723.5813, device='cuda:0', grad_fn=<SqrtBackward>) tensor(821.0203, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(762.3081, device='cuda:0', grad_fn=<SqrtBackward>) tensor(856.5100, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(655.3928, device='cuda:0', grad_fn=<SqrtBackward>) tensor(972.5924, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(710.3427, device='cuda:0', grad_fn=<SqrtBackward>) tensor(702.3506, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(576.1914, device='cuda:0', grad_fn=<SqrtBackward>) tensor(968.0455, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(609.3657, device='cuda:0', grad_fn=<SqrtBackward>) tensor(879.2505, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(644.9182, device='cuda:0', grad_fn=<SqrtBackward>) tensor(915.5121, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(859.4150, device='cuda:0', grad_fn=<SqrtBackward>) tensor(734.6310, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(738.7086, device='cuda:0', grad_fn=<SqrtBackward>) tensor(894.3519, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(765.7020, device='cuda:0', grad_fn=<SqrtBackward>) tensor(814.1789, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(657.8203, device='cuda:0', grad_fn=<SqrtBackward>) tensor(875.0076, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(776.3902, device='cuda:0', grad_fn=<SqrtBackward>) tensor(835.3079, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(641.7820, device='cuda:0', grad_fn=<SqrtBackward>) tensor(814.2996, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(793.7869, device='cuda:0', grad_fn=<SqrtBackward>) tensor(772.4284, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(694.7782, device='cuda:0', grad_fn=<SqrtBackward>) tensor(821.1000, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(737.1710, device='cuda:0', grad_fn=<SqrtBackward>) tensor(868.0576, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(652.3983, device='cuda:0', grad_fn=<SqrtBackward>) tensor(837.2869, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(665.6525, device='cuda:0', grad_fn=<SqrtBackward>) tensor(827.0293, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(683.6243, device='cuda:0', grad_fn=<SqrtBackward>) tensor(893.4035, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(720.2758, device='cuda:0', grad_fn=<SqrtBackward>) tensor(982.9265, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(715.0040, device='cuda:0', grad_fn=<SqrtBackward>) tensor(861.4299, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(725.7880, device='cuda:0', grad_fn=<SqrtBackward>) tensor(917.4727, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(590.5344, device='cuda:0', grad_fn=<SqrtBackward>) tensor(866.6879, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(709.5338, device='cuda:0', grad_fn=<SqrtBackward>) tensor(837.7102, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(808.5079, device='cuda:0', grad_fn=<SqrtBackward>) tensor(723.9739, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(668.2406, device='cuda:0', grad_fn=<SqrtBackward>) tensor(846.7006, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(634.9839, device='cuda:0', grad_fn=<SqrtBackward>) tensor(914.2598, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(602.7871, device='cuda:0', grad_fn=<SqrtBackward>) tensor(806.1508, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(681.5040, device='cuda:0', grad_fn=<SqrtBackward>) tensor(751.7527, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(777.8106, device='cuda:0', grad_fn=<SqrtBackward>) tensor(814.3483, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(631.0841, device='cuda:0', grad_fn=<SqrtBackward>) tensor(815.2819, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(671.0533, device='cuda:0', grad_fn=<SqrtBackward>) tensor(900.9882, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(558.0881, device='cuda:0', grad_fn=<SqrtBackward>) tensor(822.0848, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(603.4432, device='cuda:0', grad_fn=<SqrtBackward>) tensor(826.8433, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(826.3168, device='cuda:0', grad_fn=<SqrtBackward>) tensor(778.5859, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(764.4152, device='cuda:0', grad_fn=<SqrtBackward>) tensor(921.6591, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(736.3633, device='cuda:0', grad_fn=<SqrtBackward>) tensor(882.1917, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(749.9424, device='cuda:0', grad_fn=<SqrtBackward>) tensor(870.4683, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(743.1944, device='cuda:0', grad_fn=<SqrtBackward>) tensor(647.7754, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(697.1320, device='cuda:0', grad_fn=<SqrtBackward>) tensor(876.0658, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(680.2773, device='cuda:0', grad_fn=<SqrtBackward>) tensor(733.8498, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(658.6684, device='cuda:0', grad_fn=<SqrtBackward>) tensor(865.3141, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(651.8038, device='cuda:0', grad_fn=<SqrtBackward>) tensor(863.8167, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(733.2535, device='cuda:0', grad_fn=<SqrtBackward>) tensor(918.5276, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(662.2942, device='cuda:0', grad_fn=<SqrtBackward>) tensor(817.6894, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(733.0390, device='cuda:0', grad_fn=<SqrtBackward>) tensor(926.4319, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(664.7965, device='cuda:0', grad_fn=<SqrtBackward>) tensor(794.6262, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(680.2199, device='cuda:0', grad_fn=<SqrtBackward>) tensor(869.2070, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(612.4905, device='cuda:0', grad_fn=<SqrtBackward>) tensor(883.4985, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(575.0833, device='cuda:0', grad_fn=<SqrtBackward>) tensor(908.7625, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(742.8493, device='cuda:0', grad_fn=<SqrtBackward>) tensor(765.0237, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(895.8512, device='cuda:0', grad_fn=<SqrtBackward>) tensor(803.5891, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(596.4055, device='cuda:0', grad_fn=<SqrtBackward>) tensor(807.4453, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(679.0553, device='cuda:0', grad_fn=<SqrtBackward>) tensor(877.0642, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(704.5342, device='cuda:0', grad_fn=<SqrtBackward>) tensor(796.6143, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(629.4622, device='cuda:0', grad_fn=<SqrtBackward>) tensor(921.2219, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(628.6153, device='cuda:0', grad_fn=<SqrtBackward>) tensor(891.2843, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(669.5406, device='cuda:0', grad_fn=<SqrtBackward>) tensor(894.5720, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(667.9643, device='cuda:0', grad_fn=<SqrtBackward>) tensor(683.8535, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(617.3540, device='cuda:0', grad_fn=<SqrtBackward>) tensor(909.3779, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(630.0967, device='cuda:0', grad_fn=<SqrtBackward>) tensor(904.8506, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(765.5541, device='cuda:0', grad_fn=<SqrtBackward>) tensor(696.7800, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(695.5120, device='cuda:0', grad_fn=<SqrtBackward>) tensor(892.7326, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(664.0846, device='cuda:0', grad_fn=<SqrtBackward>) tensor(859.0194, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(726.4102, device='cuda:0', grad_fn=<SqrtBackward>) tensor(880.2290, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(698.7565, device='cuda:0', grad_fn=<SqrtBackward>) tensor(843.8566, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(676.3264, device='cuda:0', grad_fn=<SqrtBackward>) tensor(784.5436, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(611.8132, device='cuda:0', grad_fn=<SqrtBackward>) tensor(855.0745, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(758.6752, device='cuda:0', grad_fn=<SqrtBackward>) tensor(783.0179, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(651.7525, device='cuda:0', grad_fn=<SqrtBackward>) tensor(884.6627, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(613.9224, device='cuda:0', grad_fn=<SqrtBackward>) tensor(898.3222, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(757.9352, device='cuda:0', grad_fn=<SqrtBackward>) tensor(916.4980, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(737.6208, device='cuda:0', grad_fn=<SqrtBackward>) tensor(848.6558, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(716.0724, device='cuda:0', grad_fn=<SqrtBackward>) tensor(887.8046, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(655.4786, device='cuda:0', grad_fn=<SqrtBackward>) tensor(823.0251, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(714.7269, device='cuda:0', grad_fn=<SqrtBackward>) tensor(670.6904, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(650.6573, device='cuda:0', grad_fn=<SqrtBackward>) tensor(741.7068, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(653.4213, device='cuda:0', grad_fn=<SqrtBackward>) tensor(952.1830, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(581.2786, device='cuda:0', grad_fn=<SqrtBackward>) tensor(813.7667, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(762.3677, device='cuda:0', grad_fn=<SqrtBackward>) tensor(759.5532, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(659.1564, device='cuda:0', grad_fn=<SqrtBackward>) tensor(919.0040, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(733.9370, device='cuda:0', grad_fn=<SqrtBackward>) tensor(819.9563, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(713.2728, device='cuda:0', grad_fn=<SqrtBackward>) tensor(778.7962, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(748.9761, device='cuda:0', grad_fn=<SqrtBackward>) tensor(868.8558, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(739.5378, device='cuda:0', grad_fn=<SqrtBackward>) tensor(735.0841, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(709.7104, device='cuda:0', grad_fn=<SqrtBackward>) tensor(696.7341, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(699.5421, device='cuda:0', grad_fn=<SqrtBackward>) tensor(736.3470, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(689.9528, device='cuda:0', grad_fn=<SqrtBackward>) tensor(715.0257, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(555.6942, device='cuda:0', grad_fn=<SqrtBackward>) tensor(879.1894, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(709.7615, device='cuda:0', grad_fn=<SqrtBackward>) tensor(764.0663, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(706.3799, device='cuda:0', grad_fn=<SqrtBackward>) tensor(844.1257, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(704.6813, device='cuda:0', grad_fn=<SqrtBackward>) tensor(836.5539, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(644.6484, device='cuda:0', grad_fn=<SqrtBackward>) tensor(834.5481, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(668.5663, device='cuda:0', grad_fn=<SqrtBackward>) tensor(752.7062, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(645.9667, device='cuda:0', grad_fn=<SqrtBackward>) tensor(817.7275, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(554.1228, device='cuda:0', grad_fn=<SqrtBackward>) tensor(937.8041, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(829.6380, device='cuda:0', grad_fn=<SqrtBackward>) tensor(771.3783, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(873.9848, device='cuda:0', grad_fn=<SqrtBackward>) tensor(698.6744, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(642.4438, device='cuda:0', grad_fn=<SqrtBackward>) tensor(748.0101, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(714.9286, device='cuda:0', grad_fn=<SqrtBackward>) tensor(850.1730, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(765.8840, device='cuda:0', grad_fn=<SqrtBackward>) tensor(705.9836, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(748.6465, device='cuda:0', grad_fn=<SqrtBackward>) tensor(777.5797, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(748.0418, device='cuda:0', grad_fn=<SqrtBackward>) tensor(933.0141, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(743.3042, device='cuda:0', grad_fn=<SqrtBackward>) tensor(899.7061, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(630.1984, device='cuda:0', grad_fn=<SqrtBackward>) tensor(847.1611, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(555.9556, device='cuda:0', grad_fn=<SqrtBackward>) tensor(918.3563, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(583.9894, device='cuda:0', grad_fn=<SqrtBackward>) tensor(908.4095, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(637.6184, device='cuda:0', grad_fn=<SqrtBackward>) tensor(753.9608, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(668.6998, device='cuda:0', grad_fn=<SqrtBackward>) tensor(999.2328, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(784.5641, device='cuda:0', grad_fn=<SqrtBackward>) tensor(774.3456, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(693.6077, device='cuda:0', grad_fn=<SqrtBackward>) tensor(816.7065, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(744.5695, device='cuda:0', grad_fn=<SqrtBackward>) tensor(802.6451, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(671.9752, device='cuda:0', grad_fn=<SqrtBackward>) tensor(770.9726, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(614.6112, device='cuda:0', grad_fn=<SqrtBackward>) tensor(814.9529, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(705.7411, device='cuda:0', grad_fn=<SqrtBackward>) tensor(778.8160, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(590.9169, device='cuda:0', grad_fn=<SqrtBackward>) tensor(797.1117, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(758.7716, device='cuda:0', grad_fn=<SqrtBackward>) tensor(780.0120, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(590.2803, device='cuda:0', grad_fn=<SqrtBackward>) tensor(847.3156, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(712.4320, device='cuda:0', grad_fn=<SqrtBackward>) tensor(707.2831, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(712.7043, device='cuda:0', grad_fn=<SqrtBackward>) tensor(780.4064, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(645.1669, device='cuda:0', grad_fn=<SqrtBackward>) tensor(856.8663, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(569.1419, device='cuda:0', grad_fn=<SqrtBackward>) tensor(817.0872, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(758.4484, device='cuda:0', grad_fn=<SqrtBackward>) tensor(889.6730, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(656.5291, device='cuda:0', grad_fn=<SqrtBackward>) tensor(809.0370, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(702.1104, device='cuda:0', grad_fn=<SqrtBackward>) tensor(904.0142, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(669.0201, device='cuda:0', grad_fn=<SqrtBackward>) tensor(784.9280, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(650.5930, device='cuda:0', grad_fn=<SqrtBackward>) tensor(719.5919, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(619.7755, device='cuda:0', grad_fn=<SqrtBackward>) tensor(730.3615, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(667.7423, device='cuda:0', grad_fn=<SqrtBackward>) tensor(806.0118, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(792.7175, device='cuda:0', grad_fn=<SqrtBackward>) tensor(803.8497, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(690.9449, device='cuda:0', grad_fn=<SqrtBackward>) tensor(844.6840, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(772.2115, device='cuda:0', grad_fn=<SqrtBackward>) tensor(683.6891, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(754.0964, device='cuda:0', grad_fn=<SqrtBackward>) tensor(871.3997, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(658.7974, device='cuda:0', grad_fn=<SqrtBackward>) tensor(795.1285, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(672.8129, device='cuda:0', grad_fn=<SqrtBackward>) tensor(800.5789, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(623.6121, device='cuda:0', grad_fn=<SqrtBackward>) tensor(793.4833, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(593.8525, device='cuda:0', grad_fn=<SqrtBackward>) tensor(810.3680, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(658.3044, device='cuda:0', grad_fn=<SqrtBackward>) tensor(907.3559, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(774.8439, device='cuda:0', grad_fn=<SqrtBackward>) tensor(866.2943, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(624.9739, device='cuda:0', grad_fn=<SqrtBackward>) tensor(817.7437, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(711.4099, device='cuda:0', grad_fn=<SqrtBackward>) tensor(760.1830, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(750.2084, device='cuda:0', grad_fn=<SqrtBackward>) tensor(760.3333, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(659.0033, device='cuda:0', grad_fn=<SqrtBackward>) tensor(833.3519, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(754.4535, device='cuda:0', grad_fn=<SqrtBackward>) tensor(859.2501, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(687.1833, device='cuda:0', grad_fn=<SqrtBackward>) tensor(812.0627, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(698.1463, device='cuda:0', grad_fn=<SqrtBackward>) tensor(922.0418, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(679.0558, device='cuda:0', grad_fn=<SqrtBackward>) tensor(886.3818, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(611.4211, device='cuda:0', grad_fn=<SqrtBackward>) tensor(778.3509, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(682.3104, device='cuda:0', grad_fn=<SqrtBackward>) tensor(838.3497, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(647.4814, device='cuda:0', grad_fn=<SqrtBackward>) tensor(811.7855, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(677.3105, device='cuda:0', grad_fn=<SqrtBackward>) tensor(775.3352, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(617.6622, device='cuda:0', grad_fn=<SqrtBackward>) tensor(745.9318, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(703.7365, device='cuda:0', grad_fn=<SqrtBackward>) tensor(758.8397, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(447.6370, device='cuda:0', grad_fn=<SqrtBackward>) tensor(877.5215, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(795.2419, device='cuda:0', grad_fn=<SqrtBackward>) tensor(684.0692, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(650.6151, device='cuda:0', grad_fn=<SqrtBackward>) tensor(757.0714, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(589.3551, device='cuda:0', grad_fn=<SqrtBackward>) tensor(796.2949, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(595.8906, device='cuda:0', grad_fn=<SqrtBackward>) tensor(888.0441, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(535.9212, device='cuda:0', grad_fn=<SqrtBackward>) tensor(719.3287, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(504.8642, device='cuda:0', grad_fn=<SqrtBackward>) tensor(940.8552, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(697.9109, device='cuda:0', grad_fn=<SqrtBackward>) tensor(732.7556, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(816.4090, device='cuda:0', grad_fn=<SqrtBackward>) tensor(779.6019, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(706.7676, device='cuda:0', grad_fn=<SqrtBackward>) tensor(737.5270, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(729.2817, device='cuda:0', grad_fn=<SqrtBackward>) tensor(930.2521, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(724.7656, device='cuda:0', grad_fn=<SqrtBackward>) tensor(845.5309, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(689.7433, device='cuda:0', grad_fn=<SqrtBackward>) tensor(820.1287, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(712.5157, device='cuda:0', grad_fn=<SqrtBackward>) tensor(826.2730, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(688.7034, device='cuda:0', grad_fn=<SqrtBackward>) tensor(754.6670, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(574.7357, device='cuda:0', grad_fn=<SqrtBackward>) tensor(790.2049, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(534.5460, device='cuda:0', grad_fn=<SqrtBackward>) tensor(842.2485, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(627.5427, device='cuda:0', grad_fn=<SqrtBackward>) tensor(852.7862, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(734.8135, device='cuda:0', grad_fn=<SqrtBackward>) tensor(963.4512, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(693.8404, device='cuda:0', grad_fn=<SqrtBackward>) tensor(791.7552, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(589.6881, device='cuda:0', grad_fn=<SqrtBackward>) tensor(760.8654, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(663.5010, device='cuda:0', grad_fn=<SqrtBackward>) tensor(727.9861, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(797.9722, device='cuda:0', grad_fn=<SqrtBackward>) tensor(863.7442, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(611.6906, device='cuda:0', grad_fn=<SqrtBackward>) tensor(818.4669, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(585.8674, device='cuda:0', grad_fn=<SqrtBackward>) tensor(800.7817, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(752.8071, device='cuda:0', grad_fn=<SqrtBackward>) tensor(658.9979, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(612.2666, device='cuda:0', grad_fn=<SqrtBackward>) tensor(712.3858, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(656.3133, device='cuda:0', grad_fn=<SqrtBackward>) tensor(852.1042, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(717.5128, device='cuda:0', grad_fn=<SqrtBackward>) tensor(716.7543, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(681.8667, device='cuda:0', grad_fn=<SqrtBackward>) tensor(855.4986, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(695.8287, device='cuda:0', grad_fn=<SqrtBackward>) tensor(750.3353, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(679.2016, device='cuda:0', grad_fn=<SqrtBackward>) tensor(844.2632, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(661.7397, device='cuda:0', grad_fn=<SqrtBackward>) tensor(707.0679, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(594.7504, device='cuda:0', grad_fn=<SqrtBackward>) tensor(897.7689, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(657.1921, device='cuda:0', grad_fn=<SqrtBackward>) tensor(716.8741, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(564.6183, device='cuda:0', grad_fn=<SqrtBackward>) tensor(914.5168, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(647.0151, device='cuda:0', grad_fn=<SqrtBackward>) tensor(749.7120, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(694.6100, device='cuda:0', grad_fn=<SqrtBackward>) tensor(806.8369, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(602.5182, device='cuda:0', grad_fn=<SqrtBackward>) tensor(954.2502, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(564.9038, device='cuda:0', grad_fn=<SqrtBackward>) tensor(788.3842, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(629.9113, device='cuda:0', grad_fn=<SqrtBackward>) tensor(625.5090, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(675.4659, device='cuda:0', grad_fn=<SqrtBackward>) tensor(804.2253, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(536.5889, device='cuda:0', grad_fn=<SqrtBackward>) tensor(834.5952, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(664.2155, device='cuda:0', grad_fn=<SqrtBackward>) tensor(907.6710, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(731.3322, device='cuda:0', grad_fn=<SqrtBackward>) tensor(743.1899, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(639.6079, device='cuda:0', grad_fn=<SqrtBackward>) tensor(785.1139, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(674.8204, device='cuda:0', grad_fn=<SqrtBackward>) tensor(700.8417, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(593.8928, device='cuda:0', grad_fn=<SqrtBackward>) tensor(893.0339, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(694.2057, device='cuda:0', grad_fn=<SqrtBackward>) tensor(893.2905, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(620.6700, device='cuda:0', grad_fn=<SqrtBackward>) tensor(666.6745, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(571.4996, device='cuda:0', grad_fn=<SqrtBackward>) tensor(809.5331, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(737.3723, device='cuda:0', grad_fn=<SqrtBackward>) tensor(770.1854, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(730.7933, device='cuda:0', grad_fn=<SqrtBackward>) tensor(837.9818, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(713.8242, device='cuda:0', grad_fn=<SqrtBackward>) tensor(773.1034, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(514.5427, device='cuda:0', grad_fn=<SqrtBackward>) tensor(741.7407, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(669.8326, device='cuda:0', grad_fn=<SqrtBackward>) tensor(781.7302, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(715.0811, device='cuda:0', grad_fn=<SqrtBackward>) tensor(772.9039, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(589.0088, device='cuda:0', grad_fn=<SqrtBackward>) tensor(879.8939, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(628.4825, device='cuda:0', grad_fn=<SqrtBackward>) tensor(902.6805, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(719.1678, device='cuda:0', grad_fn=<SqrtBackward>) tensor(814.6317, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(569.0098, device='cuda:0', grad_fn=<SqrtBackward>) tensor(972.0096, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(576.4651, device='cuda:0', grad_fn=<SqrtBackward>) tensor(796.0955, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(680.3384, device='cuda:0', grad_fn=<SqrtBackward>) tensor(709.4492, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(763.5768, device='cuda:0', grad_fn=<SqrtBackward>) tensor(783.2244, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(677.1470, device='cuda:0', grad_fn=<SqrtBackward>) tensor(838.8656, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(767.1118, device='cuda:0', grad_fn=<SqrtBackward>) tensor(774.9048, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(714.1157, device='cuda:0', grad_fn=<SqrtBackward>) tensor(709.0234, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(575.6760, device='cuda:0', grad_fn=<SqrtBackward>) tensor(795.2939, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(539.6487, device='cuda:0', grad_fn=<SqrtBackward>) tensor(810.9409, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(686.4512, device='cuda:0', grad_fn=<SqrtBackward>) tensor(669.6205, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(762.8925, device='cuda:0', grad_fn=<SqrtBackward>) tensor(898.7180, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(587.3990, device='cuda:0', grad_fn=<SqrtBackward>) tensor(809.1051, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(571.3777, device='cuda:0', grad_fn=<SqrtBackward>) tensor(695.5991, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(667.6826, device='cuda:0', grad_fn=<SqrtBackward>) tensor(833.7148, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(661.4921, device='cuda:0', grad_fn=<SqrtBackward>) tensor(667.9995, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(619.6084, device='cuda:0', grad_fn=<SqrtBackward>) tensor(858.1506, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(511.4375, device='cuda:0', grad_fn=<SqrtBackward>) tensor(875.3501, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(760.0468, device='cuda:0', grad_fn=<SqrtBackward>) tensor(897.5900, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(608.3167, device='cuda:0', grad_fn=<SqrtBackward>) tensor(830.6136, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(671.8454, device='cuda:0', grad_fn=<SqrtBackward>) tensor(729.2417, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(666.6009, device='cuda:0', grad_fn=<SqrtBackward>) tensor(843.0336, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(701.4029, device='cuda:0', grad_fn=<SqrtBackward>) tensor(827.2018, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(597.4881, device='cuda:0', grad_fn=<SqrtBackward>) tensor(879.9535, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(660.5427, device='cuda:0', grad_fn=<SqrtBackward>) tensor(756.3683, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(569.9346, device='cuda:0', grad_fn=<SqrtBackward>) tensor(766.5178, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(684.1842, device='cuda:0', grad_fn=<SqrtBackward>) tensor(738.0352, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(672.4697, device='cuda:0', grad_fn=<SqrtBackward>) tensor(803.9565, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(699.7087, device='cuda:0', grad_fn=<SqrtBackward>) tensor(704.4570, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(653.9442, device='cuda:0', grad_fn=<SqrtBackward>) tensor(847.4440, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(551.8459, device='cuda:0', grad_fn=<SqrtBackward>) tensor(702.4630, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(687.0146, device='cuda:0', grad_fn=<SqrtBackward>) tensor(777.4473, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "agent_id = 0\n",
    "epoch = 3\n",
    "        \n",
    "# Use the nn package to define our loss function\n",
    "loss_fn=torch.nn.MSELoss()\n",
    "\n",
    "# Use the optim package to define an Optimizer\n",
    "\n",
    "learning_rate =1e-3\n",
    "#learning_rate =0.01\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "x_optimizer = torch.optim.Adam(x_model.parameters(), lr=learning_rate)\n",
    "y_optimizer = torch.optim.Adam(y_model.parameters(), lr=learning_rate)\n",
    "iterator_x = train_loader_x\n",
    "iterator_y = train_loader_y\n",
    "\n",
    "for i in trange(epoch):\n",
    "    \n",
    "    for (i_batch, sample_batch_x), (j_batch, sample_batch_y) in tqdm(zip(enumerate(iterator_x), enumerate(iterator_y)), total=3216):\n",
    "        inp_x, out_x = sample_batch_x\n",
    "        inp_y, out_y = sample_batch_y\n",
    "\n",
    "        in_x = torch.flatten(inp_x, start_dim=2)\n",
    "        out_x = torch.flatten(out_x, start_dim=2)\n",
    "        in_y = torch.flatten(inp_y, start_dim=2)\n",
    "        out_y = torch.flatten(out_y, start_dim=2)\n",
    "        \n",
    "        in_x = in_x.permute(0,2,1)\n",
    "        #out_x = out_x.permute(0,2,1)\n",
    "        in_y = in_y.permute(0,2,1)\n",
    "        #out_y = out_y.permute(0,2,1)\n",
    "        \n",
    "        in_x = in_x.float()\n",
    "        out_x = out_x.float()\n",
    "        in_y = in_y.float()\n",
    "        out_y = out_y.float()\n",
    "\n",
    "        if cuda_status:\n",
    "            in_x.to(device)\n",
    "            out_x.to(device)\n",
    "            in_y.to(device)\n",
    "            out_y.to(device)\n",
    "            \n",
    "            in_x = in_x.cuda()\n",
    "            out_x = out_x.cuda()\n",
    "            in_y = in_y.cuda()\n",
    "            out_y = out_y.cuda()\n",
    "\n",
    "        x_pred = None\n",
    "        # Forward pass: predict y by passing x to the model.    \n",
    "        x_pred = x_model(in_x)\n",
    "        #y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 4]))\n",
    "\n",
    "        # Compute the loss.\n",
    "        x_loss = loss_fn(x_pred, out_x)\n",
    "\n",
    "        # Before backward pass, zero outgradients to clear buffers  \n",
    "        x_optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient w.r.t modelparameters\n",
    "        x_loss.backward()\n",
    "\n",
    "        # makes an gradient descent step to update its parameters\n",
    "        x_optimizer.step()\n",
    "        \n",
    "        y_pred = None\n",
    "        # Forward pass: predict y by passing x to the model.    \n",
    "        y_pred = y_model(in_y)\n",
    "        #y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 4]))\n",
    "\n",
    "        # Compute the loss.\n",
    "        y_loss = loss_fn(y_pred, out_y)\n",
    "\n",
    "        # Before backward pass, zero outgradients to clear buffers  \n",
    "        y_optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient w.r.t modelparameters\n",
    "        y_loss.backward()\n",
    "\n",
    "        # makes an gradient descent step to update its parameters\n",
    "        y_optimizer.step()\n",
    "        \n",
    "        print(str(torch.sqrt(x_loss)) + \" \" + str(torch.sqrt(y_loss)))\n",
    "\n",
    "        if i_batch == 3216:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './models/2epochCNN-LSTM.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/6epochmodel.pt')\n",
    "model.eval()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Submission output\n",
    "writeCSV = True\n",
    "val_path = \"./new_val_in/new_val_in\"\n",
    "\n",
    "if writeCSV:\n",
    "    \n",
    "    dataset = ArgoverseDataset(data_path=val_path)\n",
    "    test_loader = DataLoader(dataset,batch_size=batch_sz, shuffle = False, collate_fn=test_collate, num_workers=0)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(tqdm(test_loader)):\n",
    "            inp, scene_ids, track_ids, agent_ids = sample_batch\n",
    "\n",
    "            if cuda_status:\n",
    "                model = model.cuda()\n",
    "                x = inp.permute(0,3,1,2).float().cuda()\n",
    "            else:\n",
    "                x = inp.permute(0,3,1,2).float()\n",
    "\n",
    "            y_pred = None\n",
    "\n",
    "            # Forward pass: predict y by passing x to the model.    \n",
    "            y_pred = model(x)\n",
    "            y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 4]))\n",
    "            \n",
    "            for i in range(batch_sz):\n",
    "                row = []\n",
    "                row.append(scene_ids[i].item())\n",
    "                curr = y_pred[i]\n",
    "                \n",
    "                agent_id = agent_ids[i]\n",
    "                \n",
    "                for j in range(30):\n",
    "                    vehicle_index = 0\n",
    "                    found = False\n",
    "                    while not found:\n",
    "                        if track_ids[i][vehicle_index][j][0] == agent_id:\n",
    "                            found = True\n",
    "                        else:\n",
    "                            vehicle_index += 1\n",
    "\n",
    "                    row.append(str(curr[vehicle_index][j][0].item()))\n",
    "                    row.append(str(curr[vehicle_index][j][1].item()))\n",
    "                    \n",
    "                data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, columns = ['ID','v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','v11','v12','v13','v14','v15','v16','v17','v18','v19','v20','v21','v22','v23','v24','v25','v26','v27','v28','v29','v30','v31','v32','v33','v34','v35','v36','v37','v38','v39','v40','v41','v42','v43','v44','v45','v46','v47','v48','v49','v50','v51','v52','v53','v54','v55','v56','v57','v58','v59','v60'])\n",
    "    print(df)\n",
    "    df.to_csv('submission.csv', index=False)\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
