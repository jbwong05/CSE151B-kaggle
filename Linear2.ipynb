{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "\n",
    "cuda_status = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 64\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [scene['p_out'] for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, out, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "def test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(76, 66),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(66, 66),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(66, 60)\n",
    ")\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46620d4876494954ae6036e5130cde29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3218.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52dcfe0e7e64ff19764a463564c82c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.8564219474792483\n",
      "2.2956552505493164\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "agent_id = 0\n",
    "epoch = 3\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out, scene_ids, track_ids, agent_ids = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])\n",
    "        \n",
    "# Use the nn package to define our loss function\n",
    "loss_fn=torch.nn.MSELoss()\n",
    "\n",
    "# Use the optim package to define an Optimizer\n",
    "\n",
    "learning_rate =1e-3\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "iterator = tqdm(val_loader)\n",
    "\n",
    "for i in trange(epoch):\n",
    "    \n",
    "    for i_batch, sample_batch in enumerate(iterator):\n",
    "        inp, out, scene_ids, track_ids, agent_ids = sample_batch\n",
    "        \"\"\"TODO:\n",
    "          Deep learning model\n",
    "          training routine\n",
    "        \"\"\"\n",
    "        if i_batch >= 3216:\n",
    "            #show_sample_batch(sample_batch, agent_id)\n",
    "            #show_sample_batch([inp, y_pred.cpu().detach(), scene_ids, track_ids, agent_ids], agent_id)\n",
    "            continue\n",
    "        \n",
    "        x = torch.flatten(inp, start_dim=2)\n",
    "\n",
    "        x = x.float()\n",
    "        y = out.float()\n",
    "\n",
    "        if cuda_status:\n",
    "            #model = model.cuda()\n",
    "            #x = inp.cuda()\n",
    "            #y = out.cuda()\n",
    "            x.to(device)\n",
    "            y.to(device)\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        y_pred = None\n",
    "\n",
    "        # Forward pass: predict y by passing x to the model.    \n",
    "        y_pred = model(x)\n",
    "        y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 2]))\n",
    "\n",
    "        # Compute the loss.\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        # Before backward pass, zero outgradients to clear buffers  \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient w.r.t modelparameters\n",
    "        loss.backward()\n",
    "\n",
    "        # makes an gradient descent step to update its parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(torch.sqrt(loss).item(), end='\\r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './models/3epochlinearonlyxy.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/6epochmodel.pt')\n",
    "model.eval()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408d80c20b104a0090657490287c9362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         ID                  v1                  v2                  v3  \\\n",
      "0     10002  1709.4820556640625  403.37164306640625    1685.02783203125   \n",
      "1     10015   724.8670654296875  1224.2093505859375   706.3023681640625   \n",
      "2     10019     573.87744140625   1242.388427734375   565.7113037109375   \n",
      "3     10028  1681.4075927734375    382.878173828125   1657.484130859375   \n",
      "4      1003    2102.39892578125    682.169677734375      2095.974609375   \n",
      "...     ...                 ...                 ...                 ...   \n",
      "3195   9897   256.8836669921875   803.7613525390625   257.3318176269531   \n",
      "3196     99      588.0791015625   1144.500732421875    575.885986328125   \n",
      "3197   9905   1746.699462890625   484.8403015136719  1729.4871826171875   \n",
      "3198   9910     572.97119140625  1285.6861572265625     565.48486328125   \n",
      "3199   9918    587.013427734375   1150.477294921875    574.506591796875   \n",
      "\n",
      "                      v4                  v5                  v6  \\\n",
      "0      430.2334899902344    1748.46533203125   367.5746154785156   \n",
      "1       1221.36767578125   724.4959106445312  1210.5560302734375   \n",
      "2      1242.578857421875   574.7493286132812  1235.7030029296875   \n",
      "3     407.51983642578125   1724.455810546875   343.5773620605469   \n",
      "4      685.9418334960938      2111.978515625   669.5182495117188   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   805.0848999023438  257.08929443359375   803.6149291992188   \n",
      "3196  1142.6094970703125   587.5682373046875     1135.5673828125   \n",
      "3197   501.3996887207031  1766.8233642578125   460.3404541015625   \n",
      "3198   1285.871337890625   573.6544189453125  1279.3184814453125   \n",
      "3199          1147.90625   585.7872924804688  1141.9515380859375   \n",
      "\n",
      "                      v7                  v8                  v9  ...  \\\n",
      "0           1770.0703125  396.69952392578125  1762.9686279296875  ...   \n",
      "1      727.7992553710938   1212.751708984375   715.3432006835938  ...   \n",
      "2       577.675537109375   1237.399169921875   570.9913330078125  ...   \n",
      "3     1746.9320068359375   370.7542419433594  1739.7755126953125  ...   \n",
      "4      2115.063232421875   659.7283935546875    2111.31591796875  ...   \n",
      "...                  ...                 ...                 ...  ...   \n",
      "3195   258.0342712402344   804.6759033203125     258.15087890625  ...   \n",
      "3196         588.8359375  1136.2449951171875   580.4707641601562  ...   \n",
      "3197     1780.2744140625  473.13494873046875    1776.11181640625  ...   \n",
      "3198   575.6947631835938   1280.317626953125   569.5753173828125  ...   \n",
      "3199   585.3726196289062  1141.4923095703125    576.906982421875  ...   \n",
      "\n",
      "                     v51                 v52                v53  \\\n",
      "0     1730.2406005859375  463.72869873046875      1709.19921875   \n",
      "1      724.1597900390625  1212.4112548828125  718.4716186523438   \n",
      "2      576.4009399414062  1236.7711181640625  572.4141235351562   \n",
      "3     1702.6563720703125   444.8864440917969  1680.570556640625   \n",
      "4      2118.138916015625   698.7056274414062   2095.66845703125   \n",
      "...                  ...                 ...                ...   \n",
      "3195  258.41839599609375   804.1431274414062  257.4958801269531   \n",
      "3196   586.6959228515625   1135.889892578125     582.0361328125   \n",
      "3197   1761.829833984375   526.2682495117188   1740.82568359375   \n",
      "3198   574.5226440429688     1280.2763671875  571.1193237304688   \n",
      "3199     583.21533203125     1140.7763671875  578.1798706054688   \n",
      "\n",
      "                     v54                 v55                 v56  \\\n",
      "0     383.82550048828125    1736.53466796875  395.39508056640625   \n",
      "1       1214.89990234375    713.045654296875       1228.41015625   \n",
      "2          1237.66796875   572.1889038085938  1245.8057861328125   \n",
      "3      358.6512451171875  1708.7564697265625   367.7218322753906   \n",
      "4      668.7616577148438      2092.490234375       674.302734375   \n",
      "...                  ...                 ...                 ...   \n",
      "3195     803.11181640625   259.9224548339844   804.1417846679688   \n",
      "3196   1135.621337890625   579.5476684570312   1145.487060546875   \n",
      "3197  470.75323486328125  1751.9283447265625   480.4465637207031   \n",
      "3198    1280.26318359375   570.7002563476562  1287.7406005859375   \n",
      "3199      1139.251953125   575.3325805664062  1149.1112060546875   \n",
      "\n",
      "                     v57                 v58                 v59  \\\n",
      "0      1739.119873046875    427.558837890625  1791.0023193359375   \n",
      "1      728.3916625976562    1210.48681640625   726.4088745117188   \n",
      "2      577.6858520507812   1236.145751953125   575.9901123046875   \n",
      "3         1710.212890625     404.07080078125  1767.3753662109375   \n",
      "4      2110.483642578125   683.0758666992188     2123.7412109375   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   258.3934326171875   803.8252563476562   257.2585144042969   \n",
      "3196   590.5332641601562  1133.7835693359375   588.4226684570312   \n",
      "3197  1764.5711669921875     499.56005859375  1796.4410400390625   \n",
      "3198    575.492431640625  1279.3006591796875   573.7774658203125   \n",
      "3199   588.8612060546875   1137.611083984375   586.5585327148438   \n",
      "\n",
      "                     v60  \n",
      "0      396.6579284667969  \n",
      "1     1226.3677978515625  \n",
      "2       1244.14208984375  \n",
      "3      371.6754455566406  \n",
      "4      676.9738159179688  \n",
      "...                  ...  \n",
      "3195    803.756103515625  \n",
      "3196   1144.093017578125  \n",
      "3197        481.80078125  \n",
      "3198   1286.473388671875  \n",
      "3199  1147.9949951171875  \n",
      "\n",
      "[3200 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Submission output\n",
    "writeCSV = True\n",
    "val_path = \"./new_val_in/new_val_in\"\n",
    "\n",
    "if writeCSV:\n",
    "    \n",
    "    dataset = ArgoverseDataset(data_path=val_path)\n",
    "    test_loader = DataLoader(dataset,batch_size=batch_sz, shuffle = False, collate_fn=test_collate, num_workers=0)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(tqdm(test_loader)):\n",
    "            inp, scene_ids, track_ids, agent_ids = sample_batch\n",
    "            inp = torch.flatten(inp, start_dim=2)\n",
    "\n",
    "            if cuda_status:\n",
    "                model = model.cuda()\n",
    "                x = inp.cuda()\n",
    "            else:\n",
    "                x = inp\n",
    "\n",
    "            y_pred = None\n",
    "\n",
    "            # Forward pass: predict y by passing x to the model.    \n",
    "            y_pred = model(x.float())\n",
    "            y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 2]))\n",
    "            \n",
    "            for i in range(batch_sz):\n",
    "                row = []\n",
    "                row.append(scene_ids[i].item())\n",
    "                curr = y_pred[i]\n",
    "                \n",
    "                agent_id = agent_ids[i]\n",
    "                \n",
    "                for j in range(30):\n",
    "                    vehicle_index = 0\n",
    "                    found = False\n",
    "                    while not found:\n",
    "                        if track_ids[i][vehicle_index][j][0] == agent_id:\n",
    "                            found = True\n",
    "                        else:\n",
    "                            vehicle_index += 1\n",
    "\n",
    "                    row.append(str(curr[vehicle_index][j][0].item()))\n",
    "                    row.append(str(curr[vehicle_index][j][1].item()))\n",
    "                    \n",
    "                data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, columns = ['ID','v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','v11','v12','v13','v14','v15','v16','v17','v18','v19','v20','v21','v22','v23','v24','v25','v26','v27','v28','v29','v30','v31','v32','v33','v34','v35','v36','v37','v38','v39','v40','v41','v42','v43','v44','v45','v46','v47','v48','v49','v50','v51','v52','v53','v54','v55','v56','v57','v58','v59','v60'])\n",
    "    print(df)\n",
    "    df.to_csv('submission.csv', index=False)\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
