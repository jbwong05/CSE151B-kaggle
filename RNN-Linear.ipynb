{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "\n",
    "cuda_status = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 64\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, out, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "def test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLinear(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = torch.nn.RNN(240, 200, nonlinearity='relu', batch_first=True)\n",
    "        self.linear1 = torch.nn.Linear(3800,5500)\n",
    "        self.linear2 = torch.nn.Linear(5500,5500)\n",
    "        self.linear3 = torch.nn.Linear(5500,7200)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0,2,1,3)\n",
    "        x = torch.flatten(x, start_dim=2)\n",
    "        x, _ = self.rnn(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        x = torch.reshape(x, torch.Size([64, 60, 30, 4]))\n",
    "        return x\n",
    "\n",
    "model = RNNLinear()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/1epochAdam.pt')\n",
    "model.train()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc2692a82e543ecacc4eb4e0ffe32b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3218.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21b019052a444c5833eb14d9d4bd30c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.032214164733887\n",
      "15.797248840332031\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "agent_id = 0\n",
    "epoch = 3\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out, scene_ids, track_ids, agent_ids = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])\n",
    "        \n",
    "# Use the nn package to define our loss function\n",
    "loss_fn=torch.nn.MSELoss()\n",
    "\n",
    "# Use the optim package to define an Optimizer\n",
    "\n",
    "learning_rate =1e-3\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "iterator = tqdm(val_loader)\n",
    "\n",
    "for i in trange(epoch):\n",
    "    \n",
    "    for i_batch, sample_batch in enumerate(iterator):\n",
    "        inp, out, scene_ids, track_ids, agent_ids = sample_batch\n",
    "        \"\"\"TODO:\n",
    "          Deep learning model\n",
    "          training routine\n",
    "        \"\"\"\n",
    "        #x = torch.flatten(inp, start_dim=2)\n",
    "        \n",
    "        if i_batch >= 3216:\n",
    "            #show_sample_batch(sample_batch, agent_id)\n",
    "            #show_sample_batch([inp, y_pred.cpu().detach(), scene_ids, track_ids, agent_ids], agent_id)\n",
    "            continue\n",
    "\n",
    "        x = inp.float()\n",
    "        y = out.float()\n",
    "\n",
    "        if cuda_status:\n",
    "            #model = model.cuda()\n",
    "            #x = inp.cuda()\n",
    "            #y = out.cuda()\n",
    "            x.to(device)\n",
    "            y.to(device)\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        y_pred = None\n",
    "\n",
    "        # Forward pass: predict y by passing x to the model.    \n",
    "        y_pred = model(x)\n",
    "        #y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 4]))\n",
    "\n",
    "        # Compute the loss.\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        # Before backward pass, zero outgradients to clear buffers  \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient w.r.t modelparameters\n",
    "        loss.backward()\n",
    "\n",
    "        # makes an gradient descent step to update its parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(torch.sqrt(loss).item(), end='\\r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './models/3epochlinear14rsm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/6epochmodel.pt')\n",
    "model.eval()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e673f93abd2e40d9a512bb62b3a982b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         ID                  v1                  v2                  v3  \\\n",
      "0     10002  1805.1666259765625  453.83697509765625  1807.8082275390625   \n",
      "1     10015   762.0003051757812   1272.732177734375   762.7683715820312   \n",
      "2     10019   604.6919555664062   1306.489990234375    606.215087890625   \n",
      "3     10028  1807.4989013671875   375.2181091308594    1812.63427734375   \n",
      "4      1003       2104.87890625   666.6755981445312   2106.442626953125   \n",
      "...     ...                 ...                 ...                 ...   \n",
      "3195   9897  261.19036865234375   788.8668823242188  261.38482666015625   \n",
      "3196     99   582.0120239257812  1187.8199462890625     583.74560546875   \n",
      "3197   9905   1831.308837890625  489.45794677734375         1837.546875   \n",
      "3198   9910    537.521728515625       1368.44140625   538.2230834960938   \n",
      "3199   9918     635.85205078125   1190.091064453125   635.1288452148438   \n",
      "\n",
      "                      v4                  v5                  v6  \\\n",
      "0      442.4272155761719   1804.520751953125  450.92364501953125   \n",
      "1     1273.9066162109375   761.8187866210938     1273.1630859375   \n",
      "2      1306.399658203125    605.443603515625  1305.8431396484375   \n",
      "3     378.41827392578125   1812.739501953125      379.2900390625   \n",
      "4      668.9313354492188     2108.0244140625   667.1297607421875   \n",
      "...                  ...                 ...                 ...   \n",
      "3195    789.156005859375  261.45697021484375   788.6749877929688   \n",
      "3196   1187.238525390625    582.923095703125      1188.072265625   \n",
      "3197  483.34503173828125  1834.7908935546875  485.18817138671875   \n",
      "3198   1367.275634765625   538.0446166992188  1369.7652587890625   \n",
      "3199  1193.7342529296875   636.3960571289062  1192.1185302734375   \n",
      "\n",
      "                      v7                  v8                  v9  ...  \\\n",
      "0     1803.9752197265625   446.4075927734375   1806.004638671875  ...   \n",
      "1      761.6489868164062   1273.452392578125   759.7437744140625  ...   \n",
      "2      605.0897216796875         1305.609375   604.7781982421875  ...   \n",
      "3       1818.02880859375   380.4508972167969   1812.327392578125  ...   \n",
      "4      2108.293212890625     667.35888671875   2106.737060546875  ...   \n",
      "...                  ...                 ...                 ...  ...   \n",
      "3195   261.0000915527344   788.8739013671875   260.3067932128906  ...   \n",
      "3196    583.230712890625  1187.8804931640625      584.5986328125  ...   \n",
      "3197  1835.9920654296875  484.31915283203125  1835.9925537109375  ...   \n",
      "3198   537.2303466796875   1370.913330078125   539.8484497070312  ...   \n",
      "3199          635.015625  1192.9407958984375   636.5687255859375  ...   \n",
      "\n",
      "                    v51                 v52                 v53  \\\n",
      "0      1815.85595703125    449.276611328125  1810.6317138671875   \n",
      "1     759.8088989257812   1269.982666015625   760.5758056640625   \n",
      "2     604.5188598632812   1302.805419921875   603.4187622070312   \n",
      "3      1819.48681640625    382.892822265625       1821.91015625   \n",
      "4      2109.57861328125   673.1624755859375   2112.240966796875   \n",
      "...                 ...                 ...                 ...   \n",
      "3195  261.0710144042969   786.5297241210938  260.89874267578125   \n",
      "3196  581.9198608398438   1184.409912109375        582.83984375   \n",
      "3197   1840.60791015625  488.71234130859375    1841.91357421875   \n",
      "3198  537.9498291015625     1371.3056640625   538.1969604492188   \n",
      "3199  635.9530639648438  1189.4774169921875   634.9172973632812   \n",
      "\n",
      "                     v54                 v55                 v56  \\\n",
      "0      447.3069763183594  1801.9188232421875    445.307861328125   \n",
      "1      1271.011962890625   759.9038696289062  1270.0762939453125   \n",
      "2      1303.498779296875   603.1607666015625     1303.0732421875   \n",
      "3     380.86639404296875        1827.7734375    384.630126953125   \n",
      "4       669.031005859375   2113.157470703125     672.51806640625   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   786.4056396484375  260.70379638671875   785.9971923828125   \n",
      "3196  1185.5469970703125   581.0173950195312   1185.342529296875   \n",
      "3197  485.33355712890625     1835.4443359375   489.3004150390625   \n",
      "3198  1369.0445556640625   541.7052001953125  1367.4488525390625   \n",
      "3199  1189.9693603515625   637.6873779296875    1187.62353515625   \n",
      "\n",
      "                     v57                 v58                 v59  \\\n",
      "0      1806.643310546875   445.0809631347656  1801.3795166015625   \n",
      "1       761.627197265625    1269.66845703125     759.00634765625   \n",
      "2         603.2080078125  1303.1143798828125     603.88623046875   \n",
      "3     1826.5274658203125   377.5404357910156   1819.017333984375   \n",
      "4       2112.01220703125     670.71435546875     2112.4541015625   \n",
      "...                  ...                 ...                 ...   \n",
      "3195  260.82525634765625     786.25732421875  260.31097412109375   \n",
      "3196   583.6732788085938   1185.623291015625   582.4534301757812   \n",
      "3197   1840.816162109375   488.4317321777344  1837.9390869140625   \n",
      "3198    536.475341796875   1371.439208984375   537.2672119140625   \n",
      "3199   637.2181396484375  1189.8851318359375   638.3118286132812   \n",
      "\n",
      "                     v60  \n",
      "0     447.78314208984375  \n",
      "1     1269.9276123046875  \n",
      "2      1302.601318359375  \n",
      "3      380.7572326660156  \n",
      "4      673.0923461914062  \n",
      "...                  ...  \n",
      "3195   786.5408325195312  \n",
      "3196  1184.9935302734375  \n",
      "3197  489.06536865234375  \n",
      "3198   1369.174560546875  \n",
      "3199    1189.34521484375  \n",
      "\n",
      "[3200 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Submission output\n",
    "writeCSV = True\n",
    "val_path = \"./new_val_in/new_val_in\"\n",
    "\n",
    "if writeCSV:\n",
    "    \n",
    "    dataset = ArgoverseDataset(data_path=val_path)\n",
    "    test_loader = DataLoader(dataset,batch_size=batch_sz, shuffle = False, collate_fn=test_collate, num_workers=0)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(tqdm(test_loader)):\n",
    "            inp, scene_ids, track_ids, agent_ids = sample_batch\n",
    "\n",
    "            if cuda_status:\n",
    "                model = model.cuda()\n",
    "                x = inp.cuda()\n",
    "            else:\n",
    "                x = inp\n",
    "\n",
    "            y_pred = None\n",
    "\n",
    "            # Forward pass: predict y by passing x to the model.    \n",
    "            y_pred = model(x.float())\n",
    "            \n",
    "            for i in range(batch_sz):\n",
    "                row = []\n",
    "                row.append(scene_ids[i].item())\n",
    "                curr = y_pred[i]\n",
    "                \n",
    "                agent_id = agent_ids[i]\n",
    "                \n",
    "                for j in range(30):\n",
    "                    vehicle_index = 0\n",
    "                    found = False\n",
    "                    while not found:\n",
    "                        if track_ids[i][vehicle_index][j][0] == agent_id:\n",
    "                            found = True\n",
    "                        else:\n",
    "                            vehicle_index += 1\n",
    "\n",
    "                    row.append(str(curr[vehicle_index][j][0].item()))\n",
    "                    row.append(str(curr[vehicle_index][j][1].item()))\n",
    "                    \n",
    "                data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, columns = ['ID','v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','v11','v12','v13','v14','v15','v16','v17','v18','v19','v20','v21','v22','v23','v24','v25','v26','v27','v28','v29','v30','v31','v32','v33','v34','v35','v36','v37','v38','v39','v40','v41','v42','v43','v44','v45','v46','v47','v48','v49','v50','v51','v52','v53','v54','v55','v56','v57','v58','v59','v60'])\n",
    "    print(df)\n",
    "    df.to_csv('submission.csv', index=False)\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
