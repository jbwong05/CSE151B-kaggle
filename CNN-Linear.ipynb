{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "\n",
    "cuda_status = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 64\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, out, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "def test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLinear(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(4, 64, (3,3))\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.maxPool = torch.nn.MaxPool2d((3,3), stride=2)\n",
    "        self.conv2 = torch.nn.Conv2d(64, 128, (3,3))\n",
    "        self.linear = torch.nn.Linear(3072, 4096)\n",
    "        self.linear2 = torch.nn.Linear(4096, 4096)\n",
    "        self.linear3 = torch.nn.Linear(4096, 7200)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.maxPool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.maxPool(x)\n",
    "        x = torch.flatten(x, start_dim = 1)\n",
    "        x = self.relu(self.linear(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        x = torch.reshape(x, torch.Size([64, 60, 30, 4]))\n",
    "        return x\n",
    "\n",
    "model = CNNLinear()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/1epochAdam.pt')\n",
    "model.train()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070041ca3c9b44789c1e901e7d4c1b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3218.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990df13ad27e4017962491d8e109f846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "agent_id = 0\n",
    "epoch = 5\n",
    "        \n",
    "# Use the nn package to define our loss function\n",
    "loss_fn=torch.nn.MSELoss()\n",
    "\n",
    "# Use the optim package to define an Optimizer\n",
    "\n",
    "learning_rate =1e-3\n",
    "#learning_rate =0.01\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "iterator = tqdm(val_loader, total=int(len(val_loader)))\n",
    "\n",
    "for i in trange(epoch):\n",
    "    \n",
    "    for i_batch, sample_batch in enumerate(iterator):\n",
    "        inp, out, scene_ids, track_ids, agent_ids = sample_batch\n",
    "        \"\"\"TODO:\n",
    "          Deep learning model\n",
    "          training routine\n",
    "        \"\"\"\n",
    "        x = inp.permute(0,3,1,2).float()\n",
    "        x = x.float()\n",
    "        y = out.float()\n",
    "\n",
    "        if cuda_status:\n",
    "            x.to(device)\n",
    "            y.to(device)\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        y_pred = None\n",
    "        # Forward pass: predict y by passing x to the model.    \n",
    "        y_pred = model(x)\n",
    "        #y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 4]))\n",
    "\n",
    "        # Compute the loss.\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        # Before backward pass, zero outgradients to clear buffers  \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient w.r.t modelparameters\n",
    "        loss.backward()\n",
    "\n",
    "        # makes an gradient descent step to update its parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iterator.set_postfix(loss=(torch.sqrt(loss)))\n",
    "\n",
    "        if i_batch == 3216:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type CNNLinear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, './models/5epochCNN-Linear.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/6epochmodel.pt')\n",
    "model.eval()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4857d7118daa4bfdb1ec5c79c015658c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         ID                  v1                  v2                 v3  \\\n",
      "0     10002   71.14740753173828  -36.60054016113281  72.37542724609375   \n",
      "1     10015   731.2589721679688  1251.0989990234375  730.2142333984375   \n",
      "2     10019        592.25390625   1267.733154296875   593.202880859375   \n",
      "3     10028     1872.9404296875   590.5484619140625  1870.108154296875   \n",
      "4      1003   2072.195556640625   672.5189819335938  2071.495361328125   \n",
      "...     ...                 ...                 ...                ...   \n",
      "3195   9897  260.39105224609375   786.1233520507812   260.207275390625   \n",
      "3196     99   587.2035522460938  1112.3070068359375  586.9341430664062   \n",
      "3197   9905  1717.4403076171875   482.1740417480469    1717.5478515625   \n",
      "3198   9910   611.5181274414062    1239.44091796875  612.3093872070312   \n",
      "3199   9918   647.5636596679688   1099.627197265625  648.7333374023438   \n",
      "\n",
      "                      v4                  v5                  v6  \\\n",
      "0     -34.55113983154297   72.58527374267578  -32.59185028076172   \n",
      "1       1250.48681640625   732.6236572265625  1250.3199462890625   \n",
      "2       1268.32373046875   593.3294677734375   1267.201416015625   \n",
      "3      589.8369750976562    1865.84716796875    596.609130859375   \n",
      "4      672.3208618164062    2070.88525390625   673.8826904296875   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   785.6935424804688   260.4263610839844    785.680419921875   \n",
      "3196    1112.46337890625    587.138427734375  1112.9747314453125   \n",
      "3197  482.30755615234375  1722.6700439453125   487.1846923828125   \n",
      "3198  1240.0023193359375   612.7594604492188   1240.328857421875   \n",
      "3199  1101.0294189453125   648.9243774414062  1099.8660888671875   \n",
      "\n",
      "                      v7                  v8                 v9  ...  \\\n",
      "0      72.77533721923828  -33.67729187011719  67.07716369628906  ...   \n",
      "1        730.47900390625  1250.7120361328125  730.7781372070312  ...   \n",
      "2        592.08154296875    1266.27685546875  592.9146728515625  ...   \n",
      "3     1870.7762451171875   590.3875122070312  1871.287353515625  ...   \n",
      "4      2073.710693359375    672.055419921875   2073.16357421875  ...   \n",
      "...                  ...                 ...                ...  ...   \n",
      "3195   260.1911926269531   785.4061889648438  260.2029724121094  ...   \n",
      "3196   586.9359741210938   1111.810302734375  587.1783447265625  ...   \n",
      "3197    1720.33447265625   479.2825012207031    1719.8857421875  ...   \n",
      "3198   612.3364868164062   1241.220458984375   612.067626953125  ...   \n",
      "3199   647.4266967773438   1098.154541015625  647.6070556640625  ...   \n",
      "\n",
      "                     v51                 v52                 v53  \\\n",
      "0      73.34164428710938  -33.33655548095703   76.81967163085938   \n",
      "1      730.8599853515625   1248.084716796875   729.7891845703125   \n",
      "2        591.13232421875    1266.31982421875   591.9873657226562   \n",
      "3        1869.6708984375   595.2520751953125    1877.57080078125   \n",
      "4        2077.4150390625   675.6202392578125    2074.47607421875   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   260.1823425292969   783.8238525390625   259.3914794921875   \n",
      "3196   586.4703369140625  1112.6004638671875   586.2103881835938   \n",
      "3197  1725.3001708984375   488.0594787597656  1725.8546142578125   \n",
      "3198   612.7009887695312  1239.5831298828125   611.9784545898438   \n",
      "3199   650.0067749023438  1096.7540283203125   648.4014892578125   \n",
      "\n",
      "                     v54                v55                  v56  \\\n",
      "0     -35.99225616455078  75.40743255615234  -34.278106689453125   \n",
      "1     1247.0198974609375  729.6162719726562   1246.6300048828125   \n",
      "2      1265.942626953125     590.7958984375       1264.521484375   \n",
      "3          599.083984375  1872.254638671875    594.7156372070312   \n",
      "4       677.647216796875   2076.60986328125    676.4025268554688   \n",
      "...                  ...                ...                  ...   \n",
      "3195   783.6375122070312  259.6135559082031    783.3541870117188   \n",
      "3196  1112.3387451171875   586.786376953125    1110.642333984375   \n",
      "3197   489.4591369628906  1724.785400390625   487.70550537109375   \n",
      "3198    1239.66552734375  612.9137573242188     1240.85791015625   \n",
      "3199    1096.98388671875  647.9622192382812   1099.6488037109375   \n",
      "\n",
      "                    v57                 v58                 v59  \\\n",
      "0       74.566162109375  -35.28837203979492   76.55560302734375   \n",
      "1     728.9133911132812  1248.0162353515625    730.503662109375   \n",
      "2     591.4708251953125    1265.08251953125   592.2540283203125   \n",
      "3       1872.8916015625     601.24853515625  1872.3675537109375   \n",
      "4      2075.62646484375   676.2922973632812   2076.156494140625   \n",
      "...                 ...                 ...                 ...   \n",
      "3195  259.6761779785156   783.4605102539062  259.85528564453125   \n",
      "3196  587.1961669921875  1112.1727294921875   587.4868774414062   \n",
      "3197  1729.260009765625    484.050537109375     1723.7470703125   \n",
      "3198   611.345947265625  1240.1612548828125    611.560302734375   \n",
      "3199   648.488037109375   1098.293701171875   648.6130981445312   \n",
      "\n",
      "                      v60  \n",
      "0     -33.963592529296875  \n",
      "1      1247.6055908203125  \n",
      "2      1265.5635986328125  \n",
      "3       595.7388916015625  \n",
      "4       678.4100341796875  \n",
      "...                   ...  \n",
      "3195    783.4003295898438  \n",
      "3196       1111.232421875  \n",
      "3197    490.2777404785156  \n",
      "3198    1239.237548828125  \n",
      "3199     1096.08740234375  \n",
      "\n",
      "[3200 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Submission output\n",
    "writeCSV = True\n",
    "val_path = \"./new_val_in/new_val_in\"\n",
    "\n",
    "if writeCSV:\n",
    "    \n",
    "    dataset = ArgoverseDataset(data_path=val_path)\n",
    "    test_loader = DataLoader(dataset,batch_size=batch_sz, shuffle = False, collate_fn=test_collate, num_workers=0)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(tqdm(test_loader)):\n",
    "            inp, scene_ids, track_ids, agent_ids = sample_batch\n",
    "\n",
    "            if cuda_status:\n",
    "                model = model.cuda()\n",
    "                x = inp.permute(0,3,1,2).float().cuda()\n",
    "            else:\n",
    "                x = inp.permute(0,3,1,2).float()\n",
    "\n",
    "            y_pred = None\n",
    "\n",
    "            # Forward pass: predict y by passing x to the model.    \n",
    "            y_pred = model(x)\n",
    "            y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 4]))\n",
    "            \n",
    "            for i in range(batch_sz):\n",
    "                row = []\n",
    "                row.append(scene_ids[i].item())\n",
    "                curr = y_pred[i]\n",
    "                \n",
    "                agent_id = agent_ids[i]\n",
    "                \n",
    "                for j in range(30):\n",
    "                    vehicle_index = 0\n",
    "                    found = False\n",
    "                    while not found:\n",
    "                        if track_ids[i][vehicle_index][j][0] == agent_id:\n",
    "                            found = True\n",
    "                        else:\n",
    "                            vehicle_index += 1\n",
    "\n",
    "                    row.append(str(curr[vehicle_index][j][0].item()))\n",
    "                    row.append(str(curr[vehicle_index][j][1].item()))\n",
    "                    \n",
    "                data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, columns = ['ID','v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','v11','v12','v13','v14','v15','v16','v17','v18','v19','v20','v21','v22','v23','v24','v25','v26','v27','v28','v29','v30','v31','v32','v33','v34','v35','v36','v37','v38','v39','v40','v41','v42','v43','v44','v45','v46','v47','v48','v49','v50','v51','v52','v53','v54','v55','v56','v57','v58','v59','v60'])\n",
    "    print(df)\n",
    "    df.to_csv('submission.csv', index=False)\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
