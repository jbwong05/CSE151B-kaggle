{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy as np\n",
    "import pickle\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "\n",
    "cuda_status = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 128\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [np.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [np.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    car_mask = [scene['car_mask'] for scene in batch]\n",
    "    \n",
    "    inp = torch.FloatTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    car_mask = torch.LongTensor(car_mask)\n",
    "    \n",
    "    #means = np.concatenate((np.full((60,19,1), 1474.6499039101423), np.full((60,19,1), 2175.5066745340428), np.full((60,19,1), 0.1489193408934845), np.full((60,19,1), -0.16994685542095994)), axis=2)\n",
    "    #stds = np.concatenate((np.full((60,19,1), 1283.2869100687803), np.full((60,19,1), 868.4994220908388), np.full((60,19,1), 4.313724916476951), np.full((60,19,1), 5.3678594328349645)), axis=2)\n",
    "    #inp = inp - means\n",
    "    #inp = inp / means\n",
    "    num_cars = np.zeros((inp.shape[0]))\n",
    "    offsets = np.zeros((inp.shape[0], 2))\n",
    "    \n",
    "    for i in range(inp.shape[0]):\n",
    "        num_vehicles = 0\n",
    "        for j in range(60):\n",
    "            if car_mask[i][j][0] == 1:\n",
    "                num_vehicles += 1\n",
    "        num_cars[i] = num_vehicles\n",
    "        \n",
    "        agent_id = agent_ids[i]\n",
    "        vehicle_index = 0\n",
    "        found = False\n",
    "        while not found:\n",
    "            if track_ids[i][vehicle_index][0][0] == agent_id:\n",
    "                found = True\n",
    "            else:\n",
    "                vehicle_index += 1\n",
    "        start_x = inp[i][vehicle_index][0][0]\n",
    "        start_y = inp[i][vehicle_index][0][1]\n",
    "        \n",
    "        offsets[i][0] = start_x\n",
    "        offsets[i][1] = start_y\n",
    "        \n",
    "        inp[i,0:num_vehicles,:,0] -= start_x\n",
    "        inp[i,0:num_vehicles,:,1] -= start_y\n",
    "        #out[i,j,:,0] -= start_x\n",
    "        #out[i,j,:,1] -= start_y\n",
    "        \n",
    "    offsets = torch.LongTensor(offsets)\n",
    "    num_cars = torch.LongTensor(num_cars)\n",
    "    return [inp, out, scene_ids, track_ids, agent_ids, car_mask, num_cars, offsets]\n",
    "\n",
    "def test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [np.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    car_mask = [scene['car_mask'] for scene in batch]\n",
    "    \n",
    "    inp = torch.FloatTensor(inp)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    car_mask = torch.LongTensor(car_mask)\n",
    "    \n",
    "    #means = np.concatenate((np.full((60,19,1), 1474.6499039101423), np.full((60,19,1), 2175.5066745340428), np.full((60,19,1), 0.1489193408934845), np.full((60,19,1), -0.16994685542095994)), axis=2)\n",
    "    #stds = np.concatenate((np.full((60,19,1), 1283.2869100687803), np.full((60,19,1), 868.4994220908388), np.full((60,19,1), 4.313724916476951), np.full((60,19,1), 5.3678594328349645)), axis=2)\n",
    "    #inp = inp - means\n",
    "    #inp = inp / means\n",
    "    num_cars = np.zeros((inp.shape[0]))\n",
    "    offsets = np.zeros((inp.shape[0], 2))\n",
    "    \n",
    "    for i in range(inp.shape[0]):\n",
    "        num_vehicles = 0\n",
    "        for j in range(60):\n",
    "            if car_mask[i][j][0] == 1:\n",
    "                num_vehicles += 1\n",
    "        num_cars[i] = num_vehicles\n",
    "        \n",
    "        agent_id = agent_ids[i]\n",
    "        vehicle_index = 0\n",
    "        found = False\n",
    "        while not found:\n",
    "            if track_ids[i][vehicle_index][0][0] == agent_id:\n",
    "                found = True\n",
    "            else:\n",
    "                vehicle_index += 1\n",
    "        start_x = inp[i][vehicle_index][0][0]\n",
    "        start_y = inp[i][vehicle_index][0][1]\n",
    "        \n",
    "        offsets[i][0] = start_x\n",
    "        offsets[i][1] = start_y\n",
    "        \n",
    "        inp[i,0:num_vehicles,:,0] -= start_x\n",
    "        inp[i,0:num_vehicles,:,1] -= start_y\n",
    "        #out[i,j,:,0] -= start_x\n",
    "        #out[i,j,:,1] -= start_y\n",
    "        \n",
    "    offsets = torch.LongTensor(offsets)\n",
    "    num_cars = torch.LongTensor(num_cars)\n",
    "    return [inp, scene_ids, track_ids, agent_ids, car_mask, num_cars, offsets]\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(76, 98),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(98, 98),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(98, 120)\n",
    ")\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac4a9b2b87945f8be423d1a6fe416e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bccd439a07c24ed48f62c7c84402550c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1608.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8e5c9663e74b65b00b28ad2bcee963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1608.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b4f4c0db864c4485b2c3552cc1eef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1608.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "agent_id = 0\n",
    "epoch = 3\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out, scene_ids, track_ids, agent_ids = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])\n",
    "        \n",
    "# Use the nn package to define our loss function\n",
    "loss_fn=torch.nn.MSELoss()\n",
    "\n",
    "# Use the optim package to define an Optimizer\n",
    "\n",
    "learning_rate =1e-3\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for i in trange(epoch):\n",
    "    iterator = tqdm(val_loader)\n",
    "    total = 0\n",
    "    count = 0\n",
    "    \n",
    "    for i_batch, sample_batch in enumerate(iterator):\n",
    "        inp, out, scene_ids, track_ids, agent_ids, car_mask, num_cars, offsets = sample_batch\n",
    "        \"\"\"TODO:\n",
    "          Deep learning model\n",
    "          training routine\n",
    "        \"\"\"\n",
    "        \n",
    "        x = torch.flatten(inp, start_dim=2)\n",
    "\n",
    "        x = x.float()\n",
    "        y = out.float()\n",
    "\n",
    "        if cuda_status:\n",
    "            #model = model.cuda()\n",
    "            #x = inp.cuda()\n",
    "            #y = out.cuda()\n",
    "            x.to(device)\n",
    "            y.to(device)\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        y_pred = None\n",
    "\n",
    "        # Forward pass: predict y by passing x to the model.    \n",
    "        y_pred = model(x)\n",
    "        y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 4]))\n",
    "        \n",
    "        for i in range(y_pred.shape[0]):\n",
    "            y_pred[i,0:num_cars[i],:,0] += offsets[i][0]\n",
    "            y_pred[i,0:num_cars[i],:,1] += offsets[i][1]\n",
    "\n",
    "        # Compute the loss.\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        total += torch.sqrt(loss).item()\n",
    "\n",
    "        # Before backward pass, zero outgradients to clear buffers  \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient w.r.t modelparameters\n",
    "        loss.backward()\n",
    "\n",
    "        # makes an gradient descent step to update its parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        #print(torch.sqrt(loss).item(), end='\\r')\n",
    "        iterator.set_postfix(loss=total / count, curr=torch.sqrt(loss).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './models/3epochlinearreoriented.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/6epochmodel.pt')\n",
    "model.eval()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4371f5662ccf4ec2a656456184cc53d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         ID                 v1                  v2                 v3  \\\n",
      "0     10002  2485.112548828125  286.67803955078125  2481.486083984375   \n",
      "1     10015  725.6087646484375    1230.42724609375  725.5308227539062   \n",
      "2     10019    574.95166015625   1246.204345703125  575.0689697265625   \n",
      "3     10028      2515.43359375   244.0506134033203     2511.755859375   \n",
      "4      1003  2124.853759765625   674.7344360351562   2120.89013671875   \n",
      "...     ...                ...                 ...                ...   \n",
      "3195   9897  256.3254089355469   808.0215454101562  256.4410095214844   \n",
      "3196     99  588.1023559570312  1155.5001220703125  588.2186889648438   \n",
      "3197   9905   1967.31396484375   411.7773742675781  1951.217041015625   \n",
      "3198   9910  574.8478393554688  1288.9544677734375  574.7374267578125   \n",
      "3199   9918   582.652099609375  1169.7017822265625   582.765380859375   \n",
      "\n",
      "                      v4                  v5                  v6  \\\n",
      "0      277.7186584472656   2486.538330078125     296.32763671875   \n",
      "1      1229.864013671875   725.4771118164062    1229.49951171875   \n",
      "2     1245.9515380859375   575.2005004882812  1245.8282470703125   \n",
      "3              233.90625      2517.138671875   252.6694793701172   \n",
      "4      673.0089721679688   2122.087646484375   673.6764526367188   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   807.8045654296875   256.5564270019531   807.6012573242188   \n",
      "3196  1154.7720947265625    588.325927734375   1154.081787109375   \n",
      "3197  407.05377197265625  1962.5015869140625  419.88470458984375   \n",
      "3198   1288.525146484375   574.6549682617188    1288.31103515625   \n",
      "3199   1168.679443359375   582.8748168945312  1167.7193603515625   \n",
      "\n",
      "                      v7                  v8                 v9  ...  \\\n",
      "0      2475.132568359375   275.8556213378906      2473.85546875  ...   \n",
      "1      725.4354248046875   1229.021240234375  725.4682006835938  ...   \n",
      "2       575.443115234375  1245.6363525390625  575.5990600585938  ...   \n",
      "3       2507.23095703125  233.99874877929688   2505.69775390625  ...   \n",
      "4       2120.33544921875      672.4228515625  2117.751220703125  ...   \n",
      "...                  ...                 ...                ...  ...   \n",
      "3195   256.8226623535156    807.369873046875  256.9374694824219  ...   \n",
      "3196   588.4751586914062  1153.3365478515625  588.6714477539062  ...   \n",
      "3197  1949.0194091796875  404.39617919921875   1954.93408203125  ...   \n",
      "3198       574.607421875  1287.9788818359375   574.592529296875  ...   \n",
      "3199   582.9475708007812   1166.690673828125  583.1974487304688  ...   \n",
      "\n",
      "                    v51                 v52                 v53  \\\n",
      "0     2502.983154296875  279.01934814453125   2492.417236328125   \n",
      "1      724.108154296875  1219.7073974609375   724.1753540039062   \n",
      "2     578.8519287109375   1242.335205078125   579.0619506835938   \n",
      "3      2523.99951171875   230.8981475830078   2514.661865234375   \n",
      "4      2096.89306640625   653.0509643554688   2097.833740234375   \n",
      "...                 ...                 ...                 ...   \n",
      "3195  260.2613220214844   803.0694580078125  260.39349365234375   \n",
      "3196  591.2714233398438    1137.99853515625   591.3890380859375   \n",
      "3197    1956.2275390625   403.7610778808594  1966.7901611328125   \n",
      "3198  572.6954345703125   1281.852783203125     572.75244140625   \n",
      "3199  585.3858032226562  1145.2528076171875   585.5030517578125   \n",
      "\n",
      "                     v54                v55                 v56  \\\n",
      "0     275.08184814453125   2497.23876953125   283.9032287597656   \n",
      "1      1219.315185546875  724.1016235351562   1218.931884765625   \n",
      "2     1242.1995849609375  579.2335205078125  1242.0684814453125   \n",
      "3      225.9677276611328  2519.552001953125  235.76541137695312   \n",
      "4       650.759033203125     2093.634765625       647.916015625   \n",
      "...                  ...                ...                 ...   \n",
      "3195   802.8450927734375  260.5846862792969   802.6967163085938   \n",
      "3196   1137.293212890625     591.5439453125  1136.6849365234375   \n",
      "3197  398.09210205078125  1953.609130859375   400.2254333496094   \n",
      "3198  1281.6051025390625  572.6478881835938       1281.35546875   \n",
      "3199  1144.2879638671875  585.6342163085938  1143.4117431640625   \n",
      "\n",
      "                     v57                 v58                 v59  \\\n",
      "0       2497.91845703125     264.42041015625       2518.41015625   \n",
      "1        723.93408203125     1218.5439453125    723.941162109375   \n",
      "2      579.3192749023438        1241.9453125     579.53173828125   \n",
      "3          2515.64453125   218.2100372314453   2539.895751953125   \n",
      "4      2091.432861328125   648.3416137695312   2093.927490234375   \n",
      "...                  ...                 ...                 ...   \n",
      "3195  260.72161865234375   802.4857177734375  260.89190673828125   \n",
      "3196   591.6306762695312   1135.966064453125     591.72509765625   \n",
      "3197    1946.27197265625  391.62078857421875     1960.9150390625   \n",
      "3198   572.4480590820312     1281.1142578125   572.4527587890625   \n",
      "3199   585.6912841796875    1142.43603515625   585.7467651367188   \n",
      "\n",
      "                     v60  \n",
      "0      271.9908447265625  \n",
      "1     1218.2554931640625  \n",
      "2     1241.8790283203125  \n",
      "3     224.43585205078125  \n",
      "4       648.230224609375  \n",
      "...                  ...  \n",
      "3195   802.3102416992188  \n",
      "3196     1135.3408203125  \n",
      "3197   397.3818054199219  \n",
      "3198  1280.9671630859375  \n",
      "3199  1141.5704345703125  \n",
      "\n",
      "[3200 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Submission output\n",
    "writeCSV = True\n",
    "val_path = \"./new_val_in/new_val_in\"\n",
    "\n",
    "if writeCSV:\n",
    "    \n",
    "    dataset = ArgoverseDataset(data_path=val_path)\n",
    "    test_loader = DataLoader(dataset,batch_size=64, shuffle = False, collate_fn=test_collate, num_workers=0)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(tqdm(test_loader)):\n",
    "            inp, scene_ids, track_ids, agent_ids, car_mask, num_cars, offsets = sample_batch\n",
    "            inp = torch.flatten(inp, start_dim=2)\n",
    "\n",
    "            if cuda_status:\n",
    "                model = model.cuda()\n",
    "                x = inp.cuda()\n",
    "            else:\n",
    "                x = inp\n",
    "\n",
    "            y_pred = None\n",
    "\n",
    "            # Forward pass: predict y by passing x to the model.    \n",
    "            y_pred = model(x.float())\n",
    "            y_pred = torch.reshape(y_pred, torch.Size([64, 60, 30, 4]))\n",
    "            \n",
    "            for i in range(y_pred.shape[0]):\n",
    "                y_pred[i,0:num_cars[i],:,0] += offsets[i][0]\n",
    "                y_pred[i,0:num_cars[i],:,1] += offsets[i][1]\n",
    "            \n",
    "            for i in range(64):\n",
    "                row = []\n",
    "                row.append(scene_ids[i].item())\n",
    "                curr = y_pred[i]\n",
    "                \n",
    "                agent_id = agent_ids[i]\n",
    "                \n",
    "                for j in range(30):\n",
    "                    vehicle_index = 0\n",
    "                    found = False\n",
    "                    while not found:\n",
    "                        if track_ids[i][vehicle_index][j][0] == agent_id:\n",
    "                            found = True\n",
    "                        else:\n",
    "                            vehicle_index += 1\n",
    "\n",
    "                    row.append(str(curr[vehicle_index][j][0].item()))\n",
    "                    row.append(str(curr[vehicle_index][j][1].item()))\n",
    "                    \n",
    "                data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, columns = ['ID','v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','v11','v12','v13','v14','v15','v16','v17','v18','v19','v20','v21','v22','v23','v24','v25','v26','v27','v28','v29','v30','v31','v32','v33','v34','v35','v36','v37','v38','v39','v40','v41','v42','v43','v44','v45','v46','v47','v48','v49','v50','v51','v52','v53','v54','v55','v56','v57','v58','v59','v60'])\n",
    "    print(df)\n",
    "    df.to_csv('submission.csv', index=False)\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
