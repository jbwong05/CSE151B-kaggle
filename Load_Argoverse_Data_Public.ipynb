{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "\n",
    "cuda_status = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 64\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, out, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "def test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8e2a0c9997476b8bffaa2e550e9b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926052e85c994209b57f3dbbd5e8e8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3218.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(593.2542, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(515.4708, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(338.8319, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(435.2574, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(307.8954, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(339.3917, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(237.1464, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(286.2760, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(234.6000, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(203.8491, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(193.2150, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(181.6808, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(138.3428, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(132.8286, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(107.6171, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(138.9130, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(85.2399, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(91.1226, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(66.8055, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(64.1390, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(53.2933, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(52.6319, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(55.5487, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(61.2451, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(43.0372, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(33.1086, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(27.3681, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(24.8709, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(22.8905, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(22.4093, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(22.2138, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(23.7698, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(30.9207, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(32.7256, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(33.0227, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(42.7158, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(38.4697, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(42.7909, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(34.3579, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(25.6670, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(25.3306, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(28.9195, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(25.6180, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(29.1337, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(25.9081, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(28.6603, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(31.6472, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(35.9515, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(31.4031, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(37.6827, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(48.2767, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(62.2871, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(63.6282, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(66.4598, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(51.8863, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(66.4561, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(59.3442, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(63.4190, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(46.8216, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(54.2552, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(47.1132, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(53.0072, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(43.2795, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(42.6263, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(42.9883, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(43.4839, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(38.4937, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(43.7996, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(44.9968, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(39.3978, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(35.0525, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b3c4ad2f155e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscene_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \"\"\"TODO:\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-a1bd1cc8020d>\u001b[0m in \u001b[0;36mmy_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0magent_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'agent_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mscene\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mscene_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscene_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "agent_id = 0\n",
    "epoch = 3\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out, scene_ids, track_ids, agent_ids = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(76, 98),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(98, 98),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(98, 98),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(98, 120)\n",
    ")\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()\n",
    "\n",
    "# Use the nn package to define our loss function\n",
    "loss_fn=torch.nn.MSELoss()\n",
    "\n",
    "# Use the optim package to define an Optimizer\n",
    "\n",
    "learning_rate =1e-3\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for i in trange(epoch):\n",
    "    \n",
    "    for i_batch, sample_batch in enumerate(tqdm(val_loader)):\n",
    "        inp, out, scene_ids, track_ids, agent_ids = sample_batch\n",
    "        \"\"\"TODO:\n",
    "          Deep learning model\n",
    "          training routine\n",
    "        \"\"\"\n",
    "        x = torch.flatten(inp, start_dim=2)\n",
    "\n",
    "        x = x.float()\n",
    "        y = out.float()\n",
    "\n",
    "        if cuda_status:\n",
    "            #model = model.cuda()\n",
    "            #x = inp.cuda()\n",
    "            #y = out.cuda()\n",
    "            x.to(device)\n",
    "            y.to(device)\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        y_pred = None\n",
    "\n",
    "        # Forward pass: predict y by passing x to the model.    \n",
    "        y_pred = model(x)\n",
    "        y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 4]))\n",
    "\n",
    "        # Compute the loss.\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        print(torch.sqrt(loss))\n",
    "\n",
    "        # Before backward pass, zero outgradients to clear buffers  \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient w.r.t modelparameters\n",
    "        loss.backward()\n",
    "\n",
    "        # makes an gradient descent step to update its parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        #print(y_pred.shape)\n",
    "        #show_sample_batch(sample_batch, agent_id)\n",
    "\n",
    "        if i_batch == 3216:\n",
    "            #show_sample_batch(sample_batch, agent_id)\n",
    "            #show_sample_batch([inp, y_pred.cpu().detach(), scene_ids, track_ids, agent_ids], agent_id)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './models/6epochmodel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/6epochmodel.pt')\n",
    "model.eval()\n",
    "model.to(device)\n",
    "if cuda_status:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a13ead1cd949afa00d799984a266a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         ID                  v1                  v2                  v3  \\\n",
      "0     10002  1763.3968505859375   412.9548645019531  1772.8170166015625   \n",
      "1     10015   725.8516845703125     1222.8857421875   720.3778686523438   \n",
      "2     10019   572.6814575195312   1245.853271484375   572.7365112304688   \n",
      "3     10028      1734.490234375    392.561279296875   1745.483154296875   \n",
      "4      1003    2093.14892578125   659.0765991210938    2093.48193359375   \n",
      "...     ...                 ...                 ...                 ...   \n",
      "3195   9897   258.7663269042969   804.1239624023438   258.0052795410156   \n",
      "3196     99   584.1934204101562    1143.76904296875   583.8372802734375   \n",
      "3197   9905  1759.2774658203125    467.811767578125  1766.5172119140625   \n",
      "3198   9910   572.4219970703125   1289.455810546875   572.8764038085938   \n",
      "3199   9918   580.6690063476562  1148.1163330078125   580.7485961914062   \n",
      "\n",
      "                      v4                  v5                  v6  \\\n",
      "0      383.5165710449219     1757.3447265625   387.8017883300781   \n",
      "1     1220.9168701171875   718.7011108398438  1227.1046142578125   \n",
      "2     1240.5816650390625   571.5288696289062  1243.9073486328125   \n",
      "3      362.0449523925781  1729.1072998046875   366.6072082519531   \n",
      "4          650.431640625   2090.467041015625   654.9354858398438   \n",
      "...                  ...                 ...                 ...   \n",
      "3195     804.55322265625   258.3545837402344   804.1845092773438   \n",
      "3196    1139.92236328125   582.9830322265625  1145.0509033203125   \n",
      "3197   448.0776062011719   1756.443603515625   454.8255310058594   \n",
      "3198  1284.5091552734375   571.2366333007812  1286.1934814453125   \n",
      "3199  1144.2864990234375   579.6281127929688  1149.0208740234375   \n",
      "\n",
      "                      v7                  v8                  v9  ...  \\\n",
      "0     1768.0697021484375   372.8656921386719  1787.6605224609375  ...   \n",
      "1      720.9457397460938   1224.868896484375   719.9894409179688  ...   \n",
      "2      571.1605224609375     1248.5107421875   569.2131958007812  ...   \n",
      "3     1740.2435302734375  349.50177001953125  1760.3748779296875  ...   \n",
      "4      2095.120849609375    651.077392578125   2101.344970703125  ...   \n",
      "...                  ...                 ...                 ...  ...   \n",
      "3195   258.0793762207031   803.6316528320312   258.4273681640625  ...   \n",
      "3196   582.3276977539062   1148.079833984375   580.2451782226562  ...   \n",
      "3197  1765.7457275390625  447.49017333984375  1778.1116943359375  ...   \n",
      "3198   571.7691040039062  1291.7618408203125   568.7468872070312  ...   \n",
      "3199   579.2072143554688    1152.74462890625   576.3082885742188  ...   \n",
      "\n",
      "                     v51                 v52                 v53  \\\n",
      "0      1773.446044921875     420.89794921875  1752.0350341796875   \n",
      "1      719.8867797851562   1222.927978515625   724.9444580078125   \n",
      "2      567.8772583007812   1245.004150390625   572.9285888671875   \n",
      "3      1746.052490234375   403.2859802246094  1721.7794189453125   \n",
      "4       2094.32958984375   661.4478149414062    2092.98095703125   \n",
      "...                  ...                 ...                 ...   \n",
      "3195  258.65045166015625   803.1033935546875   258.2627868652344   \n",
      "3196   580.4284057617188      1144.568359375    585.184326171875   \n",
      "3197  1767.6339111328125     469.72900390625  1758.0216064453125   \n",
      "3198   567.2428588867188  1288.0323486328125    572.067626953125   \n",
      "3199     576.85400390625  1149.1488037109375   581.4864501953125   \n",
      "\n",
      "                     v54                v55                 v56  \\\n",
      "0      411.2181091308594    1790.8466796875   368.6211853027344   \n",
      "1                1229.25    720.27783203125  1229.1588134765625   \n",
      "2       1252.89892578125  574.2042846679688   1248.802001953125   \n",
      "3      388.8490295410156  1765.820556640625   343.9031066894531   \n",
      "4         669.2548828125       2097.3984375   657.3521118164062   \n",
      "...                  ...                ...                 ...   \n",
      "3195    801.974365234375  257.1425476074219   802.2142944335938   \n",
      "3196   1151.295654296875     582.6630859375   1150.084716796875   \n",
      "3197   479.4718322753906  1774.205810546875   449.9459533691406   \n",
      "3198  1296.2098388671875   575.850830078125  1291.7127685546875   \n",
      "3199  1155.5484619140625  579.5409545898438  1154.7396240234375   \n",
      "\n",
      "                     v57                 v58                 v59  \\\n",
      "0     1794.1370849609375   420.1223449707031   1753.892333984375   \n",
      "1       720.535400390625   1220.740966796875   717.0693969726562   \n",
      "2      571.7435913085938   1241.465087890625   568.0294189453125   \n",
      "3     1772.0333251953125   400.7457580566406  1725.8179931640625   \n",
      "4        2091.7216796875     663.73876953125   2090.641357421875   \n",
      "...                  ...                 ...                 ...   \n",
      "3195  259.29766845703125    803.592529296875   259.1025695800781   \n",
      "3196    583.476318359375    1142.71240234375   578.5154418945312   \n",
      "3197   1767.584228515625  474.13629150390625  1755.3406982421875   \n",
      "3198     571.85595703125    1283.71923828125   569.2957153320312   \n",
      "3199   580.5637817382812      1146.998046875   575.6177978515625   \n",
      "\n",
      "                     v60  \n",
      "0      408.6924743652344  \n",
      "1     1223.9857177734375  \n",
      "2     1246.8870849609375  \n",
      "3     385.43658447265625  \n",
      "4      670.9901733398438  \n",
      "...                  ...  \n",
      "3195   803.1039428710938  \n",
      "3196  1146.0960693359375  \n",
      "3197   479.0723876953125  \n",
      "3198   1290.083740234375  \n",
      "3199  1150.6597900390625  \n",
      "\n",
      "[3200 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Submission output\n",
    "writeCSV = True\n",
    "val_path = \"./new_val_in/new_val_in\"\n",
    "\n",
    "if writeCSV:\n",
    "    \n",
    "    dataset = ArgoverseDataset(data_path=val_path)\n",
    "    test_loader = DataLoader(dataset,batch_size=batch_sz, shuffle = False, collate_fn=test_collate, num_workers=0)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(tqdm(test_loader)):\n",
    "            inp, scene_ids, track_ids, agent_ids = sample_batch\n",
    "            inp = torch.flatten(inp, start_dim=2)\n",
    "\n",
    "            if cuda_status:\n",
    "                model = model.cuda()\n",
    "                x = inp.cuda()\n",
    "            else:\n",
    "                x = inp\n",
    "\n",
    "            y_pred = None\n",
    "\n",
    "            # Forward pass: predict y by passing x to the model.    \n",
    "            y_pred = model(x.float())\n",
    "            y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 4]))\n",
    "            \n",
    "            for i in range(batch_sz):\n",
    "                row = []\n",
    "                row.append(scene_ids[i].item())\n",
    "                curr = y_pred[i]\n",
    "                \n",
    "                agent_id = agent_ids[i]\n",
    "                \n",
    "                for j in range(30):\n",
    "                    vehicle_index = 0\n",
    "                    found = False\n",
    "                    while not found:\n",
    "                        if track_ids[i][vehicle_index][j][0] == agent_id:\n",
    "                            found = True\n",
    "                        else:\n",
    "                            vehicle_index += 1\n",
    "\n",
    "                    row.append(str(curr[vehicle_index][j][0].item()))\n",
    "                    row.append(str(curr[vehicle_index][j][1].item()))\n",
    "                    \n",
    "                data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, columns = ['ID','v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','v11','v12','v13','v14','v15','v16','v17','v18','v19','v20','v21','v22','v23','v24','v25','v26','v27','v28','v29','v30','v31','v32','v33','v34','v35','v36','v37','v38','v39','v40','v41','v42','v43','v44','v45','v46','v47','v48','v49','v50','v51','v52','v53','v54','v55','v56','v57','v58','v59','v60'])\n",
    "    print(df)\n",
    "    df.to_csv('submission.csv', index=False)\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
