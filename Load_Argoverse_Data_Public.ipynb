{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 64\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, out, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "def test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c0112003c24545b8f8be362a08fa42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Interation', style=ProgressStyle(description_width='initiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([64, 60, 30, 4])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "agent_id = 0\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out, scene_ids, agent_ids = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])\n",
    "\n",
    "cuda_status = torch.cuda.is_available()\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(76, 98),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(98, 98),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(98, 98),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(98, 120)\n",
    ")\n",
    "\n",
    "# Use the nn package to define our loss function\n",
    "loss_fn=torch.nn.MSELoss()\n",
    "\n",
    "# Use the optim package to define an Optimizer\n",
    "\n",
    "learning_rate =1e-3\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        \n",
    "for i_batch, sample_batch in enumerate(val_loader):\n",
    "    inp, out, scene_ids, track_ids, agent_ids = sample_batch\n",
    "    \"\"\"TODO:\n",
    "      Deep learning model\n",
    "      training routine\n",
    "    \"\"\"\n",
    "    inp = torch.flatten(inp, start_dim=2)\n",
    "\n",
    "    if cuda_status:\n",
    "        model = model.cuda()\n",
    "        x = inp.cuda()\n",
    "        y = out.cuda()\n",
    "    else:\n",
    "        x = inp\n",
    "        y = out\n",
    "    \n",
    "    y_pred = None\n",
    "    \n",
    "    for t in tqdm(range(100), desc='Interation'):\n",
    "        \n",
    "        # Forward pass: predict y by passing x to the model.    \n",
    "        y_pred = model(x.float())\n",
    "        y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 4]))\n",
    "        \n",
    "        # Compute the loss.\n",
    "        loss = loss_fn(y_pred, y.float())\n",
    "        \n",
    "        # Before backward pass, zero outgradients to clear buffers  \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Backward pass: compute gradient w.r.t modelparameters\n",
    "        loss.backward()\n",
    "    \n",
    "        # makes an gradient descent step to update its parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(y_pred.shape)\n",
    "    #show_sample_batch(sample_batch, agent_id)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID                  v1                  v2                  v3  \\\n",
      "0     10002   1493.310302734375   634.3666381835938   1519.458740234375   \n",
      "1     10015   803.0217895507812   1246.845458984375   791.0904541015625   \n",
      "2     10019    637.389892578125  1265.9071044921875   627.3250732421875   \n",
      "3     10028   1461.567138671875     593.74462890625  1487.1075439453125   \n",
      "4      1003  1983.6942138671875   831.8873901367188   2013.936767578125   \n",
      "...     ...                 ...                 ...                 ...   \n",
      "3195   9897   286.5245666503906   786.5621337890625   281.9903869628906   \n",
      "3196     99   649.2754516601562  1118.2042236328125   639.1567993164062   \n",
      "3197   9905  1580.4593505859375   659.2946166992188  1607.9818115234375   \n",
      "3198   9910   639.6616821289062   1270.679443359375   629.4117431640625   \n",
      "3199   9918   643.0025024414062  1118.8931884765625    632.801513671875   \n",
      "\n",
      "                      v4                  v5                  v6  \\\n",
      "0      597.6365966796875  1488.8243408203125     679.39599609375   \n",
      "1      1262.651611328125   802.0543823242188    1272.38623046875   \n",
      "2              1299.1875   636.4730834960938  1250.4986572265625   \n",
      "3      574.7911987304688   1456.663330078125    646.784423828125   \n",
      "4      815.2889404296875  1982.6573486328125   863.1533813476562   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   749.6991577148438   286.4029846191406   702.1402587890625   \n",
      "3196   1148.952392578125   648.2837524414062  1065.3167724609375   \n",
      "3197   627.5196533203125  1578.5858154296875   710.3445434570312   \n",
      "3198  1296.6033935546875   638.6975708007812    1253.69580078125   \n",
      "3199     1140.3427734375   641.8331298828125  1108.8035888671875   \n",
      "\n",
      "                      v7                  v8                  v9  ...  \\\n",
      "0     1528.8214111328125   662.5247802734375   1518.022216796875  ...   \n",
      "1        797.86181640625  1177.8758544921875   786.2809448242188  ...   \n",
      "2      633.9539794921875  1213.0633544921875   622.2749633789062  ...   \n",
      "3     1496.9737548828125   622.6564331054688   1486.481201171875  ...   \n",
      "4     2019.1993408203125   866.5863647460938  2009.1107177734375  ...   \n",
      "...                  ...                 ...                 ...  ...   \n",
      "3195  285.91021728515625   799.2741088867188   278.1749572753906  ...   \n",
      "3196   645.4600830078125    1097.95361328125   634.7013549804688  ...   \n",
      "3197     1614.4892578125   708.3968505859375    1604.09619140625  ...   \n",
      "3198   636.2868041992188   1269.309814453125   624.2771606445312  ...   \n",
      "3199   639.3560791015625     1115.0361328125   628.4042358398438  ...   \n",
      "\n",
      "                     v51                    v52                 v53  \\\n",
      "0     1500.5250244140625  -0.010633781552314758  1547.0943603515625   \n",
      "1      806.8599853515625  -0.010633781552314758    782.143310546875   \n",
      "2      642.0394287109375  -0.010633781552314758   621.2637329101562   \n",
      "3     1467.6998291015625  -0.010633781552314758  1514.1846923828125   \n",
      "4      2009.223388671875  -0.010633781552314758     2051.3466796875   \n",
      "...                  ...                    ...                 ...   \n",
      "3195   290.1848449707031  -0.010633781552314758   280.2770690917969   \n",
      "3196        653.51171875  -0.010633781552314758   632.4927368164062   \n",
      "3197   1595.621337890625  -0.010633781552314758    1637.48193359375   \n",
      "3198   644.7095947265625  -0.010633781552314758    623.363525390625   \n",
      "3199   647.5335083007812  -0.010633781552314758    626.380126953125   \n",
      "\n",
      "                       v54                 v55                   v56  \\\n",
      "0     -0.01201196014881134    1563.39990234375  0.052837174385786057   \n",
      "1     -0.01201196014881134   806.3492431640625  0.052837174385786057   \n",
      "2     -0.01201196014881134   644.2543334960938  0.052837174385786057   \n",
      "3     -0.01201196014881134  1530.1807861328125  0.052837174385786057   \n",
      "4     -0.01201196014881134     2070.0712890625  0.052837174385786057   \n",
      "...                    ...                 ...                   ...   \n",
      "3195  -0.01201196014881134   293.2727355957031  0.052837174385786057   \n",
      "3196  -0.01201196014881134   654.2984008789062  0.052837174385786057   \n",
      "3197  -0.01201196014881134  1654.0255126953125  0.052837174385786057   \n",
      "3198  -0.01201196014881134    647.062744140625  0.052837174385786057   \n",
      "3199  -0.01201196014881134   648.0835571289062  0.052837174385786057   \n",
      "\n",
      "                     v57                  v58                 v59  \\\n",
      "0           1495.6171875  0.01866437867283821     1493.8681640625   \n",
      "1      792.6098022460938  0.01866437867283821   803.4879760742188   \n",
      "2      627.9673461914062  0.01866437867283821     638.47314453125   \n",
      "3     1463.7293701171875  0.01866437867283821     1461.4169921875   \n",
      "4      1990.006591796875  0.01866437867283821  1994.3665771484375   \n",
      "...                  ...                  ...                 ...   \n",
      "3195   281.5655822753906  0.01866437867283821   287.2205505371094   \n",
      "3196   640.3054809570312  0.01866437867283821   649.8927001953125   \n",
      "3197   1584.638427734375  0.01866437867283821    1584.53662109375   \n",
      "3198   630.0298461914062  0.01866437867283821   640.8076782226562   \n",
      "3199   634.1793823242188  0.01866437867283821   643.4144897460938   \n",
      "\n",
      "                        v60  \n",
      "0     -0.012230662629008293  \n",
      "1     -0.012230662629008293  \n",
      "2     -0.012230662629008293  \n",
      "3     -0.012230662629008293  \n",
      "4     -0.012230662629008293  \n",
      "...                     ...  \n",
      "3195  -0.012230662629008293  \n",
      "3196  -0.012230662629008293  \n",
      "3197  -0.012230662629008293  \n",
      "3198  -0.012230662629008293  \n",
      "3199  -0.012230662629008293  \n",
      "\n",
      "[3200 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Submission output\n",
    "writeCSV = True\n",
    "val_path = \"./new_val_in/new_val_in\"\n",
    "\n",
    "if writeCSV:\n",
    "    \n",
    "    dataset = ArgoverseDataset(data_path=val_path)\n",
    "    test_loader = DataLoader(dataset,batch_size=batch_sz, shuffle = False, collate_fn=test_collate, num_workers=0)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        #with tqdm(test_loader, unit=\"batch\") as batches:\n",
    "        for i_batch, sample_batch in enumerate(test_loader):\n",
    "            inp, scene_ids, track_ids, agent_ids = sample_batch\n",
    "            inp = torch.flatten(inp, start_dim=2)\n",
    "\n",
    "            if cuda_status:\n",
    "                model = model.cuda()\n",
    "                x = inp.cuda()\n",
    "            else:\n",
    "                x = inp\n",
    "\n",
    "            y_pred = None\n",
    "\n",
    "            # Forward pass: predict y by passing x to the model.    \n",
    "            y_pred = model(x.float())\n",
    "            y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 4]))\n",
    "            \n",
    "            #print(track_ids[63][15][0].item())\n",
    "            #for i in range(30):\n",
    "            #    print(track_ids[15][i][0].item())\n",
    "            #print(agent_ids[15])\n",
    "            #break\n",
    "            \n",
    "            for i in range(batch_sz):\n",
    "                row = []\n",
    "                row.append(scene_ids[i].item())\n",
    "                curr = y_pred[i]\n",
    "                #for j in range(60):\n",
    "                #    row.append(str(curr[j][29][0].item()) + ' ' + str(curr[j][29][1].item()))\n",
    "                #data.append(row)\n",
    "                \n",
    "                agent_id = agent_ids[i]\n",
    "                \n",
    "                for j in range(30):\n",
    "                    vehicle_index = 0\n",
    "                    found = False\n",
    "                    while not found:\n",
    "                        if track_ids[i][vehicle_index][j][0] == agent_id:\n",
    "                            found = True\n",
    "                        else:\n",
    "                            vehicle_index += 1\n",
    "\n",
    "                    row.append(str(curr[vehicle_index][j][0].item()))\n",
    "                    row.append(str(curr[j][j][1].item()))\n",
    "                    \n",
    "                data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, columns = ['ID','v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','v11','v12','v13','v14','v15','v16','v17','v18','v19','v20','v21','v22','v23','v24','v25','v26','v27','v28','v29','v30','v31','v32','v33','v34','v35','v36','v37','v38','v39','v40','v41','v42','v43','v44','v45','v46','v47','v48','v49','v50','v51','v52','v53','v54','v55','v56','v57','v58','v59','v60'])\n",
    "    print(df)\n",
    "    df.to_csv('submission.csv', index=False)\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
