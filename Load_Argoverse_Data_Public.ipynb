{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train\"\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 64\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    out = torch.LongTensor(out)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, out, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "def test_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    scene_ids = [scene['scene_idx'] for scene in batch]\n",
    "    track_ids = [scene['track_id'] for scene in batch]\n",
    "    agent_ids = [scene['agent_id'] for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    scene_ids = torch.LongTensor(scene_ids)\n",
    "    return [inp, scene_ids, track_ids, agent_ids]\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e23dc4543a749cbb39bc936a57ac4f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3218.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(594.6129, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(544.4818, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(345.7233, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(401.4920, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(455.6719, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(310.2443, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(239.5697, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(287.5349, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(222.7291, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(187.3951, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(174.1141, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(157.2029, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(127.7034, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(127.1480, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(89.9880, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(102.8357, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(72.9943, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(75.6037, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(57.6328, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(52.3554, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(46.3993, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(44.8650, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(49.9475, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(55.0077, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(40.0023, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(30.9652, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(26.0397, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(23.3906, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(22.7671, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(21.8519, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(20.8904, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(20.3667, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(26.5328, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(20.5186, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(17.9285, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(20.4689, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(19.4492, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(22.4391, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(18.5220, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(18.1862, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(20.0303, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(26.6099, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(31.2378, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(42.3127, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(51.1755, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(60.4079, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(67.9199, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(55.8443, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(40.6888, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(35.0222, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(34.8338, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(34.3748, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(33.5774, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(31.9651, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(39.0662, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(48.2409, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(63.2180, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(54.4381, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(61.3048, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(58.9883, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(67.0817, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(59.7334, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(59.5681, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(34.5098, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(37.0410, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(28.9989, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(29.8049, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(28.2642, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(30.5756, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(25.6987, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(25.8984, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(26.3112, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(32.6067, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(32.6627, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(31.1634, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(24.4966, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(27.6014, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(28.7053, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(32.9371, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(31.6802, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(34.5160, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(32.0357, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(33.4890, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(43.8653, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(44.0626, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(39.0241, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(31.4464, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(31.3224, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(34.2759, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(31.4442, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(30.0727, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(40.2105, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(52.6473, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(48.1030, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(64.5305, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(56.4803, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(80.7539, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(90.3282, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(102.9646, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(28.4134, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(28.6611, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(27.0004, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(25.6082, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(28.2507, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(32.3989, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(31.9361, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(36.3752, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(30.0228, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(35.1485, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(36.0653, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(39.0904, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(27.4844, device='cuda:0', grad_fn=<SqrtBackward>)\n",
      "tensor(28.5708, device='cuda:0', grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "agent_id = 0\n",
    "\n",
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out, scene_ids, track_ids, agent_ids = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])\n",
    "\n",
    "cuda_status = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(76, 98),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(98, 98),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(98, 98),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(98, 120)\n",
    ")\n",
    "model.to(device)\n",
    "model = model.cuda()\n",
    "\n",
    "# Use the nn package to define our loss function\n",
    "loss_fn=torch.nn.MSELoss()\n",
    "\n",
    "# Use the optim package to define an Optimizer\n",
    "\n",
    "learning_rate =1e-3\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        \n",
    "for i_batch, sample_batch in enumerate(tqdm(val_loader)):\n",
    "    inp, out, scene_ids, track_ids, agent_ids = sample_batch\n",
    "    \"\"\"TODO:\n",
    "      Deep learning model\n",
    "      training routine\n",
    "    \"\"\"\n",
    "    x = torch.flatten(inp, start_dim=2)\n",
    "    \n",
    "    x = x.float()\n",
    "    y = out.float()\n",
    "\n",
    "    if cuda_status:\n",
    "        #model = model.cuda()\n",
    "        #x = inp.cuda()\n",
    "        #y = out.cuda()\n",
    "        x.to(device)\n",
    "        y.to(device)\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "    \n",
    "    y_pred = None\n",
    "    \n",
    "    #for t in tqdm(range(100), desc='Interation'):\n",
    "\n",
    "    # Forward pass: predict y by passing x to the model.    \n",
    "    y_pred = model(x)\n",
    "    y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 4]))\n",
    "\n",
    "    # Compute the loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(torch.sqrt(loss))\n",
    "\n",
    "    # Before backward pass, zero outgradients to clear buffers  \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient w.r.t modelparameters\n",
    "    loss.backward()\n",
    "\n",
    "    # makes an gradient descent step to update its parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    #print(y_pred.shape)\n",
    "    #show_sample_batch(sample_batch, agent_id)\n",
    "    \n",
    "    if i_batch == 3216:\n",
    "        show_sample_batch(sample_batch, agent_id)\n",
    "        show_sample_batch([inp, y_pred.cpu(), scene_ids, track_ids, agent_ids], agent_id)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52c268d6d1f4749916a84b3c63bc1ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         ID                  v1                  v2                  v3  \\\n",
      "0     10002  1772.2906494140625   436.3206787109375  1739.6370849609375   \n",
      "1     10015   708.8126831054688  1236.3702392578125    698.725341796875   \n",
      "2     10019    565.551025390625   1263.260498046875   557.5541381835938   \n",
      "3     10028  1745.3839111328125   414.9216613769531  1711.3304443359375   \n",
      "4      1003         2113.421875   705.3589477539062     2110.6845703125   \n",
      "...     ...                 ...                 ...                 ...   \n",
      "3195   9897   259.0938415527344   818.1580810546875   260.1385803222656   \n",
      "3196     99   573.8143920898438   1161.502197265625     564.32958984375   \n",
      "3197   9905   1784.760986328125   511.9339904785156  1767.8187255859375   \n",
      "3198   9910      565.6787109375   1308.688232421875   558.0505981445312   \n",
      "3199   9918   571.3824462890625  1167.3350830078125     561.93017578125   \n",
      "\n",
      "                      v4                  v5                  v6  \\\n",
      "0       461.389404296875    1786.33642578125   405.8036804199219   \n",
      "1     1217.6131591796875   722.2525024414062    1225.18212890625   \n",
      "2     1249.8712158203125   571.3507080078125      1252.791015625   \n",
      "3      440.5215148925781   1762.898193359375   380.7854309082031   \n",
      "4      702.1546020507812   2116.067626953125   693.4302978515625   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   817.2723999023438  257.13555908203125    818.743896484375   \n",
      "3196  1147.2083740234375   581.1736450195312      1152.271484375   \n",
      "3197   523.0817260742188  1790.1339111328125   492.0671691894531   \n",
      "3198  1295.2181396484375   570.6817016601562  1297.3243408203125   \n",
      "3199  1152.8145751953125   578.3402709960938   1157.588623046875   \n",
      "\n",
      "                      v7                  v8                  v9  ...  \\\n",
      "0      1709.033935546875   399.2635498046875   1772.116943359375  ...   \n",
      "1      703.8547973632812     1233.5341796875   698.1193237304688  ...   \n",
      "2      564.4075317382812     1256.0595703125   560.1278076171875  ...   \n",
      "3      1680.123779296875    376.894287109375  1747.4835205078125  ...   \n",
      "4      2089.700927734375   686.5602416992188     2114.1865234375  ...   \n",
      "...                  ...                 ...                 ...  ...   \n",
      "3195   261.4337463378906   812.8546752929688   260.9268798828125  ...   \n",
      "3196   569.5616455078125  1158.1534423828125      564.9716796875  ...   \n",
      "3197  1740.5521240234375   481.3738098144531  1783.6898193359375  ...   \n",
      "3198     565.79736328125     1299.6044921875    561.702392578125  ...   \n",
      "3199   567.4696044921875     1163.2177734375   563.0247802734375  ...   \n",
      "\n",
      "                     v51                 v52                 v53  \\\n",
      "0         1745.251953125  446.94769287109375  1707.3345947265625   \n",
      "1      695.7208862304688    1214.88232421875   681.0770263671875   \n",
      "2      557.9993286132812  1246.8729248046875    547.413330078125   \n",
      "3       1716.28564453125   427.1927490234375  1676.3597412109375   \n",
      "4        2106.1826171875   693.3568115234375    2103.42236328125   \n",
      "...                  ...                 ...                 ...   \n",
      "3195  262.05792236328125    814.115478515625   265.9273376464844   \n",
      "3196   563.6849975585938       1145.74609375   551.7156982421875   \n",
      "3197  1769.8485107421875  508.66668701171875      1745.615234375   \n",
      "3198   559.1223754882812  1291.4766845703125   549.0650634765625   \n",
      "3199   561.5482177734375  1150.9454345703125   549.7493896484375   \n",
      "\n",
      "                     v54                 v55                 v56  \\\n",
      "0      519.3624267578125  1695.5968017578125   403.0457458496094   \n",
      "1      1217.669677734375    697.047119140625  1227.6060791015625   \n",
      "2      1246.137939453125   557.9024658203125  1256.5408935546875   \n",
      "3      503.3952941894531   1665.666259765625   377.6628723144531   \n",
      "4      723.2259521484375   2094.256103515625   692.3132934570312   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   813.4705200195312   261.5901184082031   816.0701904296875   \n",
      "3196   1144.032958984375   563.4573364257812  1155.6844482421875   \n",
      "3197   561.6060791015625  1736.8604736328125   491.8937072753906   \n",
      "3198    1291.25830078125   558.9564208984375  1301.1009521484375   \n",
      "3199  1149.5989990234375   561.3228149414062  1160.9534912109375   \n",
      "\n",
      "                     v57                 v58                 v59  \\\n",
      "0     1756.9910888671875  431.33673095703125  1680.4600830078125   \n",
      "1      710.0462646484375  1224.2760009765625   708.2500610351562   \n",
      "2      564.0053100585938  1251.1339111328125     564.60791015625   \n",
      "3     1731.1729736328125   407.4232177734375     1648.7861328125   \n",
      "4       2107.10693359375   697.3173217773438    2086.75439453125   \n",
      "...                  ...                 ...                 ...   \n",
      "3195   259.1564025878906   817.6487426757812   258.9873352050781   \n",
      "3196   573.9488525390625   1152.638916015625   572.9785766601562   \n",
      "3197   1771.487060546875   506.2742919921875   1724.993408203125   \n",
      "3198    563.668212890625   1294.737548828125   564.9554443359375   \n",
      "3199      571.4541015625    1157.58056640625   570.7008666992188   \n",
      "\n",
      "                     v60  \n",
      "0     437.55316162109375  \n",
      "1     1211.0152587890625  \n",
      "2     1246.1593017578125  \n",
      "3      416.4210205078125  \n",
      "4      708.2940063476562  \n",
      "...                  ...  \n",
      "3195   814.4890747070312  \n",
      "3196   1142.916748046875  \n",
      "3197   512.5254516601562  \n",
      "3198         1291.421875  \n",
      "3199  1148.3314208984375  \n",
      "\n",
      "[3200 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Submission output\n",
    "writeCSV = True\n",
    "val_path = \"./new_val_in/new_val_in\"\n",
    "\n",
    "if writeCSV:\n",
    "    \n",
    "    dataset = ArgoverseDataset(data_path=val_path)\n",
    "    test_loader = DataLoader(dataset,batch_size=batch_sz, shuffle = False, collate_fn=test_collate, num_workers=0)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batch in enumerate(tqdm(test_loader)):\n",
    "            inp, scene_ids, track_ids, agent_ids = sample_batch\n",
    "            inp = torch.flatten(inp, start_dim=2)\n",
    "\n",
    "            if cuda_status:\n",
    "                model = model.cuda()\n",
    "                x = inp.cuda()\n",
    "            else:\n",
    "                x = inp\n",
    "\n",
    "            y_pred = None\n",
    "\n",
    "            # Forward pass: predict y by passing x to the model.    \n",
    "            y_pred = model(x.float())\n",
    "            y_pred = torch.reshape(y_pred, torch.Size([batch_sz, 60, 30, 4]))\n",
    "            \n",
    "            #print(track_ids[63][15][0].item())\n",
    "            #for i in range(30):\n",
    "            #    print(track_ids[15][i][0].item())\n",
    "            #print(agent_ids[15])\n",
    "            #break\n",
    "            \n",
    "            #vehicle_index = 0\n",
    "            #found = False\n",
    "            #while not found:\n",
    "            #    if track_ids[i][vehicle_index][j][0] == agent_id:\n",
    "            #        found = True\n",
    "            #    else:\n",
    "            #        vehicle_index += 1\n",
    "            \n",
    "            for i in range(batch_sz):\n",
    "                row = []\n",
    "                row.append(scene_ids[i].item())\n",
    "                curr = y_pred[i]\n",
    "                #for j in range(60):\n",
    "                #    row.append(str(curr[j][29][0].item()) + ' ' + str(curr[j][29][1].item()))\n",
    "                #data.append(row)\n",
    "                \n",
    "                agent_id = agent_ids[i]\n",
    "                \n",
    "                for j in range(30):\n",
    "                    vehicle_index = 0\n",
    "                    found = False\n",
    "                    while not found:\n",
    "                        if track_ids[i][vehicle_index][j][0] == agent_id:\n",
    "                            found = True\n",
    "                        else:\n",
    "                            vehicle_index += 1\n",
    "\n",
    "                    row.append(str(curr[vehicle_index][j][0].item()))\n",
    "                    row.append(str(curr[vehicle_index][j][1].item()))\n",
    "                    \n",
    "                data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, columns = ['ID','v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','v11','v12','v13','v14','v15','v16','v17','v18','v19','v20','v21','v22','v23','v24','v25','v26','v27','v28','v29','v30','v31','v32','v33','v34','v35','v36','v37','v38','v39','v40','v41','v42','v43','v44','v45','v46','v47','v48','v49','v50','v51','v52','v53','v54','v55','v56','v57','v58','v59','v60'])\n",
    "    print(df)\n",
    "    df.to_csv('submission.csv', index=False)\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
